import argparse
import json
import os
import pathlib
import tempfile
import threading
import time
from datetime import datetime as dt
from concurrent.futures import ThreadPoolExecutor

import torch
import torchaudio
import pyaudio  # type: ignore
import wave

from utils.logger import get_logger
from modules.separation.separator import AudioSeparator
from modules.identification.VID_identify_v5 import SpeakerIdentifier
from modules.asr.whisper_asr import WhisperASR

logger = get_logger(__name__)

logger.info("ğŸ–¥ GPU available: %s", torch.cuda.is_available())
if torch.cuda.is_available():
    logger.info("   Device: %s", torch.cuda.get_device_name(0))

# ---------- 1. è‡ªå‹•åµæ¸¬ GPU ----------
use_gpu = torch.cuda.is_available()
logger.info(f"ğŸš€ ä½¿ç”¨è¨­å‚™: {'cuda' if use_gpu else 'cpu'}")

sep = AudioSeparator()
spk = SpeakerIdentifier()
asr = WhisperASR(model_name="medium", gpu=use_gpu)

def process_segment(seg_path: str, t0: float, t1: float) -> dict:
    """Process a single separated segment and return metrics."""
    logger.info(
        f"ğŸ”§ åŸ·è¡Œç·’ {threading.get_ident()} è™•ç† ({t0:.2f}-{t1:.2f}) â†’ {os.path.basename(seg_path)}"
    )
    start = time.perf_counter()

    # SpeakerID
    t_spk0 = time.perf_counter()
    speaker_id, name, dist = spk.process_audio_file(seg_path)
    t_spk1 = time.perf_counter()
    spk_time = t_spk1 - t_spk0
    logger.info(f"â± SpeakerID è€—æ™‚ {spk_time:.3f}s")

    # ASR
    t_asr0 = time.perf_counter()
    text, conf, words = asr.transcribe(seg_path)
    t_asr1 = time.perf_counter()
    asr_time = t_asr1 - t_asr0
    logger.info(f"â± ASR è€—æ™‚ {asr_time:.3f}s")

    # èª¿æ•´æ¯å€‹è©çš„æ™‚é–“æˆ³ï¼Œä½¿å…¶å°é½ŠåŸå§‹æ··éŸ³æª”è»¸
    adjusted_words = []
    for w in words:
        w['start'] = w['start'] + t0
        w['end']   = w['end'] + t0
        adjusted_words.append(w)

    total = time.perf_counter() - start
    logger.info(f"â± segment ç¸½è€—æ™‚ {total:.3f}s")

    return {
        "start": round(t0, 2),
        "end": round(t1, 2),
        "speaker": name,
        "distance": round(float(dist), 3),
        "text": text,
        "confidence": round(conf, 2),
        "words": adjusted_words,
        "spk_time": spk_time,
        "asr_time": asr_time,
    }


def make_pretty(seg: dict) -> dict:
    """Convert a segment dict to human friendly format."""
    return {
        "time": f"{seg['start']:.2f}s â†’ {seg['end']:.2f}s",
        "speaker": seg["speaker"],
        "similarity": f"{seg['distance']:.3f}",
        "confidence": f"{seg['confidence']*100:.1f}%",
        "text": seg["text"],
        "word_count": len(seg["words"]),
    }


def run_pipeline_file(raw_wav: str, max_workers: int = 3):
    """Run pipeline on an existing wav file."""
    total_start = time.perf_counter()

    waveform, sr = torchaudio.load(raw_wav)
    audio_len = waveform.shape[1] / sr
    out_dir = pathlib.Path("work_output") / dt.now().strftime("%Y%m%d_%H%M%S")
    out_dir.mkdir(parents=True, exist_ok=True)

    # 1) åˆ†é›¢
    sep_start = time.perf_counter()
    segments = sep.separate_and_save(waveform, str(out_dir), segment_index=0)
    sep_end = time.perf_counter()
    logger.info(f"â± åˆ†é›¢è€—æ™‚ {sep_end - sep_start:.3f}s, å…± {len(segments)} æ®µ")

    # 2) å¤šåŸ·è¡Œç·’è™•ç†æ‰€æœ‰æ®µ
    logger.info(f"ğŸ”„ è™•ç† {len(segments)} æ®µ... (max_workers={max_workers})")
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        bundle = [r for r in ex.map(lambda s: process_segment(*s), segments) if r]
    spk_time = sum(s.get("spk_time", 0.0) for s in bundle)
    asr_time = sum(s.get("asr_time", 0.0) for s in bundle)

    # 3) è¼¸å‡ºçµæœ
    bundle.sort(key=lambda x: x["start"])
    pretty_bundle = [make_pretty(s) for s in bundle]

    json_path = out_dir / "output.json"
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump({"segments": bundle}, f, ensure_ascii=False, indent=2)

    total_end = time.perf_counter()
    total_time = total_end - total_start
    logger.info(f"âœ… Pipeline finished â†’ {json_path} (ç¸½è€—æ™‚ {total_time:.3f}s)")

    stats = {
        "length": audio_len,
        "total": total_time,
        "separate": sep_end - sep_start,
        "speaker": spk_time,
        "asr": asr_time,
    }

    return bundle, pretty_bundle, stats


def run_pipeline_dir(dir_path: str, max_workers: int = 3) -> str:
    """ä¸€æ¬¡è™•ç†è³‡æ–™å¤¾å…§æ‰€æœ‰éŸ³æª”ï¼Œä¸¦å°‡ã€Œæª”æ¡ˆå±¤ç´šçµ±è¨ˆã€+ã€Œæ®µè½å±¤ç´šè©³æƒ…ã€å¯«å…¥åŒä¸€ä»½ TSVã€‚

    åªå‘¼å« `run_pipeline_file()` ä¸€æ¬¡å°±åŒæ™‚æ‹¿åˆ° `stats` èˆ‡ `segments`ï¼Œé¿å…é‡è¤‡é‹ç®—ã€‚
    å›å‚³å€¼ç‚ºç”Ÿæˆä¹‹ `summary.tsv` çš„è·¯å¾‘ï¼ˆå­—ä¸²ï¼‰ã€‚
    """

    # === æº–å‚™è¼¸å‡ºç›®éŒ„ ===
    timestamp = dt.now().strftime("%Y%m%d_%H%M%S")
    out_dir = pathlib.Path("work_output") / f"batch_{timestamp}"
    out_dir.mkdir(parents=True, exist_ok=True)
    summary_path = out_dir / "summary.tsv"

    # === æ”¶é›†æ‰€æœ‰æ”¯æ´æ ¼å¼ä¹‹éŸ³æª”ï¼ˆå«å­ç›®éŒ„ï¼‰ ===
    audio_files = [f for f in pathlib.Path(dir_path).rglob("*") if f.suffix.lower() in {".wav", ".mp3", ".flac", ".ogg"}]
    if not audio_files:
        logger.warning("âš ï¸  ç›®éŒ„å…§æœªæ‰¾åˆ°æ”¯æ´æ ¼å¼éŸ³æª”")
        return str(summary_path)

    # === ä¸€æ¬¡è™•ç†ä¸¦æš«å­˜çµæœ ===
    file_results = []  # [(æª”æ¡ˆç´¢å¼•, Path, stats, segments)]
    for idx, audio in enumerate(sorted(audio_files), start=1):
        logger.info(f"===== è™•ç†æª”æ¡ˆ {audio.name} ({idx}/{len(audio_files)}) =====")
        segments, pretty, stats = run_pipeline_file(str(audio), max_workers)
        file_results.append((idx, audio, stats, segments))

    # === å¯«å…¥ TSV ===
    with open(summary_path, "w", encoding="utf-8") as f:
        # -- æª”æ¡ˆå±¤ç´šçµ±è¨ˆ --
        f.write("ç·¨è™Ÿ\tæª”å\téŸ³æª”é•·åº¦(s)\tç¸½è€—æ™‚(s)\tåˆ†é›¢è€—æ™‚(s)\tSpeakerIDè€—æ™‚(s)\tASRè€—æ™‚(s)\n")
        for idx, audio, stats, _ in file_results:
            f.write(
                f"{idx}\t{audio.name}\t{stats['length']:.2f}\t{stats['total']:.2f}\t"
                f"{stats['separate']:.2f}\t{stats['speaker']:.2f}\t{stats['asr']:.2f}\n"
            )
        # ç©ºè¡Œåˆ†æ®µ
        f.write("\næª”æ¡ˆ\té–‹å§‹(s)\tçµæŸ(s)\tèªªè©±è€…\tdistance\tconfidence\tæ–‡å­—\n")
        # -- æ®µè½å±¤ç´šè©³æƒ… --
        for _, audio, _, segments in file_results:
            for seg in segments:
                text = str(seg.get("text", "")).replace("\t", " ")
                f.write(
                    f"{audio.name}\t{seg['start']:.3f}\t{seg['end']:.3f}\t"
                    f"{seg['speaker']}\t{seg['distance']:.4f}\t{seg['confidence']:.4f}\t{text}\n"
                )

    logger.info(f"âœ… Directory pipeline å®Œæˆ â†’ {summary_path}")
    return str(summary_path)



def main():
    parser = argparse.ArgumentParser(description="Speech pipeline")
    sub = parser.add_subparsers(dest="mode", required=True)

    p_file = sub.add_parser("file", help="process existing wav file")
    p_file.add_argument("path")
    p_file.add_argument("--workers", type=int, default=4)

    p_dir = sub.add_parser("dir", help="process all wav files in a directory")
    p_dir.add_argument("path")
    p_dir.add_argument("--workers", type=int, default=4)
    p_dir.add_argument("--out", default="summary.tsv")

    args = parser.parse_args()

    if args.mode == "file":
        run_pipeline_file(args.path, args.workers)
    elif args.mode == "dir":
        run_pipeline_dir(args.path, args.workers, args.out)

if __name__ == "__main__":
    main()
