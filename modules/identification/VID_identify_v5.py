"""
===============================================================================
èªè€…è­˜åˆ¥å¼•æ“ (Speaker Identification Engine) V2
===============================================================================

ç‰ˆæœ¬ï¼šv5.2.1 - V2è³‡æ–™åº«ç‰ˆæœ¬ï¼Œæœ‰pyannoteæ¨¡å‹  
ä½œè€…ï¼šCYouuu
æœ€å¾Œæ›´æ–°ï¼š2025-08-13

âš ï¸ é‡è¦è®Šæ›´ âš ï¸
æœ¬ç‰ˆæœ¬å·²å‡ç´šç‚ºV2è³‡æ–™åº«çµæ§‹ï¼Œèˆ‡V1ç‰ˆæœ¬ä¸ç›¸å®¹ï¼
- Speaker: æ–°å¢speaker_id (INT)ã€full_nameã€nicknameã€genderç­‰æ¬„ä½  
- VoicePrint: ç§»é™¤å†—é¤˜çš„voiceprint_idï¼Œç›´æ¥ä½¿ç”¨Weaviate UUIDã€sample_countã€quality_scoreç­‰æ¬„ä½
- æ™‚é–“æ¬„ä½é‡å‘½å: create_time -> created_at, updated_time -> updated_at

åŠŸèƒ½æ‘˜è¦ï¼š
-----------
æœ¬æ¨¡çµ„å¯¦ç¾äº†åŸºæ–¼æ·±åº¦å­¸ç¿’çš„èªè€…è­˜åˆ¥åŠŸèƒ½ï¼Œèƒ½å¤ å¾éŸ³è¨Šæª”æ¡ˆä¸­æå–èªè€…ç‰¹å¾µå‘é‡ï¼Œ
ä¸¦èˆ‡è³‡æ–™åº«ä¸­çš„å·²çŸ¥èªè€…é€²è¡Œæ¯”å°ï¼Œå¯¦ç¾èªè€…èº«ä»½è­˜åˆ¥èˆ‡è²ç´‹æ›´æ–°ã€‚ä¸»è¦å„ªé»åŒ…æ‹¬ï¼š

 1. æ”¯æ´å³æ™‚èªè€…è­˜åˆ¥èˆ‡è³‡æ–™åº«æ›´æ–°
 2. ä½¿ç”¨å–®ä¾‹æ¨¡å¼é¿å…é‡è¤‡åˆå§‹åŒ–æ¨¡å‹å’Œè³‡æ–™åº«é€£ç·š
 3. æ”¯æ´å¤šç¨®éŸ³è¨Šæ ¼å¼åŠå–æ¨£ç‡è‡ªå‹•é©é…
 4. æ•´åˆ Weaviate å‘é‡è³‡æ–™åº«å¯¦ç¾é«˜æ•ˆèªè€…æ¯”å°
 5. æä¾›å½ˆæ€§çš„é–¾å€¼è¨­å®šï¼Œå¯è‡ªè¨‚èªè€…åŒ¹é…ç­–ç•¥

æŠ€è¡“æ¶æ§‹ï¼š
-----------
 - èªè€…åµŒå…¥æ¨¡å‹: SpeechBrain ECAPA-TDNN æ¨¡å‹
 - å‘é‡è³‡æ–™åº«: Weaviate
 - å–æ¨£ç‡è‡ªé©æ‡‰: è‡ªå‹•è™•ç† 8kHz/16kHz/44.1kHz ç­‰å¸¸è¦‹å–æ¨£ç‡
 - å‘é‡æ›´æ–°ç­–ç•¥: åŠ æ¬Šç§»å‹•å¹³å‡ï¼Œä¿æŒè²ç´‹å‘é‡ç©©å®šæ€§

æ›´æ–°æ­·ç¨‹ï¼š
-----------
 - v5.1.2 (2025-05-06): æ–°å¢å¤šè²ç´‹æ˜ å°„åŠŸèƒ½ã€æ”¯æ´å¤–éƒ¨å‚³å…¥æ™‚é–“æˆ³è¨˜ã€å„ªåŒ–ä½¿ç”¨é«”é©—

ä½¿ç”¨æ–¹å¼ï¼š
-----------
 1. å–®æª”æ¡ˆè¾¨è­˜:
    ```python
    identifier = SpeakerIdentifier()
    identifier.process_audio_file("path/to/audio.wav")
    ```

 2. æ•´å€‹ç›®éŒ„æª”æ¡ˆè¾¨è­˜:
    ```python
    identifier = SpeakerIdentifier()
    identifier.process_audio_directory("path/to/directory")
    ```

 3. å–®å€‹éŸ³è¨Šæµè¾¨è­˜:
    ```python
    identifier = SpeakerIdentifier()
    identifier.process_audio_stream(stream)
    ```

 4. æ·»åŠ éŸ³æª”åˆ°æŒ‡å®šèªè€…:
    ```python
    identifier = SpeakerIdentifier()
    identifier.add_voiceprint_to_speaker("path/to/audio.wav", "speaker_uuid")
    ```

 5. ä½¿ç”¨speaker_system_v2.pyé€²è¡Œèªè€…è­˜åˆ¥æ¨¡çµ„å‘¼å«

é–¾å€¼åƒæ•¸è¨­å®šï¼š
-----------
 - THRESHOLD_LOW = 0.09: éæ–¼ç›¸ä¼¼ï¼Œä¸æ›´æ–°å‘é‡
 - THRESHOLD_UPDATE = 0.27: ä¸‹:æ›´æ–°è²ç´‹å‘é‡ï¼Œä¸Š:æ–°å¢ä¸€ç­†è²ç´‹åˆ°èªè€…
 - THRESHOLD_NEW = 0.38: è¶…éæ­¤å€¼è¦–ç‚ºæ–°èªè€…

å‰ç½®éœ€æ±‚ï¼š
-----------
 - Python 3.9+
 - SpeechBrain
 - Weaviate å‘é‡è³‡æ–™åº« (éœ€é€šé Docker å•Ÿå‹•)
 - NumPy, PyTorch, SoundFile ç­‰ç›¸é—œè™•ç†å¥—ä»¶

æ³¨æ„äº‹é …ï¼š
-----------
 - ä½¿ç”¨å‰è«‹ç¢ºä¿ Weaviate å·²å•Ÿå‹•ä¸¦åˆå§‹åŒ–å¿…è¦é›†åˆ
 - å»ºè­°è™•ç† 16kHz å–æ¨£ç‡çš„éŸ³æª”ä»¥ç²å¾—æœ€ä½³è­˜åˆ¥æ•ˆæœ
 - å°æ–¼æ‰¹é‡è™•ç†ï¼Œå¯èª¿æ•´é–¾å€¼ä»¥ç¬¦åˆä¸åŒæ‡‰ç”¨å ´æ™¯

è©³ç´°è³‡è¨Šï¼š
-----------
è«‹åƒè€ƒå°ˆæ¡ˆæ–‡ä»¶: https://github.com/LCY000/ProjectStudy_SpeechRecognition

===============================================================================
"""

import os
import re
import sys
import uuid
import numpy as np
import torch
import soundfile as sf
from scipy.spatial.distance import cosine
from scipy.signal import resample_poly
import warnings
import logging
from datetime import datetime, timedelta, timezone
from typing import Tuple, List, Dict, Optional, Union, Any
import weaviate  # type: ignore
from weaviate.classes.query import MetadataQuery, Filter # type: ignore
from weaviate.classes.query import QueryReference # type: ignore
from contextvars import ContextVar
from itertools import count
from utils.path_utils import format_process_prefix

# æ§åˆ¶è¼¸å‡ºçš„å…¨å±€è®Šæ•¸
_ENABLE_OUTPUT =True  # é è¨­ç‚º Trueï¼Œå³è¼¸å‡ºè©³ç´°è¨Šæ¯
# ç”¨æ–¼æ¨™è¨˜æ¯æ¬¡è™•ç†æµç¨‹çš„å‰ç¶´
_current_process_prefix: ContextVar[str] = ContextVar("current_process_prefix", default="")
_process_counter = count(1)

# ä¿å­˜åŸå§‹ print å‡½æ•¸çš„å¼•ç”¨
original_print = print

# è¼¸å‡ºæ§åˆ¶å‡½æ•¸ - æ›´æ–°ç‚ºä½¿ç”¨æ—¥èªŒç³»çµ±
def _print(*args, **kwargs) -> None:
    """
    å—æ§è¼¸å‡ºå‡½æ•¸ï¼Œä½¿ç”¨æ—¥èªŒç³»çµ±è¼¸å‡º
    
    Args:
        *args: print å‡½æ•¸çš„ä½ç½®åƒæ•¸
        **kwargs: print å‡½æ•¸çš„é—œéµå­—åƒæ•¸
    """
    # å°å…¥ logger å¯èƒ½åœ¨å‡½æ•¸ç¬¬ä¸€æ¬¡èª¿ç”¨æ™‚å°šæœªå®šç¾©
    # å› æ­¤åœ¨é€™è£¡åšä¸€å€‹æª¢æŸ¥å’Œé»˜èªå€¼è™•ç†
    global logger
    if 'logger' not in globals() or logger is None:
        logger = get_logger(__name__)
        
    if _ENABLE_OUTPUT:
        # å°‡å¤šå€‹åƒæ•¸è½‰æ›ç‚ºå–®å€‹å­—ç¬¦ä¸²
        message = " ".join(str(arg) for arg in args)
        prefix = _current_process_prefix.get()
        if prefix:
            message = f"{prefix} {message}"
        logger.info(message)
        # ç§»é™¤é‡è¤‡çš„ print è¼¸å‡ºï¼Œåªä½¿ç”¨ logger

# è¨­ç½®è¼¸å‡ºé–‹é—œçš„å‡½æ•¸
def set_output_enabled(enable: bool) -> None:
    """
    è¨­ç½®æ˜¯å¦å•Ÿç”¨æ¨¡çµ„çš„è¼¸å‡º
    
    Args:
        enable: True è¡¨ç¤ºå•Ÿç”¨è¼¸å‡ºï¼ŒFalse è¡¨ç¤ºç¦ç”¨è¼¸å‡º
    """
    global _ENABLE_OUTPUT
    old_value = _ENABLE_OUTPUT
    _ENABLE_OUTPUT = enable
    
    if enable and not old_value:
        logger.info("å·²å•Ÿç”¨ main_identify_v5 æ¨¡çµ„çš„è¼¸å‡º")
    elif not enable and old_value:
        logger.info("å·²ç¦ç”¨ main_identify_v5 æ¨¡çµ„çš„è¼¸å‡º")

# æ›¿æ›åŸå§‹ print å‡½æ•¸ï¼Œä»¥å¯¦ç¾æ§åˆ¶è¼¸å‡º
print = _print  # æ›¿æ›å…¨å±€ print å‡½æ•¸ï¼Œä½¿æ¨¡çµ„ä¸­çš„æ‰€æœ‰ print èª¿ç”¨éƒ½ç¶“éæ§åˆ¶

# è¨­å®š httpx çš„æ—¥èªŒå±¤ç´šç‚º WARNING æˆ–æ›´é«˜ï¼Œä»¥é—œé–‰ INFO å±¤ç´šçš„ HTTP è«‹æ±‚æ—¥èªŒ
logging.getLogger("httpx").setLevel(logging.WARNING)

# æ–°å¢æ™‚å€è™•ç†å‡½æ•¸
def format_rfc3339(dt: Optional[datetime] = None) -> str:
    """
    å°‡æ—¥æœŸæ™‚é–“æ ¼å¼åŒ–ç‚ºç¬¦åˆ RFC3339 æ¨™æº–çš„å­—ä¸²ï¼ŒåŒ…å«æ™‚å€ä¿¡æ¯
    
    Args:
        dt: è¦æ ¼å¼åŒ–çš„ datetime å°è±¡ï¼Œè‹¥ç‚º None å‰‡ä½¿ç”¨ç•¶å‰æ™‚é–“
        
    Returns:
        str: RFC3339 æ ¼å¼çš„æ—¥æœŸæ™‚é–“å­—ä¸²
    """
    taipei_tz = timezone(timedelta(hours=8))  # å°åŒ—æ˜¯ UTC+8

    if dt is None:
        dt = datetime.now(taipei_tz)
    elif dt.tzinfo is None:
        # è‹¥æ²’æœ‰æ™‚å€ä¿¡æ¯ï¼Œå‰‡å‡è¨­ç‚ºå°åŒ—æ™‚å€
        dt = dt.replace(tzinfo=taipei_tz)
    
    # æ ¼å¼åŒ–ç‚º RFC3339 æ ¼å¼
    return dt.isoformat()

# éš±è—å¤šé¤˜çš„è­¦å‘Šèˆ‡æ—¥èªŒ
warnings.filterwarnings("ignore")
logging.getLogger("speechbrain").setLevel(logging.ERROR)

# å°å…¥æ—¥èªŒæ¨¡çµ„
from utils.logger import get_logger
from utils.env_config import WEAVIATE_HOST, WEAVIATE_PORT, get_model_save_dir, HF_ACCESS_TOKEN
from utils.constants import (
    THRESHOLD_LOW, THRESHOLD_UPDATE, THRESHOLD_NEW, 
    SPEECHBRAIN_SPEAKER_MODEL, PYANNOTE_SPEAKER_MODEL, AUDIO_TARGET_RATE,
    ENABLE_AS_NORM, AS_NORM_COHORT_SIZE, AS_NORM_TOP_K, AS_NORM_ALPHA,
    ENABLE_T_NORM, ENABLE_Z_NORM, ENABLE_S_NORM
)

# å‰µå»ºæ¨¡çµ„å°ˆå±¬æ—¥èªŒå™¨
logger = get_logger(__name__)

# è¼‰å…¥ SpeechBrain èªéŸ³è¾¨è­˜æ¨¡å‹
from speechbrain.inference import SpeakerRecognition

# å°å…¥ AS-Norm è™•ç†å™¨
from modules.database.cohort_manager import ASNormProcessor

# å…¨åŸŸåƒæ•¸è¨­å®šï¼ˆå¾ç’°å¢ƒé…ç½®è¼‰å…¥ï¼‰
DEFAULT_SPEAKER_NAME = "æœªå‘½åèªè€…"  # é è¨­çš„èªè€…åç¨±
DEFAULT_FULL_NAME_PREFIX = "n"  # V2ç‰ˆæœ¬ï¼šé è¨­full_nameå‰ç¶´


class AudioProcessor:
    """éŸ³è¨Šè™•ç†é¡åˆ¥ï¼Œè² è²¬éŸ³è¨Šè™•ç†å’ŒåµŒå…¥å‘é‡æå–"""

    def __init__(self) -> None:
        """
        åˆå§‹åŒ–æ¨¡å‹
        æƒ³åˆ‡æ›æ¨¡å‹æ™‚ï¼Œç›´æ¥æ”¹ä¸‹é¢çš„ self.model_type
        å¯é¸å€¼: "speechbrain" æˆ– "pyannote"
        """
        # ====== é€™è£¡æ”¹æ¨¡å‹é¡å‹ ======
        self.model_type = "pyannote"
        # =========================

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        if self.model_type == "speechbrain":
            from speechbrain.inference import SpeakerRecognition
            self.model = SpeakerRecognition.from_hparams(
                source=SPEECHBRAIN_SPEAKER_MODEL,
                savedir=get_model_save_dir("speechbrain_recognition")
            )
            logger.info("å·²è¼‰å…¥ SpeechBrain ECAPA-TDNN æ¨¡å‹")

        elif self.model_type == "pyannote":
            from pyannote.audio import Inference
            from pyannote.core import Segment
            # âš ï¸ .env æª”æ¡ˆä¸­å¿…é ˆè¨­å®š HF_ACCESS_TOKEN
            hf_token = HF_ACCESS_TOKEN
            
            # ä½¿ç”¨æ•´å€‹éŸ³é »æ¨¡å¼
            self.model = Inference(
                PYANNOTE_SPEAKER_MODEL, 
                window="whole", 
                use_auth_token=hf_token
            )
            logger.info(f"å·²è¼‰å…¥ pyannote/embedding æ¨¡å‹ ")
            
            self.Segment = Segment  # ä¿å­˜ Segment é¡åˆ¥ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨

        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {self.model_type}")

    def resample_audio(self, signal: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """ä½¿ç”¨ scipy é€²è¡Œé«˜å“è³ªé‡æ–°æ¡æ¨£"""
        return resample_poly(signal, target_sr, orig_sr)

    def extract_embedding_from_stream(self, signal: np.ndarray, sr: int) -> np.ndarray:
        """å¾éŸ³è¨Šæµæå–åµŒå…¥å‘é‡"""
        try:
            if not isinstance(signal, np.ndarray):
                signal = np.array(signal)
            if signal.ndim > 1:
                signal = signal.mean(axis=1)

            target_sr = AUDIO_TARGET_RATE
            if sr != target_sr:
                signal = self.resample_audio(signal, sr, target_sr)

            signal_tensor = torch.tensor(signal, dtype=torch.float32).unsqueeze(0).to(self.device)

            if self.model_type == "speechbrain":
                embedding = self.model.encode_batch(signal_tensor).squeeze().cpu().numpy()

            elif self.model_type == "pyannote":
                # pyannote çš„ Inference éœ€è¦å¾æ–‡ä»¶ä¸­è®€å–ï¼Œæ‰€ä»¥æˆ‘å€‘éœ€è¦å‰µå»ºè‡¨æ™‚æ–‡ä»¶
                import tempfile
                import soundfile as sf
                
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_path = temp_file.name
                    # å°‡ä¿¡è™Ÿå¯«å…¥è‡¨æ™‚æ–‡ä»¶
                    sf.write(temp_path, signal, target_sr)
                
                try:
                    # æ•´å€‹éŸ³é »æ¨¡å¼ï¼šä½¿ç”¨ crop æ–¹æ³•
                    duration = len(signal) / target_sr
                    segment = self.Segment(0, duration)
                    embedding = self.model.crop(temp_path, segment)
                    embedding = embedding.squeeze()  # ç§»é™¤ç¬¬ä¸€ç¶­
                    embedding = embedding / np.linalg.norm(embedding)  # æ­£è¦åŒ–
                finally:
                    # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                    import os
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)

            return embedding

        except Exception as e:
            logger.error(f"æå–åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise

    
    def resample_audio(self, signal: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """
        ä½¿ç”¨ scipy é€²è¡Œé«˜å“è³ªé‡æ–°æ¡æ¨£
        
        Args:
            signal: åŸå§‹éŸ³è¨Šä¿¡è™Ÿ
            orig_sr: åŸå§‹å–æ¨£ç‡
            target_sr: ç›®æ¨™å–æ¨£ç‡
            
        Returns:
            np.ndarray: é‡æ–°æ¡æ¨£å¾Œçš„éŸ³è¨Šä¿¡è™Ÿ
        """
        return resample_poly(signal, target_sr, orig_sr)
    
    def extract_embedding(self, audio_path: str) -> np.ndarray:
        """
        æå–éŸ³æª”çš„åµŒå…¥å‘é‡ï¼Œæ ¹æ“šéŸ³æª”å–æ¨£ç‡æ™ºèƒ½è™•ç†

        Args:
            audio_path: éŸ³æª”è·¯å¾‘

        Returns:
            np.ndarray: éŸ³æª”çš„åµŒå…¥å‘é‡

        è™•ç†æµç¨‹:
            1. è‹¥éŸ³æª”ç‚º 16kHzï¼Œå‰‡ç›´æ¥ä½¿ç”¨
            2. è‹¥éŸ³æª”ç‚º 8kHzï¼Œå‰‡ç›´æ¥å‡é »åˆ° 16kHz
            3. è‹¥éŸ³æª”å–æ¨£ç‡é«˜æ–¼ 16kHzï¼Œå‰‡é™é »åˆ° 16kHz
            4. å…¶ä»–å–æ¨£ç‡ï¼Œå‰‡é‡æ–°æ¡æ¨£åˆ° 16kHz
        """
        try:
            # å°æ–¼ pyannote æ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶è·¯å¾‘æ›´é«˜æ•ˆ
            if self.model_type == "pyannote":
                # ç²å–éŸ³é »æ–‡ä»¶ä¿¡æ¯
                signal, sr = sf.read(audio_path)
                
                # è™•ç†ç«‹é«”è²è½‰å–®è²é“ä¸¦é‡æ¡æ¨£ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if signal.ndim > 1:
                    signal = signal.mean(axis=1)
                
                target_sr = AUDIO_TARGET_RATE
                if sr != target_sr:
                    signal = self.resample_audio(signal, sr, target_sr)
                    
                    # å‰µå»ºé‡æ¡æ¨£å¾Œçš„è‡¨æ™‚æ–‡ä»¶
                    import tempfile
                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                        temp_path = temp_file.name
                        sf.write(temp_path, signal, target_sr)
                    
                    try:
                        # æ•´å€‹éŸ³é »æ¨¡å¼ï¼šä½¿ç”¨ crop æ–¹æ³•
                        duration = len(signal) / target_sr
                        segment = self.Segment(0, duration)
                        embedding = self.model.crop(temp_path, segment)
                        embedding = embedding.squeeze()
                        embedding = embedding / np.linalg.norm(embedding)
                    finally:
                        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                        import os
                        if os.path.exists(temp_path):
                            os.unlink(temp_path)
                else:
                    # å¦‚æœå–æ¨£ç‡å·²ç¶“æ­£ç¢ºï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶
                    # æ•´å€‹éŸ³é »æ¨¡å¼ï¼šä½¿ç”¨ crop æ–¹æ³•
                    duration = len(signal) / sr
                    segment = self.Segment(0, duration)
                    embedding = self.model.crop(audio_path, segment)
                    embedding = embedding.squeeze()
                    embedding = embedding / np.linalg.norm(embedding)
                
                return embedding
            
            else:
                # å°æ–¼å…¶ä»–æ¨¡å‹ï¼ˆå¦‚ speechbrainï¼‰ï¼Œä½¿ç”¨åŸæœ‰çš„æµç¨‹
                signal, sr = sf.read(audio_path)

                # è™•ç†ç«‹é«”è²è½‰å–®è²é“
                if signal.ndim > 1:
                    signal = signal.mean(axis=1)

                # ä½¿ç”¨æ–°çš„ stream æ–¹æ³•è™•ç†æ ¸å¿ƒé‚è¼¯
                return self.extract_embedding_from_stream(signal, sr)

        except Exception as e:
            logger.error(f"å¾æª”æ¡ˆæå–åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise


# ==================== AS-Norm å·¥å…·å‡½æ•¸ ====================

def apply_as_norm_to_distances(test_embedding: np.ndarray, 
                              distance_results: List[Tuple[str, str, float, int]],
                              as_norm_processor) -> List[Tuple[str, str, float, int]]:
    """
    å°è·é›¢çµæœæ‡‰ç”¨ AS-Norm æ­£è¦åŒ–
    
    é€™æ˜¯ä¸€å€‹ä¾¿åˆ©å‡½æ•¸ï¼Œç”¨æ–¼æ‰¹é‡è™•ç†å¤šå€‹èªè€…çš„è·é›¢è¨ˆç®—
    
    Args:
        test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
        distance_results: åŸå§‹è·é›¢çµæœåˆ—è¡¨ [(voice_print_id, speaker_name, distance, update_count)]
        as_norm_processor: AS-Norm è™•ç†å™¨å¯¦ä¾‹
        
    Returns:
        List[Tuple[str, str, float, int]]: æ­£è¦åŒ–å¾Œçš„è·é›¢çµæœ
    """
    if not ENABLE_AS_NORM or not distance_results:
        return distance_results
        
    normalized_results = []
    
    for voice_print_id, speaker_name, original_distance, update_count in distance_results:
        try:
            # ç²å–ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡
            voice_print_collection = as_norm_processor.client.collections.get("VoicePrint")
            target_obj = voice_print_collection.query.fetch_object_by_id(
                uuid=voice_print_id,
                include_vector=True
            )
            
            if target_obj and target_obj.vector:
                # è™•ç† named vector
                vec_dict = target_obj.vector
                raw_vec = vec_dict["default"] if isinstance(vec_dict, dict) else vec_dict
                target_embedding = np.array(raw_vec, dtype=float)
                
                # æ‡‰ç”¨ AS-Norm
                normalized_distance = as_norm_processor.apply_as_norm(
                    test_embedding, target_embedding, speaker_name
                )
                
                normalized_results.append((voice_print_id, speaker_name, normalized_distance, update_count))
            else:
                # ç„¡æ³•ç²å–åµŒå…¥å‘é‡æ™‚ï¼Œä¿æŒåŸå§‹è·é›¢
                normalized_results.append((voice_print_id, speaker_name, original_distance, update_count))
                
        except Exception as e:
            logger.warning(f"å°èªè€… {speaker_name} æ‡‰ç”¨ AS-Norm æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # ç™¼ç”ŸéŒ¯èª¤æ™‚ä¿æŒåŸå§‹è·é›¢
            normalized_results.append((voice_print_id, speaker_name, original_distance, update_count))
            
    return normalized_results


# ==================== AS-Norm åŠŸèƒ½çµæŸ ====================


class WeaviateRepository:
    """Weaviate è³‡æ–™å­˜å–åº«é¡åˆ¥ï¼Œè² è²¬èˆ‡ Weaviate V2 è³‡æ–™åº«çš„äº¤äº’"""
    
    def __init__(self) -> None:
        """åˆå§‹åŒ– Weaviate é€£æ¥ï¼ˆV2ç‰ˆæœ¬ï¼‰"""
        try:
            self.client = weaviate.connect_to_local()
            logger.info("æˆåŠŸé€£æ¥åˆ° Weaviate V2 è³‡æ–™åº«ï¼")
            
            # æª¢æŸ¥å¿…è¦çš„V2é›†åˆæ˜¯å¦å­˜åœ¨
            if not self.client.collections.exists("VoicePrint") or not self.client.collections.exists("Speaker"):
                logger.warning("è­¦å‘Šï¼šWeaviate ä¸­ç¼ºå°‘å¿…è¦çš„V2é›†åˆ (VoicePrint / Speaker)!")
                logger.info("è«‹å…ˆé‹è¡Œ modules/database/init_v2_collections.py å»ºç«‹æ‰€éœ€çš„V2é›†åˆ")
                logger.info("æ­£åœ¨å˜—è©¦è‡ªå‹•åˆå§‹åŒ–V2é›†åˆ...")
                
                # å˜—è©¦è‡ªå‹•åˆå§‹åŒ–V2é›†åˆ
                try:
                    from modules.database.init_v2_collections import ensure_weaviate_collections
                    if ensure_weaviate_collections():
                        logger.info("âœ… å·²è‡ªå‹•åˆå§‹åŒ–V2é›†åˆï¼")
                    else:
                        logger.error("âŒ è‡ªå‹•åˆå§‹åŒ–V2é›†åˆå¤±æ•—ï¼")
                        raise RuntimeError("ç„¡æ³•åˆå§‹åŒ–V2é›†åˆ")
                except ImportError:
                    logger.error("ç„¡æ³•å°å…¥V2é›†åˆåˆå§‹åŒ–æ¨¡çµ„")
                    logger.info("ä½¿ç”¨å‘½ä»¤ 'python -m modules.database.init_v2_collections' æ‰‹å‹•åˆå§‹åŒ–V2é›†åˆ")
                    raise
        
        except Exception as e:
            logger.error(f"ç„¡æ³•é€£æ¥åˆ° Weaviate V2 è³‡æ–™åº«ï¼š{e}")
            logger.info("è«‹ç¢ºèªï¼š")
            logger.info("1. Docker æœå‹™æ˜¯å¦æ­£åœ¨é‹è¡Œ")
            logger.info("2. Weaviate å®¹å™¨æ˜¯å¦å·²ç¶“å•Ÿå‹•")
            logger.info("3. weaviate_study/docker-compose.yml ä¸­çš„é…ç½®æ˜¯å¦æ­£ç¢º")
            logger.info("ä½¿ç”¨å‘½ä»¤ 'docker-compose -f weaviate_study/docker-compose.yml up -d' å•Ÿå‹• Weaviate")
            raise
    
    def compare_embedding(self, new_embedding: np.ndarray, as_norm_processor=None) -> Tuple[Optional[str], Optional[str], float, List[Tuple[str, str, float, int]]]:
        """
        æ¯”è¼ƒæ–°çš„åµŒå…¥å‘é‡èˆ‡è³‡æ–™åº«ä¸­æ‰€æœ‰ç¾æœ‰åµŒå…¥å‘é‡çš„ç›¸ä¼¼åº¦
        
        Args:
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            as_norm_processor: AS-Norm è™•ç†å™¨ï¼Œå¯é¸
            
        Returns:
            tuple: (æœ€ä½³åŒ¹é…ID, æœ€ä½³åŒ¹é…èªè€…åç¨±, æœ€å°è·é›¢, æ‰€æœ‰è·é›¢åˆ—è¡¨)
        """
        try:
            voice_print_collection = self.client.collections.get("VoicePrint")
            
            # è¨ˆç®—æ–°å‘é‡èˆ‡æ•¸æ“šåº«ä¸­æ‰€æœ‰å‘é‡çš„è·é›¢
            results = voice_print_collection.query.near_vector(
                near_vector=new_embedding.tolist(),
                limit=3,  # æ¸¬è©¦! è¿”å›å‰ 3 å€‹æœ€ç›¸ä¼¼çš„çµæœ
                return_properties=["speaker_name", "update_count", "sample_count", "created_at", "updated_at"],  # V2å±¬æ€§
                return_metadata=MetadataQuery(distance=True)
            )
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•çµæœ
            if not results.objects:
                logger.info("è³‡æ–™åº«ä¸­å°šç„¡ä»»ä½•åµŒå…¥å‘é‡")
                return None, None, float('inf'), []
            
            # è™•ç†çµæœï¼Œè¨ˆç®—è·é›¢
            distances = []
            for obj in results.objects:
                # è·é›¢ä¿¡æ¯å¯èƒ½åœ¨ä¸åŒä½ç½®ï¼Œæ ¹æ“šæ‚¨çš„ Weaviate ç‰ˆæœ¬é€²è¡Œé©é…
                distance = None
                if hasattr(obj, 'metadata') and hasattr(obj.metadata, 'distance'):
                    # v4 API
                    distance = obj.metadata.distance
                
                # è™•ç† distance å¯èƒ½æ˜¯ None çš„æƒ…æ³
                if distance is None:
                    distance = -1  # ä½¿ç”¨é è¨­å€¼
                    print(f"è­¦å‘Šï¼šç„¡æ³•å¾çµæœä¸­ç²å–è·é›¢ä¿¡æ¯ï¼Œä½¿ç”¨é è¨­å€¼ {distance}")
                
                object_id = str(obj.uuid)  # ç¢ºä¿ UUID æ˜¯å­—ç¬¦ä¸²æ ¼å¼
                speaker_name = obj.properties.get("speaker_name")
                update_count = obj.properties.get("update_count")  # æ¢å¾©ä½¿ç”¨update_count
                
                # ç§»é™¤é‡è¤‡çš„æ¯”å°è¼¸å‡ºï¼Œäº¤ç”±ä¸Šå±¤è™•ç†
                # distance_str = f"{distance:.4f}" if distance is not None else "æœªçŸ¥"
                # print(f"æ¯”å° - èªè€…: {speaker_name}, "
                #       f"æ›´æ–°æ¬¡æ•¸: {update_count}, é¤˜å¼¦è·é›¢: {distance_str}")
                
                # ä¿å­˜è·é›¢è³‡è¨Šï¼ˆä½¿ç”¨update_countä½œç‚ºç¬¬4å€‹åƒæ•¸ï¼‰
                distances.append((object_id, speaker_name, distance, update_count))
            
            # æ‡‰ç”¨ AS-Norm (å¦‚æœå•Ÿç”¨)
            if as_norm_processor and ENABLE_AS_NORM:
                print("ğŸ”§ æ‡‰ç”¨ AS-Norm æ­£è¦åŒ–...")
                distances = apply_as_norm_to_distances(new_embedding, distances, as_norm_processor)
                print("âœ… AS-Norm æ­£è¦åŒ–å®Œæˆ")
            
            # æ‰¾å‡ºæœ€å°è·é›¢
            if distances:
                best_match = min(distances, key=lambda x: x[2])
                best_id, best_name, best_distance, _ = best_match
                return best_id, best_name, best_distance, distances
            else:
                # å¦‚æœæ²’æœ‰æœ‰æ•ˆçš„è·é›¢ä¿¡æ¯ï¼Œè¿”å›ç©ºçµæœ
                print("è­¦å‘Šï¼šæœªèƒ½ç²å–æœ‰æ•ˆçš„è·é›¢ä¿¡æ¯")
                return None, None, float('inf'), []
            
        except Exception as e:
            print(f"æ¯”å°åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def update_embedding(self, voice_print_id: str, new_embedding: np.ndarray, update_count: int) -> int:
        """
        ä½¿ç”¨åŠ æ¬Šç§»å‹•å¹³å‡æ›´æ–°ç¾æœ‰çš„åµŒå…¥å‘é‡ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            voice_print_id: è¦æ›´æ–°çš„è²ç´‹å‘é‡ UUID
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            update_count: æ–°çš„æ›´æ–°æ¬¡æ•¸
            
        Returns:
            int: æ›´æ–°å¾Œçš„æ›´æ–°æ¬¡æ•¸
        """
        try:
            # ç²å–ç¾æœ‰çš„åµŒå…¥å‘é‡
            voice_print_collection = self.client.collections.get("VoicePrint")
            existing_object = voice_print_collection.query.fetch_object_by_id(
                uuid=voice_print_id,
                include_vector=True
            )
            
            if not existing_object:
                raise ValueError(f"æ‰¾ä¸åˆ° UUID ç‚º {voice_print_id} çš„è²ç´‹å‘é‡")
            
            # ç²å–ç¾æœ‰çš„åµŒå…¥å‘é‡            
            vec_dict = existing_object.vector   # å–å‡º Weaviate å›å‚³çš„ named vector
            raw_old = vec_dict["default"] if isinstance(vec_dict, dict) else vec_dict   # å¦‚æœæ˜¯ dictï¼Œå°±ç”¨ "default" é€™çµ„ï¼›å¦å‰‡ç›´æ¥ç•¶ list è™•ç†
            old_embedding = np.array(raw_old, dtype=float)
            
            # ä½¿ç”¨åŠ æ¬Šç§»å‹•å¹³å‡æ›´æ–°åµŒå…¥å‘é‡ï¼ˆåŸºæ–¼æ›´æ–°æ¬¡æ•¸ï¼‰
            weight_old = update_count - 1
            updated_embedding = (old_embedding * weight_old + new_embedding) / update_count
            new_update_count = update_count
            
            # æ›´æ–°æ•¸æ“šåº«ä¸­çš„å‘é‡ï¼ˆV2å±¬æ€§åç¨±ï¼‰
            voice_print_collection.data.update(
                uuid=voice_print_id,
                properties={
                    "updated_at": format_rfc3339(),  # V2: updated_at
                    "update_count": new_update_count  # ä½¿ç”¨update_count
                },
                vector=updated_embedding.tolist()
            )
            
            print(f"(æ›´æ–°) è²ç´‹UUID {voice_print_id} å·²æ›´æ–°ï¼Œæ–°çš„æ›´æ–°æ¬¡æ•¸: {new_update_count}")
            return new_update_count
            
        except Exception as e:
            print(f"æ›´æ–°åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def add_embedding_without_averaging(self, speaker_name: str, new_embedding: np.ndarray, speaker_id: Optional[str] = None) -> str:
        """
        ç‚ºç¾æœ‰èªè€…æ·»åŠ æ–°çš„åµŒå…¥å‘é‡ï¼ˆä¸é€²è¡ŒåŠ æ¬Šå¹³å‡ï¼‰ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            speaker_name: èªè€…åç¨±
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            speaker_id: ç¾æœ‰èªè€… UUIDï¼Œå¦‚æœç‚º None å‰‡å‰µå»ºæ–°èªè€…
            
        Returns:
            str: æ–°å»ºç«‹çš„è²ç´‹å‘é‡ UUID
        """
        try:
            # å¦‚æœæ²’æœ‰æä¾› speaker_idï¼Œå‰‡å‰µå»ºæ–°çš„èªè€…
            if not speaker_id:
                speaker_id = self.create_new_speaker(speaker_name)
            
            # æ·»åŠ æ–°çš„åµŒå…¥å‘é‡
            voice_print_collection = self.client.collections.get("VoicePrint")
            voice_print_uuid = str(uuid.uuid4())
            
            # å‰µå»ºæ–°çš„è²ç´‹å‘é‡ï¼ˆV2å±¬æ€§ï¼‰
            voice_print_collection.data.insert(
                properties={
                    "created_at": format_rfc3339(),  # V2: created_at
                    "updated_at": format_rfc3339(),  # V2: updated_at
                    "update_count": 1,
                    "sample_count": None,  # V2: sample_countï¼ˆé ç•™ï¼Œå¯ç‚ºç©ºå€¼ï¼‰
                    "quality_score": None,  # V2: quality_scoreï¼ˆé ç•™ï¼Œå¯ç‚ºç©ºå€¼ï¼‰
                    "speaker_name": speaker_name
                },
                uuid=voice_print_uuid,
                vector=new_embedding.tolist(),
                references={
                    "speaker": [speaker_id]
                }
            )
            
            print(f"(æ–°åµŒå…¥) ç‚ºèªè€… {speaker_name} æ·»åŠ äº†æ–°çš„è²ç´‹å‘é‡ (UUID: {voice_print_uuid})")
            return voice_print_uuid
            
        except Exception as e:
            print(f"æ·»åŠ åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def create_new_speaker(self, speaker_name: str = DEFAULT_SPEAKER_NAME, first_audio: Optional[str] = None) -> str:
        """
        å‰µå»ºæ–°çš„èªè€…ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            speaker_name: èªè€…åç¨±ï¼Œé»˜èªç‚ºã€Œæœªå‘½åèªè€…ã€
            first_audio: ç¬¬ä¸€æ¬¡ç”Ÿæˆè©²èªè€…æ™‚ä½¿ç”¨çš„éŸ³æª”è·¯å¾‘ï¼ˆå¦‚ "20250709_185516\\segment_001\\speaker1.wav"ï¼‰
            
        Returns:
            str: æ–°å»ºç«‹çš„èªè€… UUID
        """
        try:
            # å‰µå»ºæ–°çš„èªè€…
            speaker_collection = self.client.collections.get("Speaker")
            speaker_uuid = str(uuid.uuid4())
            
            # ç²å–ä¸‹ä¸€å€‹speaker_id
            speaker_id = self._get_next_speaker_id()
            
            # å¦‚æœæ˜¯é»˜èªåç¨±ï¼Œç”Ÿæˆå”¯ä¸€çš„åç¨± (é¡ä¼¼ n1, n2, ...)
            if speaker_name == DEFAULT_SPEAKER_NAME:
                speaker_name = f"{DEFAULT_FULL_NAME_PREFIX}{speaker_id}"
            
            # å‰µå»ºèªè€…ï¼ˆV2å±¬æ€§ï¼‰
            properties = {
                "speaker_id": speaker_id,  # V2: speaker_id (INT)
                "full_name": speaker_name,  # V2: full_name
                "nickname": None,  # V2: nicknameï¼ˆå¯ç‚ºç©ºå€¼ï¼‰
                "gender": None,  # V2: genderï¼ˆå¯ç‚ºç©ºå€¼ï¼‰
                "created_at": format_rfc3339(),  # V2: created_at
                "last_active_at": format_rfc3339(),  # V2: last_active_at
                "meet_count": None,  # V2: meet_countï¼ˆå¯ç‚ºç©ºå€¼ï¼‰
                "meet_days": None,  # V2: meet_daysï¼ˆå¯ç‚ºç©ºå€¼ï¼‰
                "voiceprint_ids": [],  # åˆå§‹æ™‚æ²’æœ‰è²ç´‹å‘é‡
                "first_audio": first_audio or ""  # V2: first_audio
            }
            
            speaker_collection.data.insert(
                properties=properties,
                uuid=speaker_uuid
            )
            
            print(f"(æ–°èªè€…) å»ºç«‹æ–°èªè€… {speaker_name} (UUID: {speaker_uuid}, ID: {speaker_id})")
            if first_audio:
                print(f"è¨­ç½®èªè€… {speaker_name} çš„ç¬¬ä¸€å€‹éŸ³æª”è·¯å¾‘: {first_audio}")
            
            return speaker_uuid
            
        except Exception as e:
            print(f"å‰µå»ºæ–°èªè€…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def _get_next_speaker_id(self) -> int:
        """
        ç²å–ä¸‹ä¸€å€‹å¯ç”¨çš„speaker_idï¼ˆå¾1é–‹å§‹ï¼‰
        
        Returns:
            int: ä¸‹ä¸€å€‹speaker_id
        """
        try:
            # ç²å–æ‰€æœ‰Speakerçš„speaker_id
            speaker_collection = self.client.collections.get("Speaker")
            results = speaker_collection.query.fetch_objects(
                return_properties=["speaker_id"],
                limit=1000  # å‡è¨­ä¸æœƒè¶…é1000å€‹èªè€…
            )
            
            # æå–æ‰€æœ‰ç¾æœ‰çš„speaker_id
            existing_ids = []
            for obj in results.objects:
                speaker_id = obj.properties.get("speaker_id")
                if speaker_id is not None:
                    existing_ids.append(speaker_id)
            
            # æ‰¾å‡ºä¸‹ä¸€å€‹å¯ç”¨çš„ID
            next_id = max(existing_ids) + 1 if existing_ids else 1
            return next_id
            
        except Exception as e:
            print(f"ç²å–ä¸‹ä¸€å€‹speaker_idæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            # ç™¼ç”ŸéŒ¯èª¤æ™‚è¿”å›ä¸€å€‹é»˜èªå€¼
            return 1
    
    def handle_new_speaker(self, new_embedding: np.ndarray, audio_source: str = "", create_time: Optional[datetime] = None, updated_time: Optional[datetime] = None) -> Tuple[str, str, str]:
        """
        è™•ç†å…¨æ–°çš„èªè€…ï¼šå‰µå»ºæ–°èªè€…å’ŒåµŒå…¥å‘é‡ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            audio_source: éŸ³è¨Šä¾†æºï¼Œä¾‹å¦‚æª”æ¡ˆåç¨±æˆ–è·¯å¾‘
            create_time: è‡ªè¨‚å‰µå»ºæ™‚é–“ï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨ç•¶å‰æ™‚é–“
            updated_time: è‡ªè¨‚æ›´æ–°æ™‚é–“ï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨ç•¶å‰æ™‚é–“
            
        Returns:
            tuple: (èªè€…UUID, è²ç´‹å‘é‡UUID, èªè€…åç¨±)
        """
        try:
            # å‰µå»ºæ–°çš„èªè€…ï¼Œå‚³å…¥éŸ³æª”è·¯å¾‘ä½œç‚º first_audio
            speaker_uuid = self.create_new_speaker(first_audio=audio_source)
            
            # ç²å–èªè€…åç¨±ï¼ˆV2ä½¿ç”¨full_nameï¼‰
            speaker_collection = self.client.collections.get("Speaker")
            speaker_obj = speaker_collection.query.fetch_object_by_id(
                uuid=speaker_uuid,
                return_properties=["full_name"]
            )
            
            if not speaker_obj:
                raise ValueError(f"æ‰¾ä¸åˆ°å‰›å‰›å‰µå»ºçš„èªè€… (UUID: {speaker_uuid})")
            
            speaker_name = speaker_obj.properties["full_name"]
            
            # å‰µå»ºæ–°çš„åµŒå…¥å‘é‡ï¼Œä¸¦èˆ‡èªè€…å»ºç«‹é—œè¯
            voice_print_collection = self.client.collections.get("VoicePrint")
            voice_print_uuid = str(uuid.uuid4())
            
            # æ ¼å¼åŒ–æ™‚é–“æˆ–ä½¿ç”¨ç•¶å‰æ™‚é–“
            create_time_str = format_rfc3339(create_time) if create_time else format_rfc3339()
            updated_time_str = format_rfc3339(updated_time) if updated_time else format_rfc3339()
            
            # å‰µå»ºè²ç´‹å‘é‡ï¼ˆV2å±¬æ€§ï¼‰
            voice_print_collection.data.insert(
                properties={
                    "created_at": create_time_str,  # V2: created_at
                    "updated_at": updated_time_str,  # V2: updated_at
                    "update_count": 1,
                    "sample_count": None,  # V2: sample_countï¼ˆé ç•™ï¼Œå¯ç‚ºç©ºå€¼ï¼‰
                    "quality_score": None,  # V2: quality_scoreï¼ˆé ç•™ï¼Œå¯ç‚ºç©ºå€¼ï¼‰
                    "speaker_name": speaker_name
                },
                uuid=voice_print_uuid,
                vector=new_embedding.tolist(),
                references={
                    "speaker": [speaker_uuid]
                }
            )
            
            # æ›´æ–°èªè€…çš„è²ç´‹å‘é‡åˆ—è¡¨
            speaker_collection.data.update(
                uuid=speaker_uuid,
                properties={
                    "voiceprint_ids": [voice_print_uuid],
                    "last_active_at": updated_time_str
                }
            )
            
            print(f"(æ–°èªè€…) å·²å»ºç«‹æ–°èªè€… {speaker_name} å’Œå°æ‡‰çš„è²ç´‹å‘é‡ (UUID: {voice_print_uuid})")
            return speaker_uuid, voice_print_uuid, speaker_name
            
        except Exception as e:
            print(f"è™•ç†æ–°èªè€…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def get_voice_print_properties(self, voice_print_uuid: str, properties: List[str]) -> Optional[Dict[str, Any]]:
        """
        ç²å–è²ç´‹å‘é‡çš„å±¬æ€§ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            voice_print_uuid: è²ç´‹å‘é‡ UUID
            properties: éœ€è¦ç²å–çš„å±¬æ€§åˆ—è¡¨
            
        Returns:
            Optional[Dict[str, Any]]: å±¬æ€§å­—å…¸ï¼Œè‹¥ä¸å­˜åœ¨å‰‡è¿”å› None
        """
        try:
            voice_print_collection = self.client.collections.get("VoicePrint")
            result = voice_print_collection.query.fetch_object_by_id(
                uuid=voice_print_uuid,
                return_properties=properties
            )
            
            if not result:
                return None
                
            return result.properties
            
        except Exception as e:
            print(f"ç²å–è²ç´‹å‘é‡å±¬æ€§æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def update_speaker_voice_prints(self, speaker_uuid: str, voice_print_uuid: str) -> bool:
        """
        æ›´æ–°èªè€…çš„è²ç´‹å‘é‡åˆ—è¡¨ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            speaker_uuid: èªè€… UUID
            voice_print_uuid: è¦æ·»åŠ çš„è²ç´‹å‘é‡ UUID
            
        Returns:
            bool: æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        try:
            speaker_collection = self.client.collections.get("Speaker")
            speaker_obj = speaker_collection.query.fetch_object_by_id(
                uuid=speaker_uuid,
                return_properties=["voiceprint_ids"]
            )
            
            if not speaker_obj:
                return False
                
            voiceprint_ids = speaker_obj.properties.get("voiceprint_ids", [])
            if voice_print_uuid not in voiceprint_ids:
                voiceprint_ids.append(voice_print_uuid)
                
                speaker_collection.data.update(
                    uuid=speaker_uuid,
                    properties={
                        "voiceprint_ids": voiceprint_ids,
                        "last_active_at": format_rfc3339()  # V2: last_active_at
                    }
                )
            
            return True
            
        except Exception as e:
            print(f"æ›´æ–°èªè€…è²ç´‹å‘é‡åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def close(self) -> None:
        """é—œé–‰ Weaviate é€£æ¥"""
        if hasattr(self, 'client'):
            self.client.close()
            print("å·²é—œé–‰ Weaviate é€£æ¥")


class SpeakerIdentifier:
    """
    èªè€…è­˜åˆ¥é¡ï¼Œè² è²¬æ ¸å¿ƒè­˜åˆ¥é‚è¼¯
    å¯¦ç¾å–®ä¾‹æ¨¡å¼ï¼Œé¿å…é‡è¤‡åˆå§‹åŒ–æ¨¡å‹å’Œè³‡æ–™åº«é€£æ¥
    """
    _instance = None
    _initialized = False
    
    def __new__(cls) -> 'SpeakerIdentifier':
        """å¯¦ç¾å–®ä¾‹æ¨¡å¼ï¼Œç¢ºä¿å…¨å±€åªæœ‰ä¸€å€‹å¯¦ä¾‹"""
        if cls._instance is None:
            cls._instance = super(SpeakerIdentifier, cls).__new__(cls)
        return cls._instance
    
    def __init__(self) -> None:
        """åˆå§‹åŒ–èªè€…è­˜åˆ¥å™¨ï¼Œè‹¥å·²åˆå§‹åŒ–å‰‡è·³é"""
        if SpeakerIdentifier._initialized:
            return
            
        self.audio_processor = AudioProcessor()
        self.database = WeaviateRepository()
        self.threshold_low = THRESHOLD_LOW
        self.threshold_update = THRESHOLD_UPDATE
        self.threshold_new = THRESHOLD_NEW
        
        # åªæœ‰åœ¨å•Ÿç”¨ AS-Norm æ™‚æ‰åˆå§‹åŒ–è™•ç†å™¨
        if ENABLE_AS_NORM:
            self.as_norm_processor = ASNormProcessor(self.database.client)
        else:
            self.as_norm_processor = None
        
        # è¨­ç½®æ—¥èªŒæ ¼å¼
        self.verbose = True  # æ§åˆ¶è©³ç´°è¼¸å‡º
        
        # è¼¸å‡º AS-Norm åˆå§‹åŒ–ç‹€æ…‹
        if ENABLE_AS_NORM:
            logger.info("ğŸ”§ AS-Norm æ­£è¦åŒ–åŠŸèƒ½å·²å•Ÿç”¨")
        else:
            logger.info("âšª AS-Norm æ­£è¦åŒ–åŠŸèƒ½å·²åœç”¨")
        
        SpeakerIdentifier._initialized = True
    
    def set_verbose(self, verbose: bool) -> None:
        """è¨­ç½®æ˜¯å¦é¡¯ç¤ºè©³ç´°è¼¸å‡º"""
        self.verbose = verbose
    
    def set_as_norm_enabled(self, enabled: bool) -> None:
        """
        è¨­ç½®æ˜¯å¦å•Ÿç”¨ AS-Norm åŠŸèƒ½
        
        Args:
            enabled: True å•Ÿç”¨ AS-Normï¼ŒFalse åœç”¨
        """
        global ENABLE_AS_NORM
        old_value = ENABLE_AS_NORM
        ENABLE_AS_NORM = enabled
        
        # å‹•æ…‹å‰µå»ºæˆ–éŠ·æ¯€ AS-Norm è™•ç†å™¨
        if enabled and self.as_norm_processor is None:
            # å•Ÿç”¨æ™‚å‰µå»ºè™•ç†å™¨
            self.as_norm_processor = ASNormProcessor(self.database.client)
        elif not enabled and self.as_norm_processor is not None:
            # åœç”¨æ™‚éŠ·æ¯€è™•ç†å™¨
            self.as_norm_processor = None
        
        if self.verbose:
            if enabled and not old_value:
                print("âœ… AS-Norm æ­£è¦åŒ–å·²å•Ÿç”¨")
            elif not enabled and old_value:
                print("âŒ AS-Norm æ­£è¦åŒ–å·²åœç”¨")
    
    def configure_as_norm(self, t_norm: bool = True, z_norm: bool = True, s_norm: bool = True,
                         cohort_size: int = 100, top_k: int = 10, alpha: float = 0.9) -> None:
        """
        é…ç½® AS-Norm åƒæ•¸
        
        Args:
            t_norm: æ˜¯å¦å•Ÿç”¨ T-Norm
            z_norm: æ˜¯å¦å•Ÿç”¨ Z-Norm
            s_norm: æ˜¯å¦å•Ÿç”¨ S-Norm
            cohort_size: cohort å¤§å°
            top_k: Top-K impostor åˆ†æ•¸
            alpha: S-Norm æ¬Šé‡åƒæ•¸
        """
        global ENABLE_T_NORM, ENABLE_Z_NORM, ENABLE_S_NORM
        global AS_NORM_COHORT_SIZE, AS_NORM_TOP_K, AS_NORM_ALPHA
        
        ENABLE_T_NORM = t_norm
        ENABLE_Z_NORM = z_norm
        ENABLE_S_NORM = s_norm
        AS_NORM_COHORT_SIZE = cohort_size
        AS_NORM_TOP_K = top_k
        AS_NORM_ALPHA = alpha
        
        # æ›´æ–° AS-Norm è™•ç†å™¨çš„åƒæ•¸ï¼ˆåªæœ‰åœ¨è™•ç†å™¨å­˜åœ¨æ™‚ï¼‰
        if self.as_norm_processor is not None:
            self.as_norm_processor.cohort_size = cohort_size
            self.as_norm_processor.top_k = top_k
            self.as_norm_processor.alpha = alpha
        
        if self.verbose:
            if self.as_norm_processor is not None:
                print(f"ğŸ”§ AS-Norm é…ç½®å·²æ›´æ–°:")
                print(f"   T-Norm: {t_norm}, Z-Norm: {z_norm}, S-Norm: {s_norm}")
                print(f"   Cohort Size: {cohort_size}, Top-K: {top_k}, Alpha: {alpha}")
            else:
                print("âš ï¸ AS-Norm è™•ç†å™¨æœªå•Ÿç”¨ï¼Œé…ç½®å·²ä¿å­˜ä½†æœªç”Ÿæ•ˆ")
    
    def get_as_norm_status(self) -> Dict[str, Any]:
        """
        ç²å– AS-Norm ç•¶å‰ç‹€æ…‹
        
        Returns:
            Dict[str, Any]: AS-Norm ç‹€æ…‹è³‡è¨Š
        """
        return {
            "enabled": ENABLE_AS_NORM,
            "processor_initialized": self.as_norm_processor is not None,
            "t_norm": ENABLE_T_NORM,
            "z_norm": ENABLE_Z_NORM,
            "s_norm": ENABLE_S_NORM,
            "cohort_size": AS_NORM_COHORT_SIZE,
            "top_k": AS_NORM_TOP_K,
            "alpha": AS_NORM_ALPHA
        }
    
    def _handle_very_similar(self, best_id: str, best_name: str, best_distance: float) -> Tuple[str, str, float]:
        """
        è™•ç†éæ–¼ç›¸ä¼¼çš„æƒ…æ³ï¼šä¸æ›´æ–°å‘é‡
        
        Args:
            best_id: æœ€ä½³åŒ¹é…ID
            best_name: æœ€ä½³åŒ¹é…èªè€…åç¨±
            best_distance: æœ€ä½³åŒ¹é…è·é›¢
            
        Returns:
            Tuple[str, str, float]: (èªè€…ID, èªè€…åç¨±, ç›¸ä¼¼åº¦)
        """
        if self.verbose:
            print(f"(è·³é) åµŒå…¥å‘é‡éæ–¼ç›¸ä¼¼ (è·é›¢ = {best_distance:.4f})ï¼Œä¸é€²è¡Œæ›´æ–°ã€‚")
            print(f"è©²éŸ³æª”èˆ‡èªè€… {best_name} çš„æª”æ¡ˆç›¸åŒã€‚")
        return best_id, best_name, best_distance
    
    def _handle_update_embedding(self, best_id: str, best_name: str, best_distance: float, new_embedding: np.ndarray) -> Tuple[str, str, float]:
        """
        è™•ç†éœ€è¦æ›´æ–°åµŒå…¥å‘é‡çš„æƒ…æ³ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            best_id: æœ€ä½³åŒ¹é…çš„è²ç´‹å‘é‡ UUID
            best_name: æœ€ä½³åŒ¹é…èªè€…åç¨±
            best_distance: æœ€ä½³åŒ¹é…è·é›¢
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            
        Returns:
            Tuple[str, str, float]: (èªè€…ID, èªè€…åç¨±, ç›¸ä¼¼åº¦)
        """
        try:
            # ç²å–ç•¶å‰æ›´æ–°æ¬¡æ•¸
            properties = self.database.get_voice_print_properties(best_id, ["update_count"])
            if properties is None:
                raise ValueError(f"ç„¡æ³•ç²å–è²ç´‹å‘é‡ UUID {best_id} çš„å±¬æ€§")
            
            update_count = properties.get("update_count", 0)
            new_update_count = update_count + 1  # æ–°æ›´æ–°æ¬¡æ•¸ = ç•¶å‰æ¬¡æ•¸ + 1
            
            # æ›´æ–°åµŒå…¥å‘é‡ï¼ˆå‚³éæ–°çš„æ›´æ–°æ¬¡æ•¸ï¼‰
            self.database.update_embedding(best_id, new_embedding, new_update_count)
            print(f"è©²éŸ³æª”èˆ‡èªè€… {best_name} ç›¸ç¬¦ï¼Œä¸”å·²æ›´æ–°åµŒå…¥æª”æ¡ˆã€‚")
            return best_id, best_name, best_distance
        except Exception as e:
            print(f"æ›´æ–°åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def _handle_new_speaker(self, new_embedding: np.ndarray, audio_source: str = "", timestamp: Optional[datetime] = None) -> Tuple[str, str, float]:
        """
        è™•ç†æ–°èªè€…çš„æƒ…æ³ï¼šå‰µå»ºæ–°èªè€…ï¼ˆV2ç‰ˆæœ¬ï¼‰
        
        Args:
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            audio_source: éŸ³è¨Šä¾†æºæè¿°
            timestamp: éŸ³è¨Šçš„æ™‚é–“æˆ³è¨˜ï¼Œç”¨æ–¼è¨­å®šè²ç´‹çš„å‰µå»ºæ™‚é–“å’Œæ›´æ–°æ™‚é–“
            
        Returns:
            Tuple[str, str, float]: (èªè€…UUID, èªè€…åç¨±, ç›¸ä¼¼åº¦)
        """
        speaker_id, voice_print_id, speaker_name = self.database.handle_new_speaker(
            new_embedding, audio_source, create_time=timestamp, updated_time=timestamp
        )
        return speaker_id, speaker_name, -1  # -1 è¡¨ç¤ºå…¨æ–°çš„èªè€…
    
    def _handle_add_new_voiceprint_to_speaker(self, best_id: str, best_name: str, best_distance: float, new_embedding: np.ndarray, audio_source: str = "", timestamp: Optional[datetime] = None) -> Tuple[str, str, float]:
        """
        è™•ç†ç›¸ä¼¼ä½†ä¸æ›´æ–°åŸæœ‰è²ç´‹çš„æƒ…æ³ï¼šç‚ºç¾æœ‰èªè€…æ–°å¢é¡å¤–çš„è²ç´‹å‘é‡
        
        æ­¤æ–¹æ³•æä¾›æ›´å®Œæ•´çš„å°è£ï¼Œå°‡æ–°åµŒå…¥å‘é‡æ·»åŠ åˆ°å·²åŒ¹é…çš„èªè€…ï¼Œä½†å»ºç«‹ç‚ºç¨ç«‹çš„è²ç´‹å‘é‡
        è€Œéæ›´æ–°ç¾æœ‰å‘é‡ã€‚é€™å…è¨±ä¸€å€‹èªè€…æ“æœ‰å¤šå€‹ä¸åŒç’°å¢ƒæˆ–æ¢ä»¶ä¸‹çš„è²ç´‹
        
        Args:
            best_id: æœ€ä½³åŒ¹é…çš„è²ç´‹å‘é‡ID
            best_name: æœ€ä½³åŒ¹é…èªè€…åç¨±
            best_distance: æœ€ä½³åŒ¹é…è·é›¢
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            audio_source: éŸ³è¨Šä¾†æºæè¿° (å¯é¸)
            timestamp: éŸ³è¨Šçš„æ™‚é–“æˆ³è¨˜ï¼Œç”¨æ–¼è¨­å®šè²ç´‹çš„å‰µå»ºèˆ‡æ›´æ–°æ™‚é–“ (å¯é¸)
            
        Returns:
            Tuple[str, str, float]: (èªè€…ID, èªè€…åç¨±, ç›¸ä¼¼åº¦)
        """
        try:
            # å¾è²ç´‹ç²å–æ‰€å±¬çš„èªè€…ID
            speaker_id = self._get_speaker_id_from_voiceprint(best_id)
            
            # ç‚ºæ­¤èªè€…æ–°å¢ä¸€å€‹æ–°çš„è²ç´‹å‘é‡
            voice_print_id = self._add_voiceprint_to_speaker(
                speaker_id=speaker_id,
                speaker_name=best_name,
                new_embedding=new_embedding,
                audio_source=audio_source,
                timestamp=timestamp
            )
            
            if self.verbose:
                print(f"(æ–°å¢è²ç´‹) å·²ç‚ºèªè€… {best_name} å»ºç«‹æ–°çš„è²ç´‹å‘é‡ (ID: {voice_print_id})")
                print(f"è©²éŸ³æª”èˆ‡èªè€… {best_name} ç›¸ä¼¼ä½†ä¸è¶³ä»¥æ›´æ–°åŸæœ‰è²ç´‹ï¼Œå·²å»ºç«‹æ–°çš„è²ç´‹ã€‚")
            
            return speaker_id, best_name, best_distance
            
        except Exception as e:
            print(f"æ–°å¢é¡å¤–è²ç´‹å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def _get_speaker_id_from_voiceprint(self, voice_print_id: str) -> str:
        """
        æ ¹æ“šè²ç´‹å‘é‡IDç²å–å°æ‡‰çš„èªè€…ID
        
        Args:
            voice_print_id: è²ç´‹å‘é‡ID
            
        Returns:
            str: èªè€…ID
            
        Raises:
            ValueError: ç•¶ç„¡æ³•ç²å–èªè€…IDæ™‚
        """
        try:
            voice_print_collection = self.database.client.collections.get("VoicePrint")
            # ä½¿ç”¨ QueryReference æŒ‡å®šè¦å›å‚³å“ªå€‹ reference å±¬æ€§ï¼Œä»¥åŠè¦å“ªäº›æ¬„ä½
            qr = QueryReference(
                link_on="speaker",            # reference æ¬„ä½åç¨±
                return_properties=["uuid"]    # è¦æŠŠ uuid å›å‚³ä¸‹ä¾†
            )
            # å‘¼å« fetch_object_by_idï¼Œå‚³å…¥ qr è€Œéå­—ä¸²åˆ—è¡¨
            voice_print_obj = voice_print_collection.query.fetch_object_by_id(
                uuid=voice_print_id,
                return_references=qr
            )
            # å¾å›å‚³çš„ references å–å‡ºç¬¬ä¸€å€‹ speaker çš„ uuid
            refs = voice_print_obj.references.get("speaker", []).objects
            if not refs:
                raise ValueError(f"è²ç´‹å‘é‡ {voice_print_id} æ²’æœ‰å°æ‡‰çš„èªè€…åƒè€ƒ")
            return str(refs[0].uuid)  # ç¢ºä¿è¿”å›å­—ç¬¦ä¸²è€Œé Weaviate UUID å°è±¡
        except Exception as e:
            print(f"ç²å–èªè€…IDæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def _add_voiceprint_to_speaker(self, speaker_id: str, speaker_name: str, new_embedding: np.ndarray, 
                                   audio_source: str = "", timestamp: Optional[datetime] = None) -> str:
        """
        ç‚ºæŒ‡å®šèªè€…æ·»åŠ æ–°çš„è²ç´‹å‘é‡
        
        Args:
            speaker_id: èªè€…ID
            speaker_name: èªè€…åç¨±
            new_embedding: æ–°çš„åµŒå…¥å‘é‡
            audio_source: éŸ³è¨Šä¾†æºæè¿° (å¯é¸)
            timestamp: æ™‚é–“æˆ³è¨˜ï¼Œç”¨æ–¼è¨­å®šå‰µå»ºèˆ‡æ›´æ–°æ™‚é–“ (å¯é¸)
            
        Returns:
            str: æ–°å»ºç«‹çš„è²ç´‹å‘é‡ID
        """
        try:
            # æ ¼å¼åŒ–æ™‚é–“æˆ–ä½¿ç”¨ç•¶å‰æ™‚é–“
            create_time_str = format_rfc3339(timestamp) if timestamp else format_rfc3339()
            
            # æ·»åŠ æ–°çš„åµŒå…¥å‘é‡åˆ°èªè€…
            voice_print_collection = self.database.client.collections.get("VoicePrint")
            voice_print_id = str(uuid.uuid4())
            
            # å‰µå»ºæ–°çš„è²ç´‹å‘é‡ï¼ˆV2ç‰ˆæœ¬ï¼‰
            voice_print_collection.data.insert(
                properties={
                    "created_at": create_time_str,    # V2: created_at
                    "updated_at": create_time_str,    # V2: updated_at  
                    "update_count": 1,                # update_countç”¨é€”ä¸è®Š
                    "sample_count": None,             # V2: sample_countï¼ˆé ç•™ï¼Œå¯ç‚ºç©ºå€¼ï¼‰
                    "quality_score": None,            # V2: quality_scoreï¼ˆé ç•™ï¼Œå¯ç‚ºç©ºå€¼ï¼‰
                    "speaker_name": speaker_name,
                    "audio_source": audio_source
                },
                uuid=voice_print_id,
                vector=new_embedding.tolist(),
                references={
                    "speaker": [speaker_id]
                }
            )
            
            # æ›´æ–°èªè€…çš„è²ç´‹å‘é‡åˆ—è¡¨ï¼ˆV2ç‰ˆæœ¬ä½¿ç”¨UUIDåƒæ•¸åç¨±ï¼‰
            self.database.update_speaker_voice_prints(speaker_id, voice_print_id)
            
            return voice_print_id
        except Exception as e:
            print(f"ç‚ºèªè€…æ·»åŠ è²ç´‹å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise

    # ç°¡åŒ–è¼¸å‡ºçš„æ§åˆ¶å‡½æ•¸
    def simplified_print(self, message: str, verbose: bool = True) -> None:
        """
        æ ¹æ“šè©³ç´°åº¦è¨­ç½®æ±ºå®šæ˜¯å¦è¼¸å‡ºè¨Šæ¯
        
        Args:
            message: è¦è¼¸å‡ºçš„è¨Šæ¯
            verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯ï¼Œé è¨­ç‚º True
        """
        if verbose:
            # ä½¿ç”¨å¸¶å‰ç¶´çš„ logger
            prefix = _current_process_prefix.get()
            message_with_prefix = f"{prefix} {message}" if prefix else message
            logger.info(message_with_prefix)

    # æ ¼å¼åŒ–è¼¸å‡ºæ¯”å°çµæœ
    def format_comparison_result(self, speaker_name: str, update_count: int, distance: float, verbose: bool = True) -> None:
        """
        æ ¼å¼åŒ–è¼¸å‡ºæ¯”å°çµæœ
        
        Args:
            speaker_name: èªè€…åç¨±
            update_count: æ›´æ–°æ¬¡æ•¸
            distance: ç›¸ä¼¼åº¦è·é›¢
            verbose: æ˜¯å¦è¼¸å‡ºè©³ç´°ä¿¡æ¯
        """
        if verbose:
            distance_str = f"{distance:.4f}" if distance is not None else "æœªçŸ¥"
            # ä½¿ç”¨å¸¶å‰ç¶´çš„ logger
            prefix = _current_process_prefix.get()
            message = f"æ¯”å° - èªè€…: {speaker_name}, æ›´æ–°æ¬¡æ•¸: {update_count}, é¤˜å¼¦è·é›¢: {distance_str}"
            message_with_prefix = f"{prefix} {message}" if prefix else message
            logger.info(message_with_prefix)

    # ä¿®æ”¹ SpeakerIdentifier é¡åˆ¥ä¸­çš„æ–¹æ³•ä¾†ä½¿ç”¨é€™äº›å‡½æ•¸
    def process_audio_file(self, audio_file: str) -> Optional[Tuple[str, str, float]]:
        """
        è™•ç†éŸ³æª”ä¸¦é€²è¡Œèªè€…è­˜åˆ¥
        
        Args:
            audio_file: éŸ³æª”è·¯å¾‘
            
        Returns:
            Optional[Tuple[str, str, float]]: (èªè€…ID, èªè€…åç¨±, ç›¸ä¼¼åº¦) æˆ– None è¡¨ç¤ºè™•ç†å¤±æ•—
        """
        token = None
        try:
            process_id = next(_process_counter)
            prefix = format_process_prefix(process_id, audio_file)
            token = _current_process_prefix.set(prefix)
            self.simplified_print(f"\nè™•ç†éŸ³æª”: {audio_file}", self.verbose)
            if not os.path.exists(audio_file):
                self.simplified_print(f"éŸ³æª” {audio_file} ä¸å­˜åœ¨ï¼Œå–æ¶ˆè™•ç†ã€‚", self.verbose)
                return None

            # è®€å–éŸ³æª”ç²å– signal å’Œ sr
            signal, sr = sf.read(audio_file)

            # ç›´æ¥ä½¿ç”¨å®Œæ•´è·¯å¾‘ï¼Œçµ±ä¸€è½‰æ›ç‚ºæ­£æ–œç·šæ ¼å¼
            audio_source = audio_file.replace('\\', '/')

            return self.process_audio_stream(signal, sr, audio_source=audio_source)

        except Exception as e:
            self.simplified_print(f"è™•ç†éŸ³æª” {audio_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", self.verbose)
            return None
        finally:
            if token:
                _current_process_prefix.reset(token)

    def process_audio_stream(self, signal: np.ndarray, sr: int, audio_source: str = "ç„¡", timestamp: Optional[datetime] = None) -> Optional[Tuple[str, str, float]]:
        """
        è™•ç†éŸ³è¨Šæµ (NumPy é™£åˆ—) ä¸¦é€²è¡Œèªè€…è­˜åˆ¥

        Args:
            signal: éŸ³è¨Šä¿¡è™Ÿ (NumPy é™£åˆ—)
            sr: éŸ³è¨Šä¿¡è™Ÿçš„å–æ¨£ç‡
            audio_source: éŸ³è¨Šä¾†æºçš„åç¨± (ç”¨æ–¼æœªä¾†å›æœ”éŸ³æª”)
            timestamp: éŸ³è¨Šçš„æ™‚é–“æˆ³è¨˜ï¼Œç”¨æ–¼è¨­å®šè²ç´‹çš„å‰µå»ºæ™‚é–“å’Œæ›´æ–°æ™‚é–“

        Returns:
            Optional[Tuple[str, str, float]]: (èªè€…ID, èªè€…åç¨±, ç›¸ä¼¼åº¦) æˆ– None è¡¨ç¤ºè™•ç†å¤±æ•—
        """
        token = None
        try:
            if not _current_process_prefix.get():
                process_id = next(_process_counter)
                prefix = format_process_prefix(process_id, audio_source)
                token = _current_process_prefix.set(prefix)
            self.simplified_print(f"\nè™•ç†ä¾†æº: {audio_source}", self.verbose)

            # æå–åµŒå…¥å‘é‡
            new_embedding = self.audio_processor.extract_embedding_from_stream(signal, sr)

            # èˆ‡ Weaviate ä¸­çš„åµŒå…¥å‘é‡æ¯”å°ï¼Œå‚³é AS-Norm è™•ç†å™¨
            best_id, best_name, best_distance, all_distances = self.database.compare_embedding(
                new_embedding, 
                as_norm_processor=self.as_norm_processor if ENABLE_AS_NORM else None
            )

            # è¼¸å‡ºæ¯”å°çµæœ
            if self.verbose and all_distances:
                for obj_id, name, distance, update_count in all_distances[:3]:  # åªé¡¯ç¤ºå‰3å€‹çµæœ
                    self.format_comparison_result(name, update_count, distance, self.verbose)

            # æ ¹æ“šè·é›¢é€²è¡Œåˆ¤æ–·ï¼Œä½¿ç”¨è¼”åŠ©å‡½æ•¸è™•ç†ä¸åŒæƒ…æ³
            if best_id is None:
                # è³‡æ–™åº«ç‚ºç©ºï¼Œç›´æ¥å‰µå»ºæ–°èªè€…
                self.simplified_print("è³‡æ–™åº«ç‚ºç©ºï¼Œå‰µå»ºæ–°èªè€…", self.verbose)
                # å‚³ééŸ³è¨Šä¾†æºåç¨±å’Œæ™‚é–“æˆ³è¨˜
                return self._handle_new_speaker(new_embedding, audio_source, timestamp)
            elif best_distance < self.threshold_low:
                # éæ–¼ç›¸ä¼¼ï¼Œä¸æ›´æ–°
                return self._handle_very_similar(best_id, best_name, best_distance)
            elif best_distance < self.threshold_update:
                # è·é›¢åœ¨å…è¨±çš„ç¯„åœå…§ï¼Œæ›´æ–°åµŒå…¥å‘é‡
                return self._handle_update_embedding(best_id, best_name, best_distance, new_embedding)
            elif best_distance < self.threshold_new:
                # è·é›¢åœ¨åŒ¹é…ç¯„åœå…§ï¼Œå»ºç«‹æ–°çš„è²ç´‹å‘é‡
                return self._handle_add_new_voiceprint_to_speaker(best_id, best_name, best_distance, new_embedding, audio_source, timestamp)
            else:
                # åˆ¤å®šç‚ºæ–°èªè€…
                # å‚³ééŸ³è¨Šä¾†æºåç¨±å’Œæ™‚é–“æˆ³è¨˜
                return self._handle_new_speaker(new_embedding, audio_source, timestamp)

        except Exception as e:
            self.simplified_print(f"è™•ç†éŸ³è¨Šæµ '{audio_source}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", self.verbose)
            return None
        finally:
            if token:
                _current_process_prefix.reset(token)

    def process_audio_directory(self, directory: str) -> Dict[str, Any]:
        """
        è™•ç†æŒ‡å®šè³‡æ–™å¤¾å…§æ‰€æœ‰ .wav æª”æ¡ˆ
        
        Args:
            directory: è³‡æ–™å¤¾è·¯å¾‘
            
        Returns:
            Dict[str, Any]: è™•ç†çµæœçµ±è¨ˆ
        """
        if not os.path.exists(directory):
            print(f"è³‡æ–™å¤¾ {directory} ä¸å­˜åœ¨ï¼Œå–æ¶ˆè™•ç†ã€‚")
            return {"success": False, "error": "è³‡æ–™å¤¾ä¸å­˜åœ¨"}
            
        audio_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(".wav")]
        if not audio_files:
            print(f"è³‡æ–™å¤¾ {directory} ä¸­æ²’æœ‰ .wav æª”æ¡ˆã€‚")
            return {"success": False, "error": "ç„¡éŸ³æª”"}
            
        print(f"ç™¼ç¾ {len(audio_files)} å€‹éŸ³æª”æ–¼ {directory}ï¼Œé–‹å§‹è™•ç†...")
        
        results = {
            "total": len(audio_files),
            "processed": 0,
            "failed": 0,
            "new_speakers": 0,
            "updated_speakers": 0,
            "matched_speakers": 0,
            "details": []
        }
        
        try:
            for audio_file in audio_files:
                try:
                    result = self.process_audio_file(audio_file)
                    results["processed"] += 1
                    
                    if result:
                        speaker_id, speaker_name, distance = result
                        results["details"].append({
                            "file": audio_file,
                            "speaker_id": speaker_id,
                            "speaker_name": speaker_name,
                            "distance": distance
                        })
                        
                        # è¨ˆç®—çµ±è¨ˆ
                        if distance == 1.0:
                            results["new_speakers"] += 1
                        elif distance < self.threshold_update:
                            results["updated_speakers"] += 1
                        else:
                            results["matched_speakers"] += 1
                        
                except Exception as e:
                    print(f"è™•ç† {audio_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    results["failed"] += 1
                    results["details"].append({
                        "file": audio_file,
                        "error": str(e)
                    })
        finally:
            # é—œé–‰ Weaviate é€£æ¥
            self.database.close()
                
        print(f"\nå®Œæˆè™•ç†è³‡æ–™å¤¾ {directory} ä¸­æ‰€æœ‰éŸ³æª”ã€‚")
        print(f"è™•ç†ç¸½æ•¸: {results['processed']}/{results['total']}, å¤±æ•—: {results['failed']}")
        print(f"æ–°å¢èªè€…: {results['new_speakers']}, æ›´æ–°èªè€…: {results['updated_speakers']}, åŒ¹é…èªè€…: {results['matched_speakers']}")
        
        return results
    
    def add_voiceprint_to_speaker(self, audio_file: str, speaker_id: str) -> bool:
        """
        å°‡éŸ³æª”è½‰æ›ç‚ºè²ç´‹å‘é‡ï¼Œä¸¦æ·»åŠ åˆ°æŒ‡å®šçš„èªè€…
        
        æ­¤æ–¹æ³•æä¾›ä¸€å€‹å…¬é–‹ä»‹é¢ï¼Œå…è¨±ç›´æ¥å¾éŸ³è¨Šæª”æ¡ˆç‚ºå·²çŸ¥èªè€…æ·»åŠ æ–°çš„è²ç´‹å‘é‡ï¼Œ
        è€Œä¸éœ€è¦é€²è¡Œèªè€…è­˜åˆ¥çš„æ¯”å°éç¨‹ã€‚é©ç”¨æ–¼å·²ç¢ºå®šèªè€…èº«ä»½çš„éŸ³æª”ã€‚
        
        Args:
            audio_file: éŸ³æª”è·¯å¾‘
            speaker_id: èªè€… ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            print(f"\næ·»åŠ éŸ³æª”è²ç´‹å‘é‡åˆ°èªè€… (ID: {speaker_id}): {audio_file}")
            if not os.path.exists(audio_file):
                print(f"éŸ³æª” {audio_file} ä¸å­˜åœ¨ï¼Œå–æ¶ˆè™•ç†ã€‚")
                return False
            
            # æª¢æŸ¥èªè€…æ˜¯å¦å­˜åœ¨ï¼ˆV2ç‰ˆæœ¬ä½¿ç”¨full_nameï¼‰
            speaker_collection = self.database.client.collections.get("Speaker")
            speaker_obj = speaker_collection.query.fetch_object_by_id(
                uuid=speaker_id,
                return_properties=["full_name"]
            )
            
            if not speaker_obj:
                print(f"èªè€… ID {speaker_id} ä¸å­˜åœ¨ï¼Œå–æ¶ˆè™•ç†ã€‚")
                return False
                
            speaker_name = speaker_obj.properties["full_name"]  # V2: ä½¿ç”¨ full_name
            
            # æå–åµŒå…¥å‘é‡
            new_embedding = self.audio_processor.extract_embedding(audio_file)
            
            # ä½¿ç”¨å…§éƒ¨æ–¹æ³•æ·»åŠ è²ç´‹å‘é‡
            voice_print_id = self._add_voiceprint_to_speaker(
                speaker_id=speaker_id,
                speaker_name=speaker_name,
                new_embedding=new_embedding,
                audio_source=os.path.basename(audio_file)
            )
            
            if voice_print_id:
                print(f"å·²æˆåŠŸå°‡éŸ³æª”è²ç´‹å‘é‡æ·»åŠ åˆ°èªè€… {speaker_name} (è²ç´‹ID: {voice_print_id})")
                return True
            return False
                
        except Exception as e:
            print(f"æ·»åŠ è²ç´‹å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False


if __name__ == "__main__":
    set_output_enabled(True)  # å•Ÿç”¨è¼¸å‡º

    # å‰µå»ºèªè€…è­˜åˆ¥å™¨
    identifier = SpeakerIdentifier()
    
    # ==================== AS-Norm ä½¿ç”¨ç¤ºä¾‹ ====================
    # å•Ÿç”¨ AS-Norm åŠŸèƒ½
    # identifier.set_as_norm_enabled(True)
    
    # è‡ªè¨‚ AS-Norm é…ç½®
    # identifier.configure_as_norm(
    #     t_norm=True,      # å•Ÿç”¨ T-Norm
    #     z_norm=True,      # å•Ÿç”¨ Z-Norm  
    #     s_norm=True,      # å•Ÿç”¨ S-Norm (çµåˆ T-Norm å’Œ Z-Norm)
    #     cohort_size=50,   # ä½¿ç”¨ 50 å€‹ impostor èªè€…
    #     top_k=10,         # ä½¿ç”¨å‰ 10 å€‹æœ€ç›¸ä¼¼çš„ impostor
    #     alpha=0.8         # S-Norm æ¬Šé‡åƒæ•¸
    # )
    
    # æŸ¥çœ‹ AS-Norm ç‹€æ…‹
    # as_norm_status = identifier.get_as_norm_status()
    # print("ğŸ” AS-Norm ç‹€æ…‹:", as_norm_status)
    
    # æ¸¬è©¦ä¸åŒçš„ AS-Norm çµ„åˆ
    # print("\nğŸ“Š æ¸¬è©¦å„ç¨® AS-Norm è¨­å®š...")
    
    # åƒ…ä½¿ç”¨ T-Norm
    # identifier.configure_as_norm(t_norm=True, z_norm=False, s_norm=False)
    # print("ğŸ”§ ç•¶å‰è¨­å®š: åƒ… T-Norm")
    # identifier.process_audio_file("16K-model/Audios-16K-IDTF/speaker1_20250501-22_49_13_1.wav")
    
    # åƒ…ä½¿ç”¨ Z-Norm
    # identifier.configure_as_norm(t_norm=False, z_norm=True, s_norm=False)  
    # print("ğŸ”§ ç•¶å‰è¨­å®š: åƒ… Z-Norm")
    # identifier.process_audio_file("16K-model/Audios-16K-IDTF/speaker1_20250501-22_49_13_1.wav")
    
    # ä½¿ç”¨å®Œæ•´ S-Norm
    # identifier.configure_as_norm(t_norm=True, z_norm=True, s_norm=True)
    # print("ğŸ”§ ç•¶å‰è¨­å®š: å®Œæ•´ S-Norm")
    # identifier.process_audio_file("16K-model/Audios-16K-IDTF/speaker1_20250501-22_49_13_1.wav")
    
    # ==================== ä¸€èˆ¬è­˜åˆ¥æ¸¬è©¦ ====================
    # ä¸»ç¨‹å¼åŸ·è¡Œ: è‹¥è¦è™•ç†å–®ä¸€æª”æ¡ˆæˆ–è³‡æ–™å¤¾ï¼Œå¯è§£é™¤ä¸‹åˆ—è¨»è§£

    # ç¯„ä¾‹ï¼šè™•ç†å–®ä¸€æª”æ¡ˆ (ç¾åœ¨æœƒé€é process_audio_stream)
    identifier.process_audio_file("16K-model/Audios-16K-IDTF/speaker1_20250501-22_49_13_1.wav")

    # ç¯„ä¾‹ï¼šç›´æ¥è™•ç†éŸ³è¨Šæµ (å‡è¨­ä½ æœ‰ NumPy é™£åˆ— signal å’Œå–æ¨£ç‡ sr)
    # try:
    #     # å‡è¨­é€™æ˜¯å¾æŸå€‹ä¾†æºå¾—åˆ°çš„éŸ³è¨Šæ•¸æ“šå’Œå–æ¨£ç‡
    #     # ä¾‹å¦‚ï¼šå¾éº¥å…‹é¢¨ã€ç¶²è·¯æµç­‰
    #     sample_signal, sample_sr = sf.read("16K-model/Audios-16K-IDTF/speaker2_20250501-22_49_13_1.wav") # åƒ…ç‚ºç¯„ä¾‹ï¼Œå¯¦éš›æ‡‰ä¾†è‡ªæµ
    #     identifier.process_audio_stream(sample_signal, sample_sr, source_description="ç¯„ä¾‹éŸ³è¨Šæµ")
    # except Exception as e:
    #     print(f"è™•ç†ç¯„ä¾‹éŸ³è¨Šæµæ™‚å‡ºéŒ¯: {e}")


    # identifier.process_audio_directory("testFiles/test_audioFile/0770")
    
    # å¦‚æœéœ€è¦å°‡éŸ³æª”æå–è²ç´‹ä¸¦æ·»åŠ åˆ°ç¾æœ‰èªè€…ï¼Œå¯è§£é™¤ä¸‹åˆ—è¨»è§£
    # identifier.add_voiceprint_to_speaker("path_to_audio.wav", "speaker_uuid")