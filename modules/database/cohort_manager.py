"""
===============================================================================
AS-Norm Cohort è³‡æ–™åº«ç®¡ç†æ¨¡çµ„
===============================================================================

ç‰ˆæœ¬ï¼šv1.0.0
ä½œè€…ï¼šCYouuu  
æœ€å¾Œæ›´æ–°ï¼š2025-08-25

åŠŸèƒ½æ‘˜è¦ï¼š
-----------
æœ¬æ¨¡çµ„æä¾› AS-Norm å°ˆç”¨çš„ cohort è³‡æ–™åº«ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

1. Cohort Collection çš„å»ºç«‹èˆ‡ç®¡ç†
2. éŸ³é »æª”æ¡ˆæ‰¹é‡è™•ç†èˆ‡è²ç´‹æå–
3. Cohort è³‡æ–™çš„å°å…¥èˆ‡æ›´æ–°
4. è³‡æ–™åº«åˆå§‹åŒ–èˆ‡é‡ç½®åŠŸèƒ½

è¨­è¨ˆåŸå‰‡ï¼š
-----------
- éš”é›¢æ€§ï¼šcohort è³‡æ–™èˆ‡å¯¦éš›èªè€…è³‡æ–™å®Œå…¨åˆ†é›¢  
- ç©©å®šæ€§ï¼šcohort é›†åˆå›ºå®šï¼Œä¸æœƒå› æ–°å¢èªè€…è€Œæ”¹è®Š
- å°ˆç”¨æ€§ï¼šcohort åƒ…ç”¨æ–¼ AS-Norm è¨ˆç®—ï¼Œä¸åƒèˆ‡å¯¦éš›è¾¨è­˜

æŠ€è¡“æ¶æ§‹ï¼š
-----------
- è²ç´‹æå–ï¼špyannote/embedding æ¨¡å‹ (512ç¶­)
- å‘é‡è³‡æ–™åº«ï¼šWeaviate V2
- éŸ³é »è™•ç†ï¼šlibrosa + soundfile
- åˆ‡ç‰‡ç­–ç•¥ï¼šå›ºå®šé•·åº¦åˆ‡ç‰‡ + é‡ç–Šçª—å£

ä½¿ç”¨æ–¹å¼ï¼š
-----------
1. åˆå§‹åŒ– cohort è³‡æ–™åº«ï¼š
   ```python
   manager = CohortDatabaseManager()
   manager.initialize_cohort_collection()
   ```

2. å°å…¥å–®å€‹éŸ³é »æª”æ¡ˆï¼š
   ```python
   manager.import_audio_file("/path/to/audio.wav")  # è‡ªå‹•ä½¿ç”¨æª”åä½œç‚º source_dataset
   ```

3. å¾éŸ³é »è³‡æ–™å¤¾æ‰¹é‡å°å…¥ cohortï¼š
   ```python
   manager.import_audio_folder("/path/to/cohort/audio")  # æ¯å€‹æª”æ¡ˆä½¿ç”¨æª”åä½œç‚º source_dataset
   ```

4. é‡ç½® cohort è³‡æ–™åº«ï¼š
   ```python
   manager.reset_cohort_collection()
   ```

æ³¨æ„ï¼šç¾åœ¨ç›´æ¥è™•ç†æ•´å€‹éŸ³æª”ï¼ˆ6ç§’ï¼‰ï¼Œä¸å†é€²è¡Œåˆ‡ç‰‡è™•ç†ã€‚
"""

import os
import sys
import logging
import numpy as np
import librosa
import soundfile as sf
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import pytz  # æ–°å¢ï¼šæ™‚å€æ”¯æ´

# æ·»åŠ æ¨¡çµ„è·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

import weaviate
import weaviate.classes.config as wcc
import torch
from speechbrain.inference import SpeakerRecognition
from pyannote.audio import Inference
from pyannote.core import Segment
from scipy.spatial.distance import cosine
from scipy.signal import resample_poly  # æ–°å¢ï¼šèˆ‡ VID_identify_v5.py ä¸€è‡´çš„é‡æ–°æ¡æ¨£
from weaviate.classes.query import Filter

# å°å…¥é …ç›®æ¨¡çµ„
from utils.logger import get_logger
from utils.env_config import get_model_save_dir, HF_ACCESS_TOKEN
from utils.constants import (
    AS_NORM_COHORT_COLLECTION, SPEECHBRAIN_SPEAKER_MODEL, PYANNOTE_SPEAKER_MODEL,
    AUDIO_TARGET_RATE, AUDIO_SAMPLE_RATE,
    ENABLE_AS_NORM, AS_NORM_COHORT_SIZE, AS_NORM_TOP_K, AS_NORM_ALPHA,
    ENABLE_T_NORM, ENABLE_Z_NORM, ENABLE_S_NORM, AS_NORM_USE_DEDICATED_COHORT
)

# å‰µå»ºæ¨¡çµ„å°ˆå±¬æ—¥èªŒå™¨
logger = get_logger(__name__)

# å°åŒ—æ™‚å€è¨­å®š
TAIPEI_TZ = pytz.timezone('Asia/Taipei')

def get_taipei_time() -> datetime:
    """
    ç²å–å°åŒ—æ™‚é–“
    
    Returns:
        datetime: å°åŒ—æ™‚å€çš„ç•¶å‰æ™‚é–“
    """
    return datetime.now(TAIPEI_TZ)


class ASNormProcessor:
    """
    AS-Norm (Adaptive Score Normalization) è™•ç†å™¨
    
    å¯¦ç¾å¤šç¨®æ­£è¦åŒ–æŠ€è¡“ï¼š
    - T-Norm (Test Normalization): ä½¿ç”¨ impostor æ¨¡å‹çš„åˆ†æ•¸é€²è¡Œæ­£è¦åŒ–
    - Z-Norm (Zero Normalization): ä½¿ç”¨çµ±è¨ˆ Z-score æ­£è¦åŒ–
    - S-Norm (Symmetric Normalization): çµåˆ T-Norm å’Œ Z-Norm
    
    ä¸»è¦ç›®çš„ï¼šæ”¹å–„èªè€…è­˜åˆ¥çš„ç©©å®šæ€§å’Œæº–ç¢ºæ€§ï¼Œæ¸›å°‘æ¢ä»¶è®Šç•°çš„å½±éŸ¿
    """
    
    def __init__(self, database_client=None):
        """
        åˆå§‹åŒ– AS-Norm è™•ç†å™¨
        
        Args:
            database_client: Weaviate è³‡æ–™åº«å®¢æˆ¶ç«¯å¯¦ä¾‹
        """
        self.client = database_client
        self.cohort_size = AS_NORM_COHORT_SIZE
        self.top_k = AS_NORM_TOP_K
        self.alpha = AS_NORM_ALPHA
        
        # çµ±è¨ˆè³‡æ–™ç·©å­˜
        self._impostor_stats = {}
        self._stats_cache_size = 100
        
    def set_database_client(self, client):
        """è¨­å®šè³‡æ–™åº«å®¢æˆ¶ç«¯"""
        self.client = client
        
    def compute_t_norm_score(self, test_embedding: np.ndarray, target_embedding: np.ndarray, 
                           impostor_embeddings: List[np.ndarray]) -> float:
        """
        è¨ˆç®— T-Norm æ­£è¦åŒ–åˆ†æ•¸ï¼ˆåœ¨è·é›¢ç©ºé–“æ“ä½œï¼‰
        
        T-Norm é€šéä½¿ç”¨ impostor æ¨¡å‹åˆ†æ•¸ä¾†æ­£è¦åŒ–ç›®æ¨™åˆ†æ•¸
        åœ¨è·é›¢ç©ºé–“çš„å…¬å¼: (target_distance - mean_impostor_distance) / std_impostor_distance
        
        æ³¨æ„ï¼šæ­£è¦åŒ–å¾Œçš„å€¼å¯èƒ½ç‚ºè² æ•¸ï¼ˆè¡¨ç¤ºæ¯”å¹³å‡ impostor æ›´ç›¸ä¼¼ï¼‰
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡  
            impostor_embeddings: impostor èªè€…çš„åµŒå…¥å‘é‡åˆ—è¡¨
            
        Returns:
            float: T-Norm æ­£è¦åŒ–å¾Œçš„è·é›¢åˆ†æ•¸
        """
        if not impostor_embeddings:
            # æ²’æœ‰ impostor æ™‚ï¼Œè¿”å›åŸå§‹é¤˜å¼¦è·é›¢
            return cosine(test_embedding, target_embedding)
            
        # è¨ˆç®—ç›®æ¨™è·é›¢ï¼ˆé¤˜å¼¦è·é›¢ï¼‰
        target_distance = cosine(test_embedding, target_embedding)
        
        # è¨ˆç®— impostor è·é›¢
        impostor_distances = []
        for imp_embedding in impostor_embeddings:
            imp_distance = cosine(test_embedding, imp_embedding)
            impostor_distances.append(imp_distance)
            
        # è¨ˆç®— impostor è·é›¢çš„çµ±è¨ˆé‡
        mean_impostor_distance = np.mean(impostor_distances)
        std_impostor_distance = np.std(impostor_distances)
        
        # T-Norm æ­£è¦åŒ–ï¼ˆåœ¨è·é›¢ç©ºé–“ï¼‰
        if std_impostor_distance > 0:
            # æ³¨æ„ï¼šç›®æ¨™è·é›¢å°æ–¼å¹³å‡ impostor è·é›¢æ™‚ï¼Œæ­£è¦åŒ–å€¼ç‚ºè² 
            t_norm_distance = (target_distance - mean_impostor_distance) / std_impostor_distance
        else:
            t_norm_distance = target_distance
            
        return t_norm_distance
    
    def compute_z_norm_score(self, test_embedding: np.ndarray, target_embedding: np.ndarray) -> float:
        """
        è¨ˆç®— Z-Norm æ­£è¦åŒ–åˆ†æ•¸ï¼ˆåœ¨è·é›¢ç©ºé–“æ“ä½œï¼‰
        
        Z-Norm ä½¿ç”¨æ¸¬è©¦èªéŸ³å°æ‰€æœ‰å·²çŸ¥èªè€…çš„çµ±è¨ˆåˆ†å¸ƒé€²è¡Œæ­£è¦åŒ–
        åœ¨è·é›¢ç©ºé–“çš„å…¬å¼: (target_distance - mean_all_distance) / std_all_distance
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡
            
        Returns:
            float: Z-Norm æ­£è¦åŒ–å¾Œçš„è·é›¢åˆ†æ•¸
        """
        # è¨ˆç®—ç›®æ¨™è·é›¢ï¼ˆé¤˜å¼¦è·é›¢ï¼‰
        target_distance = cosine(test_embedding, target_embedding)
        
        # ç²å–æ‰€æœ‰èªè€…çš„åµŒå…¥å‘é‡
        all_embeddings = self._get_all_speaker_embeddings()
        
        if not all_embeddings:
            return target_distance
            
        # è¨ˆç®—å°æ‰€æœ‰èªè€…çš„è·é›¢
        all_distances = []
        for embedding in all_embeddings:
            distance = cosine(test_embedding, embedding)
            all_distances.append(distance)
            
        # Z-Norm æ­£è¦åŒ–ï¼ˆåœ¨è·é›¢ç©ºé–“ï¼‰
        mean_all_distance = np.mean(all_distances)
        std_all_distance = np.std(all_distances)
        
        if std_all_distance > 0:
            z_norm_distance = (target_distance - mean_all_distance) / std_all_distance
        else:
            z_norm_distance = target_distance
            
        return z_norm_distance
    
    def compute_s_norm_score(self, test_embedding: np.ndarray, target_embedding: np.ndarray,
                           impostor_embeddings: List[np.ndarray]) -> float:
        """
        è¨ˆç®— S-Norm (Symmetric Normalization) æ­£è¦åŒ–åˆ†æ•¸
        
        S-Norm çµåˆ T-Norm å’Œ Z-Norm çš„å„ªé»
        å…¬å¼: alpha * t_norm + (1-alpha) * z_norm
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡
            impostor_embeddings: impostor èªè€…çš„åµŒå…¥å‘é‡åˆ—è¡¨
            
        Returns:
            float: S-Norm æ­£è¦åŒ–å¾Œçš„åˆ†æ•¸
        """
        # è¨ˆç®— T-Norm åˆ†æ•¸
        t_norm_score = self.compute_t_norm_score(test_embedding, target_embedding, impostor_embeddings)
        
        # è¨ˆç®— Z-Norm åˆ†æ•¸
        z_norm_score = self.compute_z_norm_score(test_embedding, target_embedding)
        
        # S-Norm çµåˆ
        s_norm_score = self.alpha * t_norm_score + (1 - self.alpha) * z_norm_score
        
        return s_norm_score
    
    def apply_as_norm(self, test_embedding: np.ndarray, target_embedding: np.ndarray,
                     target_id: str) -> float:
        """
        æ‡‰ç”¨ AS-Norm è™•ç†ï¼ˆä¿®æ­£ç‰ˆï¼šä¿æŒçµ±è¨ˆç©©å®šæ€§å’Œå€åˆ¥æ€§ï¼‰
        
        æ ¹æ“šé…ç½®é¸æ“‡æ€§åœ°æ‡‰ç”¨ä¸åŒçš„æ­£è¦åŒ–æ–¹æ³•ï¼Œç¢ºä¿ä¸æœƒç ´å£è·é›¢çš„å€åˆ¥èƒ½åŠ›
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡
            target_id: ç›®æ¨™èªè€…ID
            
        Returns:
            float: æ­£è¦åŒ–å¾Œçš„è·é›¢åˆ†æ•¸ï¼ˆèˆ‡åŸå§‹é¤˜å¼¦è·é›¢æ¦‚å¿µä¸€è‡´ï¼‰
        """
        if not ENABLE_AS_NORM:
            # AS-Norm é—œé–‰æ™‚ï¼Œè¿”å›åŸå§‹é¤˜å¼¦è·é›¢
            original_distance = cosine(test_embedding, target_embedding)
            logger.debug(f"âšª AS-Norm å·²åœç”¨ï¼Œè¿”å›åŸå§‹é¤˜å¼¦è·é›¢: {original_distance:.4f}")
            return original_distance
            
        # è¨ˆç®—åŸå§‹é¤˜å¼¦è·é›¢ä½œç‚ºå°æ¯”
        original_distance = cosine(test_embedding, target_embedding)
        logger.debug(f"ğŸ“ åŸå§‹é¤˜å¼¦è·é›¢: {original_distance:.4f}")
        
        # ç²å– impostor åµŒå…¥å‘é‡
        impostor_embeddings = self._get_impostor_embeddings(target_id)
        
        # æ ¹æ“šé…ç½®é¸æ“‡æ­£è¦åŒ–æ–¹æ³•ï¼ˆåœ¨è·é›¢ç©ºé–“æ“ä½œï¼‰
        if ENABLE_S_NORM and ENABLE_T_NORM and ENABLE_Z_NORM:
            # å®Œæ•´ S-Norm
            logger.debug("ğŸ”§ ä½¿ç”¨å®Œæ•´ S-Norm (T-Norm + Z-Norm çµ„åˆ)")
            normalized_distance = self.compute_s_norm_score(test_embedding, target_embedding, impostor_embeddings)
        elif ENABLE_T_NORM and ENABLE_Z_NORM:
            # T-Norm + Z-Norm çµ„åˆ
            logger.debug("ğŸ”§ ä½¿ç”¨ T-Norm + Z-Norm çµ„åˆ")
            t_distance = self.compute_t_norm_score(test_embedding, target_embedding, impostor_embeddings)
            z_distance = self.compute_z_norm_score(test_embedding, target_embedding)
            normalized_distance = 0.5 * t_distance + 0.5 * z_distance
        elif ENABLE_T_NORM:
            # åƒ… T-Norm
            logger.debug("ğŸ”§ ä½¿ç”¨ T-Norm æ­£è¦åŒ–")
            normalized_distance = self.compute_t_norm_score(test_embedding, target_embedding, impostor_embeddings)
        elif ENABLE_Z_NORM:
            # åƒ… Z-Norm
            logger.debug("ğŸ”§ ä½¿ç”¨ Z-Norm æ­£è¦åŒ–")
            normalized_distance = self.compute_z_norm_score(test_embedding, target_embedding)
        else:
            # æ‰€æœ‰æ­£è¦åŒ–éƒ½é—œé–‰ï¼Œè¿”å›åŸå§‹åˆ†æ•¸
            logger.debug("âšª æ‰€æœ‰æ­£è¦åŒ–æ–¹æ³•éƒ½å·²åœç”¨ï¼Œè¿”å›åŸå§‹åˆ†æ•¸")
            return original_distance
        
        # æª¢æŸ¥æ­£è¦åŒ–çµæœçš„åˆç†æ€§
        if abs(normalized_distance) > 10:
            logger.warning(f"âš ï¸ AS-Norm æ­£è¦åŒ–å€¼ç•°å¸¸: {normalized_distance:.4f}ï¼Œcohort è³‡æ–™å¯èƒ½æœ‰å•é¡Œ")
            logger.warning(f"âš ï¸ å›é€€åˆ°åŸå§‹è·é›¢: {original_distance:.4f}")
            return original_distance
        
        # ä½¿ç”¨ä¿å®ˆçš„æ˜ å°„ç­–ç•¥ï¼Œä¿æŒå€åˆ¥æ€§
        from utils.constants import THRESHOLD_LOW, THRESHOLD_UPDATE, THRESHOLD_NEW
        
        # ä¿®æ­£ç‰ˆæ˜ å°„ï¼šä¿æŒåŸå§‹è·é›¢çš„ç›¸å°é—œä¿‚ï¼Œåªåšé©åº¦èª¿æ•´
        # æ ¸å¿ƒç†å¿µï¼šå¥½çš„åŒ¹é…å°å¹…æ”¹å–„ï¼Œå£çš„åŒ¹é…ä¿æŒåŸæ¨£æˆ–ç•¥å¾®æƒ¡åŒ–
        
        if normalized_distance <= -2.0:
            # å¾ˆå¥½çš„åŒ¹é…ï¼šè·é›¢æ¸›å°‘ 20-40%
            reduction_factor = 0.6 + 0.2 * max(0, min(1, (normalized_distance + 4) / 2))
            final_distance = original_distance * reduction_factor
        elif normalized_distance <= -1.0:
            # å¥½çš„åŒ¹é…ï¼šè·é›¢æ¸›å°‘ 10-20%
            reduction_factor = 0.8 + 0.1 * (normalized_distance + 2) / 1
            final_distance = original_distance * reduction_factor
        elif normalized_distance <= 0:
            # ä¸­ç­‰åŒ¹é…ï¼šè·é›¢æ¸›å°‘ 0-10%
            reduction_factor = 0.9 + 0.1 * (normalized_distance + 1) / 1
            final_distance = original_distance * reduction_factor
        elif normalized_distance <= 1.0:
            # è¼ƒå·®åŒ¹é…ï¼šè·é›¢ä¿æŒä¸è®Šæˆ–ç•¥å¾®å¢åŠ 
            increase_factor = 1.0 + 0.1 * normalized_distance / 1
            final_distance = original_distance * increase_factor
        else:
            # å¾ˆå·®åŒ¹é…ï¼šè·é›¢å¢åŠ  10-20%
            increase_factor = 1.1 + 0.1 * min(1.0, (normalized_distance - 1) / 2)
            final_distance = original_distance * increase_factor
        
        # ç¢ºä¿çµæœåœ¨åˆç†ç¯„åœå…§
        final_distance = max(0.001, min(2.0, final_distance))
        
        # è¨˜éŒ„æ­£è¦åŒ–æ•ˆæœå’ŒåŸå§‹æ•¸æ“š
        improvement = original_distance - final_distance  # è·é›¢æ¸›å°‘è¡¨ç¤ºæ”¹å–„
        improvement_percent = (improvement / original_distance) * 100 if original_distance > 0 else 0
        
        # è©³ç´°è¨˜éŒ„æ­£è¦åŒ–éç¨‹
        logger.debug(f"ğŸ“Š åŸå§‹é¤˜å¼¦è·é›¢: {original_distance:.4f}")
        logger.debug(f"ğŸ“Š AS-Norm æ­£è¦åŒ–å€¼: {normalized_distance:.4f}")
        logger.debug(f"ğŸ“Š æœ€çµ‚æ˜ å°„è·é›¢: {final_distance:.4f}")
        
        # æ ¹æ“šå¯¦éš›æ•ˆæœè¨˜éŒ„
        if abs(improvement_percent) < 1:
            logger.debug(f"ğŸ“Š æ­£è¦åŒ–çµæœ: {original_distance:.4f} â†’ {final_distance:.4f} (å¾®èª¿: {improvement:+.4f})")
        elif improvement > 0:
            logger.debug(f"ğŸ“Š æ­£è¦åŒ–çµæœ: {original_distance:.4f} â†’ {final_distance:.4f} (æ”¹å–„: {improvement:+.4f}, {improvement_percent:+.1f}%)")
        else:
            logger.debug(f"ğŸ“Š æ­£è¦åŒ–çµæœ: {original_distance:.4f} â†’ {final_distance:.4f} (èª¿æ•´: {improvement:+.4f}, {improvement_percent:+.1f}%)")
        
        return final_distance
    
    def _get_impostor_embeddings(self, target_id: str) -> List[np.ndarray]:
        """
        ç²å– impostor èªè€…çš„åµŒå…¥å‘é‡ï¼ˆç”¨æ–¼ T-Normï¼‰
        
        é‚è¼¯èªªæ˜ï¼š
        1. ç›´æ¥å¾å°ˆé–€çš„ CohortVoicePrint collection ç²å–
        2. cohort è³‡æ–™åº«æœ¬èº«å°±ä¸åŒ…å«ç›®æ¨™èªè€…ï¼Œç„¡éœ€éæ¿¾
        
        Args:
            target_id: ç›®æ¨™èªè€…ID
            
        Returns:
            List[np.ndarray]: impostor åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not self.client:
            logger.warning("è³‡æ–™åº«å®¢æˆ¶ç«¯æœªè¨­å®šï¼Œç„¡æ³•ç²å– impostor åµŒå…¥å‘é‡")
            return []
            
        try:
            impostor_embeddings = []
            
            # æª¢æŸ¥ cohort è³‡æ–™åº«æ˜¯å¦å­˜åœ¨
            if not self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                logger.error(f"âŒ Cohort è³‡æ–™åº« '{AS_NORM_COHORT_COLLECTION}' ä¸å­˜åœ¨ï¼Œç„¡æ³•ç²å– impostor åµŒå…¥å‘é‡")
                return []
            
            logger.debug(f"ğŸ¯ ä½¿ç”¨å°ˆé–€çš„ cohort è³‡æ–™åº«: {AS_NORM_COHORT_COLLECTION}")
            collection = self.client.collections.get(AS_NORM_COHORT_COLLECTION)
            
            # å¾ cohort è³‡æ–™åº«ç²å–ï¼Œç„¡éœ€éæ¿¾ï¼ˆcohort æœ¬èº«å°±ä¸åŒ…å«ç›®æ¨™èªè€…ï¼‰
            results = collection.query.fetch_objects(
                include_vector=True,
                limit=self.top_k
            )
            
            for obj in results.objects:
                if obj.vector:
                    # è™•ç† named vector
                    vec_dict = obj.vector
                    raw_vec = vec_dict["default"] if isinstance(vec_dict, dict) else vec_dict
                    embedding = np.array(raw_vec, dtype=float)
                    impostor_embeddings.append(embedding)
            
            logger.debug(f"âœ… å¾ cohort è³‡æ–™åº«ç²å–äº† {len(impostor_embeddings)} å€‹ impostor åµŒå…¥å‘é‡ï¼ˆç›®æ¨™: {self.top_k}ï¼‰")
            
            if len(impostor_embeddings) == 0:
                logger.warning("âš ï¸ æœªèƒ½å¾ cohort è³‡æ–™åº«ç²å–ä»»ä½• impostor åµŒå…¥å‘é‡")
            elif len(impostor_embeddings) < self.top_k:
                logger.warning(f"âš ï¸ cohort è³‡æ–™åº«åµŒå…¥å‘é‡æ•¸é‡ä¸è¶³ï¼šç²å– {len(impostor_embeddings)} å€‹ï¼Œç›®æ¨™ {self.top_k} å€‹")
            
            return impostor_embeddings
            
        except Exception as e:
            logger.warning(f"ç²å– impostor åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def _get_all_speaker_embeddings(self) -> List[np.ndarray]:
        """
        ç²å–èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡ï¼ˆç”¨æ–¼ Z-Normï¼‰
        
        é‚è¼¯èªªæ˜ï¼š
        1. ç›´æ¥ä½¿ç”¨å°ˆé–€çš„ cohort è³‡æ–™åº«ä¾†ä¿æŒçµ±è¨ˆç©©å®šæ€§
        2. Z-Norm éœ€è¦è¶³å¤ çš„çµ±è¨ˆæ¨£æœ¬ï¼ˆä½¿ç”¨ cohort_size é™åˆ¶ï¼‰
        
        Returns:
            List[np.ndarray]: èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not self.client:
            logger.warning("è³‡æ–™åº«å®¢æˆ¶ç«¯æœªè¨­å®šï¼Œç„¡æ³•ç²å–èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡")
            return []
            
        try:
            all_embeddings = []
            
            # æª¢æŸ¥ cohort è³‡æ–™åº«æ˜¯å¦å­˜åœ¨
            if not self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                logger.error(f"âŒ Cohort è³‡æ–™åº« '{AS_NORM_COHORT_COLLECTION}' ä¸å­˜åœ¨ï¼Œç„¡æ³•ç²å–èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡")
                return []
            
            logger.debug(f"ğŸ¯ ä½¿ç”¨å°ˆé–€çš„ cohort è³‡æ–™åº«é€²è¡Œ Z-Norm: {AS_NORM_COHORT_COLLECTION}")
            collection = self.client.collections.get(AS_NORM_COHORT_COLLECTION)
            
            results = collection.query.fetch_objects(
                include_vector=True,
                limit=self.cohort_size  # Z-Norm ä½¿ç”¨ cohort_size è€Œé top_k
            )
            
            for obj in results.objects:
                if obj.vector:
                    # è™•ç† named vector
                    vec_dict = obj.vector
                    raw_vec = vec_dict["default"] if isinstance(vec_dict, dict) else vec_dict
                    embedding = np.array(raw_vec, dtype=float)
                    all_embeddings.append(embedding)
            
            logger.debug(f"âœ… å¾ cohort è³‡æ–™åº«ç²å–äº† {len(all_embeddings)} å€‹èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡ï¼ˆç›®æ¨™: {self.cohort_size}ï¼‰")
            
            if len(all_embeddings) == 0:
                logger.warning("âš ï¸ æœªèƒ½å¾ cohort è³‡æ–™åº«ç²å–ä»»ä½•èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡")
            elif len(all_embeddings) < self.cohort_size:
                logger.warning(f"âš ï¸ cohort è³‡æ–™åº«åµŒå…¥å‘é‡æ•¸é‡ä¸è¶³ï¼šç²å– {len(all_embeddings)} å€‹ï¼Œç›®æ¨™ {self.cohort_size} å€‹")
            
            return all_embeddings
            
        except Exception as e:
            logger.warning(f"ç²å–èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []


class CohortDatabaseManager:
    """AS-Norm Cohort è³‡æ–™åº«ç®¡ç†å™¨"""
    
    def __init__(self, model_name: str = None, model_type: str = "pyannote") -> None:
        """
        åˆå§‹åŒ– Cohort è³‡æ–™åº«ç®¡ç†å™¨
        
        Args:
            model_name: è²ç´‹æå–æ¨¡å‹åç¨±ï¼ˆå°‡è¢« model_type è¦†è“‹ï¼‰
            model_type: æ¨¡å‹é¡å‹ï¼Œå¯é¸å€¼: "speechbrain" æˆ– "pyannote"
        """
        # ====== é€™è£¡æ”¹æ¨¡å‹é¡å‹ ======
        self.model_type = model_type
        # =========================
        
        if self.model_type == "speechbrain":
            self.model_name = SPEECHBRAIN_SPEAKER_MODEL
        elif self.model_type == "pyannote":
            self.model_name = PYANNOTE_SPEAKER_MODEL
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹é¡å‹: {self.model_type}")
            
        self.client = None
        self.speaker_model = None
        self._connect_database()
        self._init_speaker_model()
    
    def _connect_database(self) -> None:
        """é€£æ¥åˆ° Weaviate è³‡æ–™åº«"""
        try:
            self.client = weaviate.connect_to_local()
            logger.info("ğŸ”— æˆåŠŸé€£æ¥åˆ° Weaviate è³‡æ–™åº«")
        except Exception as e:
            logger.error(f"âŒ é€£æ¥åˆ° Weaviate å¤±æ•—: {e}")
            raise
    
    def _init_speaker_model(self) -> None:
        """åˆå§‹åŒ–è²ç´‹æå–æ¨¡å‹ï¼ˆæ”¯æ´ speechbrain å’Œ pyannoteï¼‰"""
        try:
            logger.info(f"ğŸ”§ æ­£åœ¨è¼‰å…¥è²ç´‹æå–æ¨¡å‹: {self.model_name}")
            logger.info(f"ğŸ¯ æ¨¡å‹é¡å‹: {self.model_type}")
            
            # è¨­å®šè¨­å‚™
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            logger.info(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}")
            
            if self.model_type == "speechbrain":
                # è¼‰å…¥ SpeechBrain èªè€…è¾¨è­˜æ¨¡å‹
                model_save_dir = get_model_save_dir("speechbrain_recognition")
                os.makedirs(model_save_dir, exist_ok=True)
                
                self.speaker_model = SpeakerRecognition.from_hparams(
                    source=self.model_name,
                    savedir=model_save_dir,
                    use_auth_token=HF_ACCESS_TOKEN
                )
                logger.info("âœ… SpeechBrain ECAPA-TDNN æ¨¡å‹è¼‰å…¥æˆåŠŸ (192ç¶­)")
                
            elif self.model_type == "pyannote":
                # è¼‰å…¥ pyannote èªè€…åµŒå…¥æ¨¡å‹
                self.speaker_model = Inference(
                    self.model_name, 
                    window="whole",
                    device=self.device,
                    use_auth_token=HF_ACCESS_TOKEN
                )
                self.Segment = Segment  # ä¿å­˜ Segment é¡åˆ¥ä»¥ä¾¿å¾ŒçºŒä½¿ç”¨
                logger.info("âœ… pyannote/embedding æ¨¡å‹è¼‰å…¥æˆåŠŸ (512ç¶­)")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥è²ç´‹æå–æ¨¡å‹å¤±æ•—: {e}")
            raise
    
    def initialize_cohort_collection(self) -> bool:
        """
        åˆå§‹åŒ– cohort collection
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸå»ºç«‹æˆ–ç¢ºèª collection å­˜åœ¨
        """
        if not self.client:
            logger.error("âŒ è³‡æ–™åº«å®¢æˆ¶ç«¯æœªé€£æ¥")
            return False
        
        try:
            logger.info(f"ğŸ—ï¸  æ­£åœ¨åˆå§‹åŒ– cohort collection: {AS_NORM_COHORT_COLLECTION}")
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                logger.info(f"âœ… Cohort collection '{AS_NORM_COHORT_COLLECTION}' å·²å­˜åœ¨")
                return True
            
            # å»ºç«‹ AS-Norm å°ˆç”¨çš„ Cohort VoicePrint é›†åˆ
            # é€™å€‹é›†åˆå­˜æ”¾ä¸æœƒåœ¨å¯¦éš›è¾¨è­˜ä¸­å‡ºç¾çš„èƒŒæ™¯èªéŸ³è³‡æ–™
            cohort_collection = self.client.collections.create(
                name=AS_NORM_COHORT_COLLECTION,
                properties=[
                    wcc.Property(name="create_time", data_type=wcc.DataType.DATE),
                    wcc.Property(name="cohort_id", data_type=wcc.DataType.TEXT),  # èƒŒæ™¯æ¨¡å‹è­˜åˆ¥ç¢¼
                    wcc.Property(name="source_dataset", data_type=wcc.DataType.TEXT),  # ä¾†æºè³‡æ–™é›†
                    wcc.Property(name="gender", data_type=wcc.DataType.TEXT),  # æ€§åˆ¥ï¼ˆå¯é¸ï¼‰
                    wcc.Property(name="language", data_type=wcc.DataType.TEXT),  # èªè¨€ï¼ˆå¯é¸ï¼‰
                    wcc.Property(name="description", data_type=wcc.DataType.TEXT),  # æè¿°
                ],
                vectorizer_config=wcc.Configure.Vectorizer.none(),
                vector_index_config=wcc.Configure.VectorIndex.hnsw(
                    distance_metric=wcc.VectorDistances.COSINE
                )
            )
            logger.info(f"âœ… æˆåŠŸå»ºç«‹ cohort collection '{AS_NORM_COHORT_COLLECTION}'")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ– cohort collection æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def reset_cohort_collection(self, force: bool = False) -> bool:
        """
        é‡ç½® cohort collectionï¼ˆåˆªé™¤æ‰€æœ‰è³‡æ–™ä¸¦é‡æ–°å»ºç«‹ï¼‰
        
        Args:
            force: æ˜¯å¦å¼·åˆ¶é‡ç½®ï¼Œè‹¥ç‚º False æœƒå…ˆç¢ºèªè³‡æ–™åº«ç‹€æ…‹
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸé‡ç½®
        """
        try:
            logger.info(f"ğŸ—‘ï¸  æ­£åœ¨é‡ç½® cohort collection: {AS_NORM_COHORT_COLLECTION}")
            
            # å¦‚æœä¸æ˜¯å¼·åˆ¶æ¨¡å¼ï¼Œå…ˆæª¢æŸ¥ç¾æœ‰è³‡æ–™
            if not force and self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                stats = self.get_cohort_statistics()
                current_count = stats.get('total_count', 0)
                if current_count > 0:
                    logger.warning(f"âš ï¸  ç•¶å‰ cohort è³‡æ–™åº«åŒ…å« {current_count} ç­†è³‡æ–™")
                    logger.warning(f"âš ï¸  é‡ç½®æ“ä½œå°‡åˆªé™¤æ‰€æœ‰ç¾æœ‰è³‡æ–™")
                    logger.info(f"ğŸ’¡ å¦‚éœ€å¼·åˆ¶é‡ç½®ï¼Œè«‹è¨­å®š force=True")
                    return False
                else:
                    logger.info(f"ğŸ“Š ç•¶å‰ cohort è³‡æ–™åº«ç‚ºç©ºï¼Œç¹¼çºŒé‡ç½®æ“ä½œ")
            
            # è¨˜éŒ„é‡ç½®æ™‚é–“
            reset_time = get_taipei_time()
            logger.info(f"ğŸ• é‡ç½®æ™‚é–“: {reset_time.strftime('%Y-%m-%d %H:%M:%S %Z')}")
            
            # åˆªé™¤ç¾æœ‰ collection
            if self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                self.client.collections.delete(AS_NORM_COHORT_COLLECTION)
                logger.info(f"ğŸ—‘ï¸  å·²åˆªé™¤ç¾æœ‰çš„ cohort collection")
            else:
                logger.info(f"â„¹ï¸  Cohort collection ä¸å­˜åœ¨ï¼Œç›´æ¥å»ºç«‹æ–°çš„")
            
            # é‡æ–°å»ºç«‹
            success = self.initialize_cohort_collection()
            if success:
                logger.info(f"âœ… æˆåŠŸé‡ç½® cohort collection")
                
                # é©—è­‰é‡ç½®çµæœ
                final_stats = self.get_cohort_statistics()
                logger.info(f"ğŸ“Š é‡ç½®å¾Œç‹€æ…‹: ç¸½è¨ˆ {final_stats.get('total_count', 0)} ç­†è³‡æ–™")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ é‡ç½® cohort collection æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def resample_audio(self, signal: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """
        ä½¿ç”¨ scipy é€²è¡Œé«˜å“è³ªé‡æ–°æ¡æ¨£ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
        
        Args:
            signal: éŸ³é »ä¿¡è™Ÿ
            orig_sr: åŸå§‹æ¡æ¨£ç‡
            target_sr: ç›®æ¨™æ¡æ¨£ç‡
            
        Returns:
            np.ndarray: é‡æ–°æ¡æ¨£å¾Œçš„éŸ³é »ä¿¡è™Ÿ
        """
        return resample_poly(signal, target_sr, orig_sr)
    
    def extract_embedding(self, audio_path: str) -> Optional[np.ndarray]:
        """
        å¾éŸ³é »æª”æ¡ˆæå–è²ç´‹åµŒå…¥å‘é‡ï¼ˆæ”¯æ´ speechbrain å’Œ pyannoteï¼‰
        èˆ‡ VID_identify_v5.py ä¿æŒå®Œå…¨ä¸€è‡´çš„å¯¦ä½œ
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            
        Returns:
            Optional[np.ndarray]: è²ç´‹åµŒå…¥å‘é‡ï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        try:
            # è¼‰å…¥éŸ³é »æª”æ¡ˆï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´çš„æ–¹å¼ï¼‰
            waveform, sample_rate = librosa.load(audio_path, sr=None)  # ä¿æŒåŸå§‹æ¡æ¨£ç‡
            
            # è™•ç†ç«‹é«”è²è½‰å–®è²é“ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            if waveform.ndim > 1:
                waveform = waveform.mean(axis=1)
            
            # é‡æ–°æ¡æ¨£åˆ°ç›®æ¨™æ¡æ¨£ç‡ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            target_sr = AUDIO_TARGET_RATE
            if sample_rate != target_sr:
                waveform = self.resample_audio(waveform, sample_rate, target_sr)
            
            # æª¢æŸ¥éŸ³é »é•·åº¦ï¼ˆè‡³å°‘éœ€è¦ 1 ç§’ï¼‰
            min_length = target_sr  # 1 ç§’
            if len(waveform) < min_length:
                logger.warning(f"âš ï¸  éŸ³é »æª”æ¡ˆå¤ªçŸ­ï¼Œè·³é: {audio_path} ({len(waveform)/target_sr:.2f}s)")
                return None
            
            # æ ¹æ“šæ¨¡å‹é¡å‹æå–åµŒå…¥å‘é‡
            if self.model_type == "speechbrain":
                # SpeechBrain æ¨¡å‹è™•ç†
                waveform_tensor = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(self.device)
                embedding = self.speaker_model.encode_batch(waveform_tensor)
                
                # è½‰æ›ç‚º numpy array ä¸¦æ­£è¦åŒ–
                embedding_np = embedding.squeeze().cpu().numpy()
                embedding_np = embedding_np / np.linalg.norm(embedding_np)  # L2 æ­£è¦åŒ–
                
            elif self.model_type == "pyannote":
                # pyannote æ¨¡å‹è™•ç†ï¼ˆä½¿ç”¨è‡¨æ™‚æª”æ¡ˆæ–¹å¼ï¼‰
                import tempfile
                import soundfile as sf
                
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_path = temp_file.name
                    # å°‡ä¿¡è™Ÿå¯«å…¥è‡¨æ™‚æ–‡ä»¶
                    sf.write(temp_path, waveform, target_sr)
                
                try:
                    # æ•´å€‹éŸ³é »æ¨¡å¼ï¼šä½¿ç”¨ crop æ–¹æ³•
                    duration = len(waveform) / target_sr
                    segment = self.Segment(0, duration)
                    embedding = self.speaker_model.crop(temp_path, segment)
                    
                    # è½‰æ›ç‚º numpy array ä¸¦æ­£è¦åŒ–
                    embedding_np = embedding.squeeze()  # ç§»é™¤ç¬¬ä¸€ç¶­
                    embedding_np = embedding_np / np.linalg.norm(embedding_np)  # L2 æ­£è¦åŒ–
                    
                finally:
                    # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)
            
            return embedding_np
            
        except Exception as e:
            logger.warning(f"âš ï¸  æå–è²ç´‹å¤±æ•—: {audio_path} - {e}")
            return None
    
    def split_audio(self, audio_path: str, chunk_length: float = 6.0, 
                   overlap: float = 0.5) -> List[Tuple[np.ndarray, float, float]]:
        """
        å°‡éŸ³é »æª”æ¡ˆåˆ‡ç‰‡
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            chunk_length: åˆ‡ç‰‡é•·åº¦ï¼ˆç§’ï¼‰
            overlap: é‡ç–Šæ¯”ä¾‹ï¼ˆ0-1ï¼‰
            
        Returns:
            List[Tuple[np.ndarray, float, float]]: (éŸ³é »ç‰‡æ®µ, é–‹å§‹æ™‚é–“, çµæŸæ™‚é–“) åˆ—è¡¨
        """
        chunks = []
        
        try:
            # è¼‰å…¥éŸ³é »æª”æ¡ˆï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            waveform, sample_rate = librosa.load(audio_path, sr=None)  # ä¿æŒåŸå§‹æ¡æ¨£ç‡
            
            # è™•ç†ç«‹é«”è²è½‰å–®è²é“ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            if waveform.ndim > 1:
                waveform = waveform.mean(axis=1)
            
            # é‡æ–°æ¡æ¨£åˆ°ç›®æ¨™æ¡æ¨£ç‡ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            target_sr = AUDIO_TARGET_RATE
            if sample_rate != target_sr:
                waveform = self.resample_audio(waveform, sample_rate, target_sr)
                sample_rate = target_sr  # æ›´æ–°æ¡æ¨£ç‡è®Šæ•¸
            
            audio_length = len(waveform) / sample_rate
            
            # è¨ˆç®—åˆ‡ç‰‡åƒæ•¸
            chunk_samples = int(chunk_length * sample_rate)
            step_samples = int(chunk_samples * (1 - overlap))
            
            # å¦‚æœéŸ³é »å¤ªçŸ­ï¼Œç›´æ¥è¿”å›æ•´å€‹éŸ³é »
            if audio_length < chunk_length:
                chunks.append((waveform, 0.0, audio_length))
                return chunks
            
            # åˆ‡ç‰‡è™•ç†
            start_sample = 0
            chunk_id = 0
            
            while start_sample + chunk_samples <= len(waveform):
                end_sample = start_sample + chunk_samples
                chunk = waveform[start_sample:end_sample]
                
                start_time = start_sample / sample_rate
                end_time = end_sample / sample_rate
                
                chunks.append((chunk, start_time, end_time))
                
                start_sample += step_samples
                chunk_id += 1
            
            logger.debug(f"ğŸ”ª éŸ³é »åˆ‡ç‰‡å®Œæˆ: {audio_path} -> {len(chunks)} å€‹ç‰‡æ®µ")
            return chunks
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »åˆ‡ç‰‡å¤±æ•—: {audio_path} - {e}")
            return []
    
    def import_audio_file(self, audio_path: str, source_dataset: str = None,
                         metadata: Dict[str, Any] = None) -> int:
        """
        å°å…¥å–®å€‹éŸ³é »æª”æ¡ˆåˆ° cohort è³‡æ–™åº«ï¼ˆç›´æ¥è™•ç†æ•´å€‹éŸ³æª”ï¼Œä¸åˆ‡ç‰‡ï¼‰
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            source_dataset: ä¾†æºè³‡æ–™é›†åç¨±ï¼Œè‹¥ç‚º None å‰‡ä½¿ç”¨æª”åï¼ˆä¸å«å‰¯æª”åï¼‰
            metadata: é¡å¤–çš„å…ƒæ•¸æ“š
            
        Returns:
            int: æˆåŠŸå°å…¥çš„è²ç´‹æ•¸é‡ï¼ˆ0 æˆ– 1ï¼‰
        """
        if not self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
            logger.error(f"âŒ Cohort collection '{AS_NORM_COHORT_COLLECTION}' ä¸å­˜åœ¨ï¼Œè«‹å…ˆåˆå§‹åŒ–")
            return 0
        
        file_name = Path(audio_path).stem
        
        # å¦‚æœæ²’æœ‰æŒ‡å®š source_datasetï¼Œä½¿ç”¨æª”å
        if source_dataset is None:
            source_dataset = file_name
        
        try:
            # ç›´æ¥æå–æ•´å€‹éŸ³æª”çš„åµŒå…¥å‘é‡ï¼ˆä¸åˆ‡ç‰‡ï¼‰
            embedding_np = self.extract_embedding(audio_path)
            
            if embedding_np is None:
                logger.warning(f"âš ï¸  ç„¡æ³•æå–åµŒå…¥å‘é‡: {audio_path}")
                return 0
            
            collection = self.client.collections.get(AS_NORM_COHORT_COLLECTION)
            
            # æº–å‚™å…ƒæ•¸æ“š
            properties = {
                "create_time": get_taipei_time(),
                "cohort_id": file_name,  # ä½¿ç”¨æª”åä½œç‚º cohort_id
                "source_dataset": source_dataset,  # ä½¿ç”¨æª”åæˆ–æŒ‡å®šçš„ source_dataset
                "gender": metadata.get("gender", "unknown") if metadata else "unknown",
                "language": metadata.get("language", "zh") if metadata else "zh",
                "description": f"å®Œæ•´éŸ³æª”: {file_name}"
            }
            
            # å¦‚æœæœ‰é¡å¤–å…ƒæ•¸æ“šï¼Œåˆä½µé€²å»
            if metadata:
                for key, value in metadata.items():
                    if key not in properties:
                        properties[key] = value
            
            # æ’å…¥åˆ°è³‡æ–™åº«
            collection.data.insert(
                properties=properties,
                vector=embedding_np.tolist()
            )
            
            logger.info(f"âœ… æˆåŠŸå°å…¥è²ç´‹: {audio_path} -> {source_dataset}")
            return 1
            
        except Exception as e:
            logger.error(f"âŒ å°å…¥éŸ³é »æª”æ¡ˆå¤±æ•—: {audio_path} - {e}")
            return 0
    
    def import_audio_folder(self, folder_path: str, source_dataset_prefix: str = None,
                           audio_extensions: List[str] = None,
                           metadata: Dict[str, Any] = None) -> Dict[str, int]:
        """
        å¾è³‡æ–™å¤¾æ‰¹é‡å°å…¥éŸ³é »æª”æ¡ˆåˆ° cohort è³‡æ–™åº«ï¼ˆç›´æ¥è™•ç†æ•´å€‹éŸ³æª”ï¼Œä¸åˆ‡ç‰‡ï¼‰
        
        Args:
            folder_path: éŸ³é »è³‡æ–™å¤¾è·¯å¾‘
            source_dataset_prefix: ä¾†æºè³‡æ–™é›†å‰ç¶´ï¼Œè‹¥ç‚º None å‰‡ç›´æ¥ä½¿ç”¨æª”å
            audio_extensions: æ”¯æ´çš„éŸ³é »å‰¯æª”å
            metadata: å…¨åŸŸå…ƒæ•¸æ“š
            
        Returns:
            Dict[str, int]: å°å…¥çµæœçµ±è¨ˆ
        """
        if audio_extensions is None:
            audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.aac', '.ogg']
        
        folder_path = Path(folder_path)
        if not folder_path.exists():
            logger.error(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
            return {"total_files": 0, "success_files": 0, "total_embeddings": 0}
        
        logger.info(f"ğŸ“ é–‹å§‹æ‰¹é‡å°å…¥éŸ³é »è³‡æ–™å¤¾: {folder_path}")
        
        # ç¢ºä¿ cohort collection å­˜åœ¨
        if not self.initialize_cohort_collection():
            logger.error("âŒ ç„¡æ³•åˆå§‹åŒ– cohort collection")
            return {"total_files": 0, "success_files": 0, "total_embeddings": 0}
        
        # æœå°‹éŸ³é »æª”æ¡ˆ
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(folder_path.rglob(f"*{ext}"))
            audio_files.extend(folder_path.rglob(f"*{ext.upper()}"))
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(audio_files)} å€‹éŸ³é »æª”æ¡ˆ")
        
        # æ‰¹é‡è™•ç†
        total_files = len(audio_files)
        success_files = 0
        total_embeddings = 0
        
        for i, audio_file in enumerate(audio_files, 1):
            logger.info(f"ğŸµ è™•ç†éŸ³é »æª”æ¡ˆ ({i}/{total_files}): {audio_file.name}")
            
            # ç‚ºæ¯å€‹æª”æ¡ˆæº–å‚™å…ƒæ•¸æ“š
            file_metadata = metadata.copy() if metadata else {}
            file_metadata.update({
                "original_file": audio_file.name,
                "file_path": str(audio_file.relative_to(folder_path))
            })
            
            # æ±ºå®š source_dataset åç¨±
            if source_dataset_prefix:
                source_dataset = f"{source_dataset_prefix}_{audio_file.stem}"
            else:
                source_dataset = audio_file.stem  # ç›´æ¥ä½¿ç”¨æª”å
            
            # å°å…¥æª”æ¡ˆï¼ˆä¸åˆ‡ç‰‡ï¼‰
            embeddings_count = self.import_audio_file(
                str(audio_file), source_dataset, file_metadata
            )
            
            if embeddings_count > 0:
                success_files += 1
                total_embeddings += embeddings_count
        
        # çµ±è¨ˆçµæœ
        results = {
            "total_files": total_files,
            "success_files": success_files,
            "failed_files": total_files - success_files,
            "total_embeddings": total_embeddings
        }
        
        logger.info(f"ğŸ“ˆ æ‰¹é‡å°å…¥å®Œæˆ:")
        logger.info(f"   ğŸ“ ç¸½æª”æ¡ˆæ•¸: {results['total_files']}")
        logger.info(f"   âœ… æˆåŠŸæª”æ¡ˆ: {results['success_files']}")
        logger.info(f"   âŒ å¤±æ•—æª”æ¡ˆ: {results['failed_files']}")
        logger.info(f"   ğŸ¯ ç¸½è²ç´‹æ•¸: {results['total_embeddings']}")
        
        return results
    
    def get_cohort_statistics(self) -> Dict[str, Any]:
        """
        ç²å– cohort è³‡æ–™åº«çµ±è¨ˆä¿¡æ¯
        
        Returns:
            Dict[str, Any]: çµ±è¨ˆä¿¡æ¯
        """
        try:
            if not self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                return {"exists": False, "count": 0}
            
            collection = self.client.collections.get(AS_NORM_COHORT_COLLECTION)
            
            # ç²å–ç¸½æ•¸
            aggregate_result = collection.aggregate.over_all(total_count=True)
            total_count = aggregate_result.total_count if aggregate_result.total_count else 0
            
            # ç²å–æ¨£æœ¬æ•¸æ“šä¾†åˆ†æ
            sample_results = collection.query.fetch_objects(
                limit=min(100, total_count),
                return_properties=["source_dataset", "gender", "language", "create_time"]
            )
            
            # çµ±è¨ˆåˆ†æ
            source_datasets = {}
            genders = {}
            languages = {}
            creation_dates = []
            
            for obj in sample_results.objects:
                if obj.properties:
                    # çµ±è¨ˆä¾†æºè³‡æ–™é›†
                    dataset = obj.properties.get("source_dataset", "unknown")
                    source_datasets[dataset] = source_datasets.get(dataset, 0) + 1
                    
                    # çµ±è¨ˆæ€§åˆ¥
                    gender = obj.properties.get("gender", "unknown")
                    genders[gender] = genders.get(gender, 0) + 1
                    
                    # çµ±è¨ˆèªè¨€
                    language = obj.properties.get("language", "unknown")
                    languages[language] = languages.get(language, 0) + 1
                    
                    # æ”¶é›†å»ºç«‹æ™‚é–“
                    if obj.properties.get("create_time"):
                        creation_dates.append(obj.properties["create_time"])
            
            # è¨ˆç®—æ™‚é–“ç¯„åœ
            time_range = {}
            if creation_dates:
                creation_dates.sort()
                time_range = {
                    "earliest": creation_dates[0].isoformat() if hasattr(creation_dates[0], 'isoformat') else str(creation_dates[0]),
                    "latest": creation_dates[-1].isoformat() if hasattr(creation_dates[-1], 'isoformat') else str(creation_dates[-1])
                }
            
            return {
                "exists": True,
                "total_count": total_count,
                "source_datasets": source_datasets,
                "genders": genders,
                "languages": languages,
                "time_range": time_range,
                "collection_name": AS_NORM_COHORT_COLLECTION
            }
            
        except Exception as e:
            logger.error(f"âŒ ç²å– cohort çµ±è¨ˆä¿¡æ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {"exists": False, "count": 0, "error": str(e)}
    
    def export_cohort_info(self, output_file: str = None) -> str:
        """
        åŒ¯å‡º cohort è³‡æ–™åº«ä¿¡æ¯åˆ°æª”æ¡ˆ
        
        Args:
            output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼Œè‹¥ç‚º None å‰‡è‡ªå‹•ç”Ÿæˆ
            
        Returns:
            str: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        if output_file is None:
            timestamp = get_taipei_time().strftime("%Y%m%d_%H%M%S")
            output_file = f"cohort_info_{timestamp}.json"
        
        try:
            import json
            
            stats = self.get_cohort_statistics()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ“„ Cohort ä¿¡æ¯å·²åŒ¯å‡ºåˆ°: {output_file}")
            return output_file
            
        except Exception as e:
            logger.error(f"âŒ åŒ¯å‡º cohort ä¿¡æ¯å¤±æ•—: {e}")
            return ""
    
    def create_as_norm_processor(self) -> ASNormProcessor:
        """
        å‰µå»º AS-Norm è™•ç†å™¨å¯¦ä¾‹
        
        Returns:
            ASNormProcessor: å·²é…ç½®çš„ AS-Norm è™•ç†å™¨
        """
        processor = ASNormProcessor(self.client)
        return processor
    
    def close(self) -> None:
        """é—œé–‰é€£æ¥ä¸¦æ¸…ç†è³‡æº"""
        try:
            if hasattr(self, 'client') and self.client:
                self.client.close()
                logger.info("ğŸ”Œ å·²é—œé–‰ Weaviate é€£æ¥")
        except Exception as e:
            logger.warning(f"âš ï¸  é—œé–‰é€£æ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def main():
    """å‘½ä»¤åˆ—ä»‹é¢"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AS-Norm Cohort è³‡æ–™åº«ç®¡ç†å·¥å…·")
    parser.add_argument("--action", choices=["init", "reset", "import", "stats", "export"], 
                       default="stats", help="åŸ·è¡Œçš„å‹•ä½œ")
    parser.add_argument("--folder", type=str, help="è¦å°å…¥çš„éŸ³é »è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--dataset-prefix", type=str, 
                       help="ä¾†æºè³‡æ–™é›†å‰ç¶´ï¼Œè‹¥ä¸æŒ‡å®šå‰‡ç›´æ¥ä½¿ç”¨æª”å")
    parser.add_argument("--gender", type=str, help="èªè€…æ€§åˆ¥")
    parser.add_argument("--language", type=str, default="zh", help="èªéŸ³èªè¨€")
    parser.add_argument("--output", type=str, help="åŒ¯å‡ºæª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--force", action="store_true", 
                       help="å¼·åˆ¶åŸ·è¡Œé‡ç½®æ“ä½œï¼ˆå¿½ç•¥è³‡æ–™ç¢ºèªï¼‰")
    
    args = parser.parse_args()
    
    manager = CohortDatabaseManager()
    
    try:
        if args.action == "init":
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– cohort collection...")
            success = manager.initialize_cohort_collection()
            print(f"âœ… åˆå§‹åŒ–{'æˆåŠŸ' if success else 'å¤±æ•—'}")
            
        elif args.action == "reset":
            print("ğŸ—‘ï¸  æ­£åœ¨é‡ç½® cohort collection...")
            success = manager.reset_cohort_collection(force=args.force)
            print(f"âœ… é‡ç½®{'æˆåŠŸ' if success else 'å¤±æ•—'}")
            if not success and not args.force:
                print("ğŸ’¡ æç¤ºï¼šå¦‚éœ€å¼·åˆ¶é‡ç½®ï¼Œè«‹åŠ ä¸Š --force åƒæ•¸")
            
        elif args.action == "import":
            if not args.folder:
                print("âŒ è«‹æŒ‡å®šè¦å°å…¥çš„éŸ³é »è³‡æ–™å¤¾è·¯å¾‘ (--folder)")
                return
            
            # æº–å‚™å…ƒæ•¸æ“š
            metadata = {}
            if args.gender:
                metadata["gender"] = args.gender
            if args.language:
                metadata["language"] = args.language
            
            print(f"ğŸ“ æ­£åœ¨å°å…¥éŸ³é »è³‡æ–™å¤¾: {args.folder}")
            results = manager.import_audio_folder(
                args.folder, args.dataset_prefix, metadata=metadata
            )
            
            print(f"ğŸ“ˆ å°å…¥å®Œæˆ:")
            for key, value in results.items():
                print(f"   {key}: {value}")
                
        elif args.action == "stats":
            print("ğŸ“Š æ­£åœ¨ç²å– cohort çµ±è¨ˆä¿¡æ¯...")
            stats = manager.get_cohort_statistics()
            print(f"ğŸ“ˆ çµ±è¨ˆçµæœ:")
            for key, value in stats.items():
                print(f"   {key}: {value}")
                
        elif args.action == "export":
            print("ğŸ“„ æ­£åœ¨åŒ¯å‡º cohort ä¿¡æ¯...")
            output_file = manager.export_cohort_info(args.output)
            if output_file:
                print(f"âœ… ä¿¡æ¯å·²åŒ¯å‡ºåˆ°: {output_file}")
            
    finally:
        manager.close()


if __name__ == "__main__":
    main()
