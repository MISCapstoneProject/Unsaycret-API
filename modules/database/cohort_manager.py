"""
===============================================================================
AS-Norm Cohort è³‡æ–™åº«ç®¡ç†æ¨¡çµ„
===============================================================================

ç‰ˆæœ¬ï¼šv1.0.0
ä½œè€…ï¼šCYouuu  
æœ€å¾Œæ›´æ–°ï¼š2025-08-25

åŠŸèƒ½æ‘˜è¦ï¼š
-----------
æœ¬æ¨¡çµ„æä¾› AS-Norm å°ˆç”¨çš„ cohort è³‡æ–™åº«ç®¡ç†åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š

1. Cohort Collection çš„å»ºç«‹èˆ‡ç®¡ç†
2. éŸ³é »æª”æ¡ˆæ‰¹é‡è™•ç†èˆ‡è²ç´‹æå–
3. Cohort è³‡æ–™çš„å°å…¥èˆ‡æ›´æ–°
4. è³‡æ–™åº«åˆå§‹åŒ–èˆ‡é‡ç½®åŠŸèƒ½

è¨­è¨ˆåŸå‰‡ï¼š
-----------
- éš”é›¢æ€§ï¼šcohort è³‡æ–™èˆ‡å¯¦éš›èªè€…è³‡æ–™å®Œå…¨åˆ†é›¢  
- ç©©å®šæ€§ï¼šcohort é›†åˆå›ºå®šï¼Œä¸æœƒå› æ–°å¢èªè€…è€Œæ”¹è®Š
- å°ˆç”¨æ€§ï¼šcohort åƒ…ç”¨æ–¼ AS-Norm è¨ˆç®—ï¼Œä¸åƒèˆ‡å¯¦éš›è¾¨è­˜

æŠ€è¡“æ¶æ§‹ï¼š
-----------
- è²ç´‹æå–ï¼šSpeechBrain ECAPA-TDNN æ¨¡å‹
- å‘é‡è³‡æ–™åº«ï¼šWeaviate V2
- éŸ³é »è™•ç†ï¼šlibrosa + soundfile
- åˆ‡ç‰‡ç­–ç•¥ï¼šå›ºå®šé•·åº¦åˆ‡ç‰‡ + é‡ç–Šçª—å£

ä½¿ç”¨æ–¹å¼ï¼š
-----------
1. åˆå§‹åŒ– cohort è³‡æ–™åº«ï¼š
   ```python
   manager = CohortDatabaseManager()
   manager.initialize_cohort_collection()
   ```

2. å°å…¥å–®å€‹éŸ³é »æª”æ¡ˆï¼š
   ```python
   manager.import_audio_file("/path/to/audio.wav")  # è‡ªå‹•ä½¿ç”¨æª”åä½œç‚º source_dataset
   ```

3. å¾éŸ³é »è³‡æ–™å¤¾æ‰¹é‡å°å…¥ cohortï¼š
   ```python
   manager.import_audio_folder("/path/to/cohort/audio")  # æ¯å€‹æª”æ¡ˆä½¿ç”¨æª”åä½œç‚º source_dataset
   ```

4. é‡ç½® cohort è³‡æ–™åº«ï¼š
   ```python
   manager.reset_cohort_collection()
   ```

æ³¨æ„ï¼šç¾åœ¨ç›´æ¥è™•ç†æ•´å€‹éŸ³æª”ï¼ˆ6ç§’ï¼‰ï¼Œä¸å†é€²è¡Œåˆ‡ç‰‡è™•ç†ã€‚
"""

import os
import sys
import logging
import numpy as np
import librosa
import soundfile as sf
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path

# æ·»åŠ æ¨¡çµ„è·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.insert(0, project_root)

import weaviate
import torch
from speechbrain.inference import SpeakerRecognition
from scipy.spatial.distance import cosine
from scipy.signal import resample_poly  # æ–°å¢ï¼šèˆ‡ VID_identify_v5.py ä¸€è‡´çš„é‡æ–°æ¡æ¨£
import weaviate.classes as wc
from weaviate.classes.query import Filter

# å°å…¥é …ç›®æ¨¡çµ„
from utils.logger import get_logger
from utils.env_config import get_model_save_dir, HF_ACCESS_TOKEN
from utils.constants import (
    AS_NORM_COHORT_COLLECTION, SPEECHBRAIN_SPEAKER_MODEL,
    AUDIO_TARGET_RATE, AUDIO_SAMPLE_RATE,
    ENABLE_AS_NORM, AS_NORM_COHORT_SIZE, AS_NORM_TOP_K, AS_NORM_ALPHA,
    ENABLE_T_NORM, ENABLE_Z_NORM, ENABLE_S_NORM, AS_NORM_USE_DEDICATED_COHORT
)

# å‰µå»ºæ¨¡çµ„å°ˆå±¬æ—¥èªŒå™¨
logger = get_logger(__name__)


class ASNormProcessor:
    """
    AS-Norm (Adaptive Score Normalization) è™•ç†å™¨
    
    å¯¦ç¾å¤šç¨®æ­£è¦åŒ–æŠ€è¡“ï¼š
    - T-Norm (Test Normalization): ä½¿ç”¨ impostor æ¨¡å‹çš„åˆ†æ•¸é€²è¡Œæ­£è¦åŒ–
    - Z-Norm (Zero Normalization): ä½¿ç”¨çµ±è¨ˆ Z-score æ­£è¦åŒ–
    - S-Norm (Symmetric Normalization): çµåˆ T-Norm å’Œ Z-Norm
    
    ä¸»è¦ç›®çš„ï¼šæ”¹å–„èªè€…è­˜åˆ¥çš„ç©©å®šæ€§å’Œæº–ç¢ºæ€§ï¼Œæ¸›å°‘æ¢ä»¶è®Šç•°çš„å½±éŸ¿
    """
    
    def __init__(self, database_client=None):
        """
        åˆå§‹åŒ– AS-Norm è™•ç†å™¨
        
        Args:
            database_client: Weaviate è³‡æ–™åº«å®¢æˆ¶ç«¯å¯¦ä¾‹
        """
        self.client = database_client
        self.cohort_size = AS_NORM_COHORT_SIZE
        self.top_k = AS_NORM_TOP_K
        self.alpha = AS_NORM_ALPHA
        
        # çµ±è¨ˆè³‡æ–™ç·©å­˜
        self._impostor_stats = {}
        self._stats_cache_size = 100
        
    def set_database_client(self, client):
        """è¨­å®šè³‡æ–™åº«å®¢æˆ¶ç«¯"""
        self.client = client
        
    def compute_t_norm_score(self, test_embedding: np.ndarray, target_embedding: np.ndarray, 
                           impostor_embeddings: List[np.ndarray]) -> float:
        """
        è¨ˆç®— T-Norm æ­£è¦åŒ–åˆ†æ•¸
        
        T-Norm é€šéä½¿ç”¨ impostor æ¨¡å‹åˆ†æ•¸ä¾†æ­£è¦åŒ–ç›®æ¨™åˆ†æ•¸
        å…¬å¼: (score - mean_impostor) / std_impostor
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡  
            impostor_embeddings: impostor èªè€…çš„åµŒå…¥å‘é‡åˆ—è¡¨
            
        Returns:
            float: T-Norm æ­£è¦åŒ–å¾Œçš„åˆ†æ•¸
        """
        if not impostor_embeddings:
            # æ²’æœ‰ impostor æ™‚ï¼Œè¿”å›åŸå§‹é¤˜å¼¦è·é›¢
            return cosine(test_embedding, target_embedding)
            
        # è¨ˆç®—ç›®æ¨™åˆ†æ•¸ï¼ˆé¤˜å¼¦è·é›¢ï¼‰
        target_score = cosine(test_embedding, target_embedding)
        
        # è¨ˆç®— impostor åˆ†æ•¸
        impostor_scores = []
        for imp_embedding in impostor_embeddings:
            imp_score = cosine(test_embedding, imp_embedding)
            impostor_scores.append(imp_score)
            
        # è¨ˆç®— impostor åˆ†æ•¸çš„çµ±è¨ˆé‡
        mean_impostor = np.mean(impostor_scores)
        std_impostor = np.std(impostor_scores)
        
        # T-Norm æ­£è¦åŒ–
        if std_impostor > 0:
            t_norm_score = (target_score - mean_impostor) / std_impostor
        else:
            t_norm_score = target_score
            
        return t_norm_score
    
    def compute_z_norm_score(self, test_embedding: np.ndarray, target_embedding: np.ndarray) -> float:
        """
        è¨ˆç®— Z-Norm æ­£è¦åŒ–åˆ†æ•¸
        
        Z-Norm ä½¿ç”¨æ¸¬è©¦èªéŸ³å°æ‰€æœ‰å·²çŸ¥èªè€…çš„çµ±è¨ˆåˆ†å¸ƒé€²è¡Œæ­£è¦åŒ–
        å…¬å¼: (score - mean_all) / std_all
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡
            
        Returns:
            float: Z-Norm æ­£è¦åŒ–å¾Œçš„åˆ†æ•¸
        """
        # è¨ˆç®—ç›®æ¨™åˆ†æ•¸
        target_score = cosine(test_embedding, target_embedding)
        
        # ç²å–æ‰€æœ‰èªè€…çš„åµŒå…¥å‘é‡
        all_embeddings = self._get_all_speaker_embeddings()
        
        if not all_embeddings:
            return target_score
            
        # è¨ˆç®—å°æ‰€æœ‰èªè€…çš„åˆ†æ•¸
        all_scores = []
        for embedding in all_embeddings:
            score = cosine(test_embedding, embedding)
            all_scores.append(score)
            
        # Z-Norm æ­£è¦åŒ–
        mean_all = np.mean(all_scores)
        std_all = np.std(all_scores)
        
        if std_all > 0:
            z_norm_score = (target_score - mean_all) / std_all
        else:
            z_norm_score = target_score
            
        return z_norm_score
    
    def compute_s_norm_score(self, test_embedding: np.ndarray, target_embedding: np.ndarray,
                           impostor_embeddings: List[np.ndarray]) -> float:
        """
        è¨ˆç®— S-Norm (Symmetric Normalization) æ­£è¦åŒ–åˆ†æ•¸
        
        S-Norm çµåˆ T-Norm å’Œ Z-Norm çš„å„ªé»
        å…¬å¼: alpha * t_norm + (1-alpha) * z_norm
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡
            impostor_embeddings: impostor èªè€…çš„åµŒå…¥å‘é‡åˆ—è¡¨
            
        Returns:
            float: S-Norm æ­£è¦åŒ–å¾Œçš„åˆ†æ•¸
        """
        # è¨ˆç®— T-Norm åˆ†æ•¸
        t_norm_score = self.compute_t_norm_score(test_embedding, target_embedding, impostor_embeddings)
        
        # è¨ˆç®— Z-Norm åˆ†æ•¸
        z_norm_score = self.compute_z_norm_score(test_embedding, target_embedding)
        
        # S-Norm çµåˆ
        s_norm_score = self.alpha * t_norm_score + (1 - self.alpha) * z_norm_score
        
        return s_norm_score
    
    def apply_as_norm(self, test_embedding: np.ndarray, target_embedding: np.ndarray,
                     target_id: str) -> float:
        """
        æ‡‰ç”¨ AS-Norm è™•ç†
        
        æ ¹æ“šé…ç½®é¸æ“‡æ€§åœ°æ‡‰ç”¨ä¸åŒçš„æ­£è¦åŒ–æ–¹æ³•
        
        Args:
            test_embedding: æ¸¬è©¦éŸ³è¨Šçš„åµŒå…¥å‘é‡
            target_embedding: ç›®æ¨™èªè€…çš„åµŒå…¥å‘é‡
            target_id: ç›®æ¨™èªè€…ID
            
        Returns:
            float: æ­£è¦åŒ–å¾Œçš„åˆ†æ•¸
        """
        if not ENABLE_AS_NORM:
            # AS-Norm é—œé–‰æ™‚ï¼Œè¿”å›åŸå§‹é¤˜å¼¦è·é›¢
            original_score = cosine(test_embedding, target_embedding)
            logger.debug(f"âšª AS-Norm å·²åœç”¨ï¼Œè¿”å›åŸå§‹é¤˜å¼¦è·é›¢: {original_score:.4f}")
            return original_score
            
        # è¨ˆç®—åŸå§‹é¤˜å¼¦è·é›¢ä½œç‚ºå°æ¯”
        original_score = cosine(test_embedding, target_embedding)
        logger.debug(f"ğŸ“ åŸå§‹é¤˜å¼¦è·é›¢: {original_score:.4f}")
        
        # ç²å– impostor åµŒå…¥å‘é‡
        impostor_embeddings = self._get_impostor_embeddings(target_id)
        
        # æ ¹æ“šé…ç½®é¸æ“‡æ­£è¦åŒ–æ–¹æ³•
        if ENABLE_S_NORM and ENABLE_T_NORM and ENABLE_Z_NORM:
            # å®Œæ•´ S-Norm
            logger.debug("ğŸ”§ ä½¿ç”¨å®Œæ•´ S-Norm (T-Norm + Z-Norm çµ„åˆ)")
            normalized_score = self.compute_s_norm_score(test_embedding, target_embedding, impostor_embeddings)
        elif ENABLE_T_NORM and ENABLE_Z_NORM:
            # T-Norm + Z-Norm çµ„åˆ
            logger.debug("ğŸ”§ ä½¿ç”¨ T-Norm + Z-Norm çµ„åˆ")
            t_score = self.compute_t_norm_score(test_embedding, target_embedding, impostor_embeddings)
            z_score = self.compute_z_norm_score(test_embedding, target_embedding)
            normalized_score = 0.5 * t_score + 0.5 * z_score
        elif ENABLE_T_NORM:
            # åƒ… T-Norm
            logger.debug("ğŸ”§ ä½¿ç”¨ T-Norm æ­£è¦åŒ–")
            normalized_score = self.compute_t_norm_score(test_embedding, target_embedding, impostor_embeddings)
        elif ENABLE_Z_NORM:
            # åƒ… Z-Norm
            logger.debug("ğŸ”§ ä½¿ç”¨ Z-Norm æ­£è¦åŒ–")
            normalized_score = self.compute_z_norm_score(test_embedding, target_embedding)
        else:
            # æ‰€æœ‰æ­£è¦åŒ–éƒ½é—œé–‰ï¼Œè¿”å›åŸå§‹åˆ†æ•¸
            logger.debug("âšª æ‰€æœ‰æ­£è¦åŒ–æ–¹æ³•éƒ½å·²åœç”¨ï¼Œè¿”å›åŸå§‹åˆ†æ•¸")
            normalized_score = original_score
        
        # è¨˜éŒ„æ­£è¦åŒ–æ•ˆæœ
        improvement = original_score - normalized_score
        logger.debug(f"ğŸ“Š æ­£è¦åŒ–çµæœ: {original_score:.4f} â†’ {normalized_score:.4f} (æ”¹å–„: {improvement:+.4f})")
        
        return normalized_score
    
    def _get_impostor_embeddings(self, target_id: str) -> List[np.ndarray]:
        """
        ç²å– impostor èªè€…çš„åµŒå…¥å‘é‡ï¼ˆç”¨æ–¼ T-Normï¼‰
        
        å¦‚æœå•Ÿç”¨å°ˆé–€çš„cohortè³‡æ–™åº«ï¼Œå‰‡å¾CohortVoicePrint collectionç²å–
        å¦å‰‡å¾ä¸»è¦çš„VoicePrint collectionä¸­æ’é™¤ç›®æ¨™èªè€…å¾Œç²å–
        
        Args:
            target_id: ç›®æ¨™èªè€…ID
            
        Returns:
            List[np.ndarray]: impostor åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not self.client:
            logger.warning("è³‡æ–™åº«å®¢æˆ¶ç«¯æœªè¨­å®šï¼Œç„¡æ³•ç²å– impostor åµŒå…¥å‘é‡")
            return []
            
        try:
            # æ ¹æ“šé…ç½®é¸æ“‡è³‡æ–™ä¾†æº
            if AS_NORM_USE_DEDICATED_COHORT:
                collection_name = AS_NORM_COHORT_COLLECTION
                # æª¢æŸ¥å°ˆé–€çš„cohort collectionæ˜¯å¦å­˜åœ¨
                if not self.client.collections.exists(collection_name):
                    logger.warning(f"å°ˆé–€çš„cohort collection '{collection_name}' ä¸å­˜åœ¨ï¼Œå›é€€åˆ°ä¸»è³‡æ–™åº«")
                    collection_name = "VoicePrint"
                    use_where_filter = True
                else:
                    use_where_filter = False  # cohortè³‡æ–™åº«ä¸­æ²’æœ‰ç›®æ¨™èªè€…ï¼Œä¸éœ€è¦éæ¿¾
            else:
                collection_name = "VoicePrint"
                use_where_filter = True
            
            collection = self.client.collections.get(collection_name)
            
            # æ ¹æ“šæ˜¯å¦éœ€è¦éæ¿¾ç›®æ¨™èªè€…ä¾†æ§‹å»ºæŸ¥è©¢
            if use_where_filter:
                results = collection.query.fetch_objects(
                    where=Filter.by_property("speaker_name").not_equal(target_id),
                    return_properties=["speaker_name"],
                    include_vector=True,
                    limit=self.top_k  # ç›´æ¥æŸ¥è©¢ top_k æ•¸é‡ï¼Œé¿å…ä¸å¿…è¦çš„è³‡æ–™å‚³è¼¸
                )
            else:
                # å¾å°ˆé–€çš„cohortè³‡æ–™åº«ç²å–ï¼Œä¸éœ€è¦éæ¿¾
                results = collection.query.fetch_objects(
                    include_vector=True,
                    limit=self.top_k
                )
            
            impostor_embeddings = []
            for obj in results.objects:
                if obj.vector:
                    # è™•ç† named vector
                    vec_dict = obj.vector
                    raw_vec = vec_dict["default"] if isinstance(vec_dict, dict) else vec_dict
                    embedding = np.array(raw_vec, dtype=float)
                    impostor_embeddings.append(embedding)
            
            logger.debug(f"å¾ {collection_name} ç²å–äº† {len(impostor_embeddings)} å€‹ impostor åµŒå…¥å‘é‡")
            return impostor_embeddings  # å·²ç¶“é™åˆ¶åœ¨ top_k æ•¸é‡å…§
            
        except Exception as e:
            logger.warning(f"ç²å– impostor åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []
    
    def _get_all_speaker_embeddings(self) -> List[np.ndarray]:
        """
        ç²å–èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡ï¼ˆç”¨æ–¼ Z-Normï¼‰
        
        å¦‚æœå•Ÿç”¨å°ˆé–€çš„cohortè³‡æ–™åº«ï¼Œå‰‡å¾CohortVoicePrint collectionç²å–
        å¦å‰‡å¾ä¸»è¦çš„VoicePrint collectionç²å–
        
        Returns:
            List[np.ndarray]: èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡åˆ—è¡¨
        """
        if not self.client:
            logger.warning("è³‡æ–™åº«å®¢æˆ¶ç«¯æœªè¨­å®šï¼Œç„¡æ³•ç²å–èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡")
            return []
            
        try:
            # æ ¹æ“šé…ç½®é¸æ“‡è³‡æ–™ä¾†æº
            if AS_NORM_USE_DEDICATED_COHORT:
                collection_name = AS_NORM_COHORT_COLLECTION
                # æª¢æŸ¥å°ˆé–€çš„cohort collectionæ˜¯å¦å­˜åœ¨
                if not self.client.collections.exists(collection_name):
                    logger.warning(f"å°ˆé–€çš„cohort collection '{collection_name}' ä¸å­˜åœ¨ï¼Œå›é€€åˆ°ä¸»è³‡æ–™åº«")
                    collection_name = "VoicePrint"
            else:
                collection_name = "VoicePrint"
            
            collection = self.client.collections.get(collection_name)
            
            results = collection.query.fetch_objects(
                include_vector=True,
                limit=self.cohort_size  # Z-Norm éœ€è¦æ›´å¤šæ¨£æœ¬ä¾†è¨ˆç®—çµ±è¨ˆé‡
            )
            
            all_embeddings = []
            for obj in results.objects:
                if obj.vector:
                    # è™•ç† named vector
                    vec_dict = obj.vector
                    raw_vec = vec_dict["default"] if isinstance(vec_dict, dict) else vec_dict
                    embedding = np.array(raw_vec, dtype=float)
                    all_embeddings.append(embedding)
            
            logger.debug(f"å¾ {collection_name} ç²å–äº† {len(all_embeddings)} å€‹èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡")
            return all_embeddings
            
        except Exception as e:
            logger.warning(f"ç²å–èƒŒæ™¯æ¨¡å‹åµŒå…¥å‘é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return []


class CohortDatabaseManager:
    """AS-Norm Cohort è³‡æ–™åº«ç®¡ç†å™¨"""
    
    def __init__(self, model_name: str = None) -> None:
        """
        åˆå§‹åŒ– Cohort è³‡æ–™åº«ç®¡ç†å™¨
        
        Args:
            model_name: è²ç´‹æå–æ¨¡å‹åç¨±ï¼Œé è¨­ä½¿ç”¨ SPEECHBRAIN_SPEAKER_MODEL
        """
        self.model_name = model_name or SPEECHBRAIN_SPEAKER_MODEL
        self.client = None
        self.speaker_model = None
        self._connect_database()
        self._init_speaker_model()
    
    def _connect_database(self) -> None:
        """é€£æ¥åˆ° Weaviate è³‡æ–™åº«"""
        try:
            self.client = weaviate.connect_to_local()
            logger.info("ğŸ”— æˆåŠŸé€£æ¥åˆ° Weaviate è³‡æ–™åº«")
        except Exception as e:
            logger.error(f"âŒ é€£æ¥åˆ° Weaviate å¤±æ•—: {e}")
            raise
    
    def _init_speaker_model(self) -> None:
        """åˆå§‹åŒ–è²ç´‹æå–æ¨¡å‹"""
        try:
            logger.info(f"ğŸ”§ æ­£åœ¨è¼‰å…¥è²ç´‹æå–æ¨¡å‹: {self.model_name}")
            
            # è¨­å®šæ¨¡å‹å¿«å–ç›®éŒ„
            model_save_dir = get_model_save_dir("speechbrain_recognition")
            os.makedirs(model_save_dir, exist_ok=True)
            
            # è¨­å®šè¨­å‚™
            self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            logger.info(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}")
            
            # è¼‰å…¥ SpeechBrain èªè€…è¾¨è­˜æ¨¡å‹
            self.speaker_model = SpeakerRecognition.from_hparams(
                source=self.model_name,
                savedir=model_save_dir,
                use_auth_token=HF_ACCESS_TOKEN
            )
            logger.info("âœ… è²ç´‹æå–æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥è²ç´‹æå–æ¨¡å‹å¤±æ•—: {e}")
            raise
    
    def initialize_cohort_collection(self) -> bool:
        """
        åˆå§‹åŒ– cohort collection
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸå»ºç«‹æˆ–ç¢ºèª collection å­˜åœ¨
        """
        if not self.client:
            logger.error("âŒ è³‡æ–™åº«å®¢æˆ¶ç«¯æœªé€£æ¥")
            return False
        
        try:
            logger.info(f"ğŸ—ï¸  æ­£åœ¨åˆå§‹åŒ– cohort collection: {AS_NORM_COHORT_COLLECTION}")
            
            # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨
            if self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                logger.info(f"âœ… Cohort collection '{AS_NORM_COHORT_COLLECTION}' å·²å­˜åœ¨")
                return True
            
            # å»ºç«‹ AS-Norm å°ˆç”¨çš„ Cohort VoicePrint é›†åˆ
            # é€™å€‹é›†åˆå­˜æ”¾ä¸æœƒåœ¨å¯¦éš›è¾¨è­˜ä¸­å‡ºç¾çš„èƒŒæ™¯èªéŸ³è³‡æ–™
            cohort_collection = self.client.collections.create(
                name=AS_NORM_COHORT_COLLECTION,
                properties=[
                    wc.Property(name="create_time", data_type=wc.DataType.DATE),
                    wc.Property(name="cohort_id", data_type=wc.DataType.TEXT),  # èƒŒæ™¯æ¨¡å‹è­˜åˆ¥ç¢¼
                    wc.Property(name="source_dataset", data_type=wc.DataType.TEXT),  # ä¾†æºè³‡æ–™é›†
                    wc.Property(name="gender", data_type=wc.DataType.TEXT),  # æ€§åˆ¥ï¼ˆå¯é¸ï¼‰
                    wc.Property(name="language", data_type=wc.DataType.TEXT),  # èªè¨€ï¼ˆå¯é¸ï¼‰
                    wc.Property(name="description", data_type=wc.DataType.TEXT),  # æè¿°
                ],
                vectorizer_config=wc.Configure.Vectorizer.none(),
                vector_index_config=wc.Configure.VectorIndex.hnsw(
                    distance_metric=wc.VectorDistances.COSINE
                )
            )
            logger.info(f"âœ… æˆåŠŸå»ºç«‹ cohort collection '{AS_NORM_COHORT_COLLECTION}'")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ– cohort collection æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def reset_cohort_collection(self) -> bool:
        """
        é‡ç½® cohort collectionï¼ˆåˆªé™¤æ‰€æœ‰è³‡æ–™ä¸¦é‡æ–°å»ºç«‹ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸé‡ç½®
        """
        try:
            logger.info(f"ğŸ—‘ï¸  æ­£åœ¨é‡ç½® cohort collection: {AS_NORM_COHORT_COLLECTION}")
            
            # åˆªé™¤ç¾æœ‰ collection
            if self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                self.client.collections.delete(AS_NORM_COHORT_COLLECTION)
                logger.info(f"ğŸ—‘ï¸  å·²åˆªé™¤ç¾æœ‰çš„ cohort collection")
            
            # é‡æ–°å»ºç«‹
            success = self.initialize_cohort_collection()
            if success:
                logger.info(f"âœ… æˆåŠŸé‡ç½® cohort collection")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ é‡ç½® cohort collection æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return False
    
    def resample_audio(self, signal: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """
        ä½¿ç”¨ scipy é€²è¡Œé«˜å“è³ªé‡æ–°æ¡æ¨£ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
        
        Args:
            signal: éŸ³é »ä¿¡è™Ÿ
            orig_sr: åŸå§‹æ¡æ¨£ç‡
            target_sr: ç›®æ¨™æ¡æ¨£ç‡
            
        Returns:
            np.ndarray: é‡æ–°æ¡æ¨£å¾Œçš„éŸ³é »ä¿¡è™Ÿ
        """
        return resample_poly(signal, target_sr, orig_sr)
    
    def extract_embedding(self, audio_path: str) -> Optional[np.ndarray]:
        """
        å¾éŸ³é »æª”æ¡ˆæå–è²ç´‹åµŒå…¥å‘é‡
        èˆ‡ VID_identify_v5.py ä¿æŒå®Œå…¨ä¸€è‡´çš„å¯¦ä½œ
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            
        Returns:
            Optional[np.ndarray]: è²ç´‹åµŒå…¥å‘é‡ï¼Œå¤±æ•—æ™‚è¿”å› None
        """
        try:
            # è¼‰å…¥éŸ³é »æª”æ¡ˆï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´çš„æ–¹å¼ï¼‰
            waveform, sample_rate = librosa.load(audio_path, sr=None)  # ä¿æŒåŸå§‹æ¡æ¨£ç‡
            
            # è™•ç†ç«‹é«”è²è½‰å–®è²é“ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            if waveform.ndim > 1:
                waveform = waveform.mean(axis=1)
            
            # é‡æ–°æ¡æ¨£åˆ°ç›®æ¨™æ¡æ¨£ç‡ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            target_sr = AUDIO_TARGET_RATE
            if sample_rate != target_sr:
                waveform = self.resample_audio(waveform, sample_rate, target_sr)
            
            # æª¢æŸ¥éŸ³é »é•·åº¦ï¼ˆè‡³å°‘éœ€è¦ 1 ç§’ï¼‰
            min_length = target_sr  # 1 ç§’
            if len(waveform) < min_length:
                logger.warning(f"âš ï¸  éŸ³é »æª”æ¡ˆå¤ªçŸ­ï¼Œè·³é: {audio_path} ({len(waveform)/target_sr:.2f}s)")
                return None
            
            # è½‰æ›ç‚ºå¼µé‡ä¸¦è¨­ç½®æ­£ç¢ºçš„è¨­å‚™ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            waveform_tensor = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).to(self.device)
            embedding = self.speaker_model.encode_batch(waveform_tensor)
            
            # è½‰æ›ç‚º numpy array ä¸¦æ­£è¦åŒ–ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            embedding_np = embedding.squeeze().cpu().numpy()
            embedding_np = embedding_np / np.linalg.norm(embedding_np)  # L2 æ­£è¦åŒ–
            
            return embedding_np
            
        except Exception as e:
            logger.warning(f"âš ï¸  æå–è²ç´‹å¤±æ•—: {audio_path} - {e}")
            return None
    
    def split_audio(self, audio_path: str, chunk_length: float = 6.0, 
                   overlap: float = 0.5) -> List[Tuple[np.ndarray, float, float]]:
        """
        å°‡éŸ³é »æª”æ¡ˆåˆ‡ç‰‡
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            chunk_length: åˆ‡ç‰‡é•·åº¦ï¼ˆç§’ï¼‰
            overlap: é‡ç–Šæ¯”ä¾‹ï¼ˆ0-1ï¼‰
            
        Returns:
            List[Tuple[np.ndarray, float, float]]: (éŸ³é »ç‰‡æ®µ, é–‹å§‹æ™‚é–“, çµæŸæ™‚é–“) åˆ—è¡¨
        """
        chunks = []
        
        try:
            # è¼‰å…¥éŸ³é »æª”æ¡ˆï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            waveform, sample_rate = librosa.load(audio_path, sr=None)  # ä¿æŒåŸå§‹æ¡æ¨£ç‡
            
            # è™•ç†ç«‹é«”è²è½‰å–®è²é“ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            if waveform.ndim > 1:
                waveform = waveform.mean(axis=1)
            
            # é‡æ–°æ¡æ¨£åˆ°ç›®æ¨™æ¡æ¨£ç‡ï¼ˆèˆ‡ VID_identify_v5.py ä¸€è‡´ï¼‰
            target_sr = AUDIO_TARGET_RATE
            if sample_rate != target_sr:
                waveform = self.resample_audio(waveform, sample_rate, target_sr)
                sample_rate = target_sr  # æ›´æ–°æ¡æ¨£ç‡è®Šæ•¸
            
            audio_length = len(waveform) / sample_rate
            
            # è¨ˆç®—åˆ‡ç‰‡åƒæ•¸
            chunk_samples = int(chunk_length * sample_rate)
            step_samples = int(chunk_samples * (1 - overlap))
            
            # å¦‚æœéŸ³é »å¤ªçŸ­ï¼Œç›´æ¥è¿”å›æ•´å€‹éŸ³é »
            if audio_length < chunk_length:
                chunks.append((waveform, 0.0, audio_length))
                return chunks
            
            # åˆ‡ç‰‡è™•ç†
            start_sample = 0
            chunk_id = 0
            
            while start_sample + chunk_samples <= len(waveform):
                end_sample = start_sample + chunk_samples
                chunk = waveform[start_sample:end_sample]
                
                start_time = start_sample / sample_rate
                end_time = end_sample / sample_rate
                
                chunks.append((chunk, start_time, end_time))
                
                start_sample += step_samples
                chunk_id += 1
            
            logger.debug(f"ğŸ”ª éŸ³é »åˆ‡ç‰‡å®Œæˆ: {audio_path} -> {len(chunks)} å€‹ç‰‡æ®µ")
            return chunks
            
        except Exception as e:
            logger.error(f"âŒ éŸ³é »åˆ‡ç‰‡å¤±æ•—: {audio_path} - {e}")
            return []
    
    def import_audio_file(self, audio_path: str, source_dataset: str = None,
                         metadata: Dict[str, Any] = None) -> int:
        """
        å°å…¥å–®å€‹éŸ³é »æª”æ¡ˆåˆ° cohort è³‡æ–™åº«ï¼ˆç›´æ¥è™•ç†æ•´å€‹éŸ³æª”ï¼Œä¸åˆ‡ç‰‡ï¼‰
        
        Args:
            audio_path: éŸ³é »æª”æ¡ˆè·¯å¾‘
            source_dataset: ä¾†æºè³‡æ–™é›†åç¨±ï¼Œè‹¥ç‚º None å‰‡ä½¿ç”¨æª”åï¼ˆä¸å«å‰¯æª”åï¼‰
            metadata: é¡å¤–çš„å…ƒæ•¸æ“š
            
        Returns:
            int: æˆåŠŸå°å…¥çš„è²ç´‹æ•¸é‡ï¼ˆ0 æˆ– 1ï¼‰
        """
        if not self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
            logger.error(f"âŒ Cohort collection '{AS_NORM_COHORT_COLLECTION}' ä¸å­˜åœ¨ï¼Œè«‹å…ˆåˆå§‹åŒ–")
            return 0
        
        file_name = Path(audio_path).stem
        
        # å¦‚æœæ²’æœ‰æŒ‡å®š source_datasetï¼Œä½¿ç”¨æª”å
        if source_dataset is None:
            source_dataset = file_name
        
        try:
            # ç›´æ¥æå–æ•´å€‹éŸ³æª”çš„åµŒå…¥å‘é‡ï¼ˆä¸åˆ‡ç‰‡ï¼‰
            embedding_np = self.extract_embedding(audio_path)
            
            if embedding_np is None:
                logger.warning(f"âš ï¸  ç„¡æ³•æå–åµŒå…¥å‘é‡: {audio_path}")
                return 0
            
            collection = self.client.collections.get(AS_NORM_COHORT_COLLECTION)
            
            # æº–å‚™å…ƒæ•¸æ“š
            properties = {
                "create_time": datetime.now(),
                "cohort_id": file_name,  # ä½¿ç”¨æª”åä½œç‚º cohort_id
                "source_dataset": source_dataset,  # ä½¿ç”¨æª”åæˆ–æŒ‡å®šçš„ source_dataset
                "gender": metadata.get("gender", "unknown") if metadata else "unknown",
                "language": metadata.get("language", "zh") if metadata else "zh",
                "description": f"å®Œæ•´éŸ³æª”: {file_name}"
            }
            
            # å¦‚æœæœ‰é¡å¤–å…ƒæ•¸æ“šï¼Œåˆä½µé€²å»
            if metadata:
                for key, value in metadata.items():
                    if key not in properties:
                        properties[key] = value
            
            # æ’å…¥åˆ°è³‡æ–™åº«
            collection.data.insert(
                properties=properties,
                vector=embedding_np.tolist()
            )
            
            logger.info(f"âœ… æˆåŠŸå°å…¥è²ç´‹: {audio_path} -> {source_dataset}")
            return 1
            
        except Exception as e:
            logger.error(f"âŒ å°å…¥éŸ³é »æª”æ¡ˆå¤±æ•—: {audio_path} - {e}")
            return 0
    
    def import_audio_folder(self, folder_path: str, source_dataset_prefix: str = None,
                           audio_extensions: List[str] = None,
                           metadata: Dict[str, Any] = None) -> Dict[str, int]:
        """
        å¾è³‡æ–™å¤¾æ‰¹é‡å°å…¥éŸ³é »æª”æ¡ˆåˆ° cohort è³‡æ–™åº«ï¼ˆç›´æ¥è™•ç†æ•´å€‹éŸ³æª”ï¼Œä¸åˆ‡ç‰‡ï¼‰
        
        Args:
            folder_path: éŸ³é »è³‡æ–™å¤¾è·¯å¾‘
            source_dataset_prefix: ä¾†æºè³‡æ–™é›†å‰ç¶´ï¼Œè‹¥ç‚º None å‰‡ç›´æ¥ä½¿ç”¨æª”å
            audio_extensions: æ”¯æ´çš„éŸ³é »å‰¯æª”å
            metadata: å…¨åŸŸå…ƒæ•¸æ“š
            
        Returns:
            Dict[str, int]: å°å…¥çµæœçµ±è¨ˆ
        """
        if audio_extensions is None:
            audio_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.aac', '.ogg']
        
        folder_path = Path(folder_path)
        if not folder_path.exists():
            logger.error(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
            return {"total_files": 0, "success_files": 0, "total_embeddings": 0}
        
        logger.info(f"ğŸ“ é–‹å§‹æ‰¹é‡å°å…¥éŸ³é »è³‡æ–™å¤¾: {folder_path}")
        
        # ç¢ºä¿ cohort collection å­˜åœ¨
        if not self.initialize_cohort_collection():
            logger.error("âŒ ç„¡æ³•åˆå§‹åŒ– cohort collection")
            return {"total_files": 0, "success_files": 0, "total_embeddings": 0}
        
        # æœå°‹éŸ³é »æª”æ¡ˆ
        audio_files = []
        for ext in audio_extensions:
            audio_files.extend(folder_path.rglob(f"*{ext}"))
            audio_files.extend(folder_path.rglob(f"*{ext.upper()}"))
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(audio_files)} å€‹éŸ³é »æª”æ¡ˆ")
        
        # æ‰¹é‡è™•ç†
        total_files = len(audio_files)
        success_files = 0
        total_embeddings = 0
        
        for i, audio_file in enumerate(audio_files, 1):
            logger.info(f"ğŸµ è™•ç†éŸ³é »æª”æ¡ˆ ({i}/{total_files}): {audio_file.name}")
            
            # ç‚ºæ¯å€‹æª”æ¡ˆæº–å‚™å…ƒæ•¸æ“š
            file_metadata = metadata.copy() if metadata else {}
            file_metadata.update({
                "original_file": audio_file.name,
                "file_path": str(audio_file.relative_to(folder_path))
            })
            
            # æ±ºå®š source_dataset åç¨±
            if source_dataset_prefix:
                source_dataset = f"{source_dataset_prefix}_{audio_file.stem}"
            else:
                source_dataset = audio_file.stem  # ç›´æ¥ä½¿ç”¨æª”å
            
            # å°å…¥æª”æ¡ˆï¼ˆä¸åˆ‡ç‰‡ï¼‰
            embeddings_count = self.import_audio_file(
                str(audio_file), source_dataset, file_metadata
            )
            
            if embeddings_count > 0:
                success_files += 1
                total_embeddings += embeddings_count
        
        # çµ±è¨ˆçµæœ
        results = {
            "total_files": total_files,
            "success_files": success_files,
            "failed_files": total_files - success_files,
            "total_embeddings": total_embeddings
        }
        
        logger.info(f"ğŸ“ˆ æ‰¹é‡å°å…¥å®Œæˆ:")
        logger.info(f"   ğŸ“ ç¸½æª”æ¡ˆæ•¸: {results['total_files']}")
        logger.info(f"   âœ… æˆåŠŸæª”æ¡ˆ: {results['success_files']}")
        logger.info(f"   âŒ å¤±æ•—æª”æ¡ˆ: {results['failed_files']}")
        logger.info(f"   ğŸ¯ ç¸½è²ç´‹æ•¸: {results['total_embeddings']}")
        
        return results
    
    def get_cohort_statistics(self) -> Dict[str, Any]:
        """
        ç²å– cohort è³‡æ–™åº«çµ±è¨ˆä¿¡æ¯
        
        Returns:
            Dict[str, Any]: çµ±è¨ˆä¿¡æ¯
        """
        try:
            if not self.client.collections.exists(AS_NORM_COHORT_COLLECTION):
                return {"exists": False, "count": 0}
            
            collection = self.client.collections.get(AS_NORM_COHORT_COLLECTION)
            
            # ç²å–ç¸½æ•¸
            aggregate_result = collection.aggregate.over_all(total_count=True)
            total_count = aggregate_result.total_count if aggregate_result.total_count else 0
            
            # ç²å–æ¨£æœ¬æ•¸æ“šä¾†åˆ†æ
            sample_results = collection.query.fetch_objects(
                limit=min(100, total_count),
                return_properties=["source_dataset", "gender", "language", "create_time"]
            )
            
            # çµ±è¨ˆåˆ†æ
            source_datasets = {}
            genders = {}
            languages = {}
            creation_dates = []
            
            for obj in sample_results.objects:
                if obj.properties:
                    # çµ±è¨ˆä¾†æºè³‡æ–™é›†
                    dataset = obj.properties.get("source_dataset", "unknown")
                    source_datasets[dataset] = source_datasets.get(dataset, 0) + 1
                    
                    # çµ±è¨ˆæ€§åˆ¥
                    gender = obj.properties.get("gender", "unknown")
                    genders[gender] = genders.get(gender, 0) + 1
                    
                    # çµ±è¨ˆèªè¨€
                    language = obj.properties.get("language", "unknown")
                    languages[language] = languages.get(language, 0) + 1
                    
                    # æ”¶é›†å»ºç«‹æ™‚é–“
                    if obj.properties.get("create_time"):
                        creation_dates.append(obj.properties["create_time"])
            
            # è¨ˆç®—æ™‚é–“ç¯„åœ
            time_range = {}
            if creation_dates:
                creation_dates.sort()
                time_range = {
                    "earliest": creation_dates[0].isoformat() if hasattr(creation_dates[0], 'isoformat') else str(creation_dates[0]),
                    "latest": creation_dates[-1].isoformat() if hasattr(creation_dates[-1], 'isoformat') else str(creation_dates[-1])
                }
            
            return {
                "exists": True,
                "total_count": total_count,
                "source_datasets": source_datasets,
                "genders": genders,
                "languages": languages,
                "time_range": time_range,
                "collection_name": AS_NORM_COHORT_COLLECTION
            }
            
        except Exception as e:
            logger.error(f"âŒ ç²å– cohort çµ±è¨ˆä¿¡æ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return {"exists": False, "count": 0, "error": str(e)}
    
    def export_cohort_info(self, output_file: str = None) -> str:
        """
        åŒ¯å‡º cohort è³‡æ–™åº«ä¿¡æ¯åˆ°æª”æ¡ˆ
        
        Args:
            output_file: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼Œè‹¥ç‚º None å‰‡è‡ªå‹•ç”Ÿæˆ
            
        Returns:
            str: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"cohort_info_{timestamp}.json"
        
        try:
            import json
            
            stats = self.get_cohort_statistics()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(stats, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ“„ Cohort ä¿¡æ¯å·²åŒ¯å‡ºåˆ°: {output_file}")
            return output_file
            
        except Exception as e:
            logger.error(f"âŒ åŒ¯å‡º cohort ä¿¡æ¯å¤±æ•—: {e}")
            return ""
    
    def create_as_norm_processor(self) -> ASNormProcessor:
        """
        å‰µå»º AS-Norm è™•ç†å™¨å¯¦ä¾‹
        
        Returns:
            ASNormProcessor: å·²é…ç½®çš„ AS-Norm è™•ç†å™¨
        """
        processor = ASNormProcessor(self.client)
        return processor
    
    def close(self) -> None:
        """é—œé–‰é€£æ¥ä¸¦æ¸…ç†è³‡æº"""
        try:
            if hasattr(self, 'client') and self.client:
                self.client.close()
                logger.info("ğŸ”Œ å·²é—œé–‰ Weaviate é€£æ¥")
        except Exception as e:
            logger.warning(f"âš ï¸  é—œé–‰é€£æ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def main():
    """å‘½ä»¤åˆ—ä»‹é¢"""
    import argparse
    
    parser = argparse.ArgumentParser(description="AS-Norm Cohort è³‡æ–™åº«ç®¡ç†å·¥å…·")
    parser.add_argument("--action", choices=["init", "reset", "import", "stats", "export"], 
                       default="stats", help="åŸ·è¡Œçš„å‹•ä½œ")
    parser.add_argument("--folder", type=str, help="è¦å°å…¥çš„éŸ³é »è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--dataset-prefix", type=str, 
                       help="ä¾†æºè³‡æ–™é›†å‰ç¶´ï¼Œè‹¥ä¸æŒ‡å®šå‰‡ç›´æ¥ä½¿ç”¨æª”å")
    parser.add_argument("--gender", type=str, help="èªè€…æ€§åˆ¥")
    parser.add_argument("--language", type=str, default="zh", help="èªéŸ³èªè¨€")
    parser.add_argument("--output", type=str, help="åŒ¯å‡ºæª”æ¡ˆè·¯å¾‘")
    
    args = parser.parse_args()
    
    manager = CohortDatabaseManager()
    
    try:
        if args.action == "init":
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– cohort collection...")
            success = manager.initialize_cohort_collection()
            print(f"âœ… åˆå§‹åŒ–{'æˆåŠŸ' if success else 'å¤±æ•—'}")
            
        elif args.action == "reset":
            print("ğŸ—‘ï¸  æ­£åœ¨é‡ç½® cohort collection...")
            success = manager.reset_cohort_collection()
            print(f"âœ… é‡ç½®{'æˆåŠŸ' if success else 'å¤±æ•—'}")
            
        elif args.action == "import":
            if not args.folder:
                print("âŒ è«‹æŒ‡å®šè¦å°å…¥çš„éŸ³é »è³‡æ–™å¤¾è·¯å¾‘ (--folder)")
                return
            
            # æº–å‚™å…ƒæ•¸æ“š
            metadata = {}
            if args.gender:
                metadata["gender"] = args.gender
            if args.language:
                metadata["language"] = args.language
            
            print(f"ğŸ“ æ­£åœ¨å°å…¥éŸ³é »è³‡æ–™å¤¾: {args.folder}")
            results = manager.import_audio_folder(
                args.folder, args.dataset_prefix, metadata=metadata
            )
            
            print(f"ğŸ“ˆ å°å…¥å®Œæˆ:")
            for key, value in results.items():
                print(f"   {key}: {value}")
                
        elif args.action == "stats":
            print("ğŸ“Š æ­£åœ¨ç²å– cohort çµ±è¨ˆä¿¡æ¯...")
            stats = manager.get_cohort_statistics()
            print(f"ğŸ“ˆ çµ±è¨ˆçµæœ:")
            for key, value in stats.items():
                print(f"   {key}: {value}")
                
        elif args.action == "export":
            print("ğŸ“„ æ­£åœ¨åŒ¯å‡º cohort ä¿¡æ¯...")
            output_file = manager.export_cohort_info(args.output)
            if output_file:
                print(f"âœ… ä¿¡æ¯å·²åŒ¯å‡ºåˆ°: {output_file}")
            
    finally:
        manager.close()


if __name__ == "__main__":
    main()
