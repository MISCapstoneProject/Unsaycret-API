# whisper_asr.py
from pathlib import Path
import json, csv, os, time ,torchaudio
from .asr_model import load_model
from .text_utils import merge_char_to_word
from utils.logger import get_logger
import torch


logger = get_logger(__name__)

# CSV ç´€éŒ„è·¯å¾‘
CSV_PATH = Path("work_output/asr_performance.csv")

class WhisperASR:
    counter = 0
    
    def __init__(self, model_name="medium", gpu=False, beam=5, lang="auto"):
        self.gpu = gpu
        self.model = load_model(model_name=model_name, gpu=self.gpu)
        self.beam = beam
        self.lang = lang

        # åŠ é€™ä¸€è¡Œä¾†é©—è­‰æ¨¡å‹è£åœ¨å“ªè£¡ logç¢ºèªGPUæˆ–CPU
        device_str = "cuda" if self.gpu else "cpu"
        logger.info(f"ğŸ§  Whisper å¯¦éš›é‹è¡Œè£ç½®: {device_str}")
        
        # å¦‚æœ CSV ä¸å­˜åœ¨ï¼Œå»ºç«‹ä¸¦å¯«å…¥æ¨™é ­
        if not CSV_PATH.exists():
            with open(CSV_PATH, mode="w", newline="", encoding="utf-8") as f:
                writer = csv.writer(f)
                writer.writerow([
                    "ç·¨è™Ÿ",
                    "éŸ³æª”é•·åº¦(ç§’)",
                    "æ¨ç†è€—æ™‚(ç§’)",
                    "ç¸½è€—æ™‚(ç§’)",
                    "å¹³å‡ä¿¡å¿ƒå€¼"
                ])
        
# #æ‰¹æ¬¡è™•ç†è³‡æ–™å¤¾éŸ³æª”
#     def transcribe_dir(self, input_dir: str, output_id: str) -> str:
#         wav_list = sorted(Path(input_dir).glob("*.wav"))
#         if not wav_list:
#             raise FileNotFoundError("âŒ No .wav found in input_dir")

#         results = []

#         for wav in wav_list:
#             logger.info(f"ğŸš€ é–‹å§‹è¾¨è­˜éŸ³æª”: {wav.name}")
#             seg_gen, _ = self.model.transcribe(
#                 str(wav),
#                 word_timestamps=True,
#                 vad_filter=False,
#                 beam_size=self.beam,
#                 language=None if self.lang == "auto" else self.lang
#             )
#             segments = list(seg_gen)
#             if not segments:
#                 continue

#             full_txt = "".join(s.text for s in segments).strip()
#             char_words = [{
#                 "start": float(w.start),
#                 "end": float(w.end),
#                 "word": str(w.word),
#                 "probability": float(w.probability)
#             } for s in segments for w in (s.words or [])]
#             word_level = merge_char_to_word(full_txt, char_words)

#             results.append({
#                 "track_id": wav.stem,
#                 "transcript": full_txt,
#                 "words": word_level,
#             })

#         out_dir = Path("data") / output_id
#         out_dir.mkdir(parents=True, exist_ok=True)
#         out_path = out_dir / "asr.json"
#         with open(out_path, "w", encoding="utf-8") as f:
#             json.dump(results, f, ensure_ascii=False, indent=2)

#         logger.info(f"âœ… å®Œæˆè¾¨è­˜ï¼Œçµæœè¼¸å‡ºè‡³: {out_path}")
#         return str(out_path)


    # å°å–®ä¸€æª”æ¡ˆå³æ™‚è™•ç†
    def transcribe(self, wav_path: str) -> tuple[str, float, list[dict]]:
        # batch_id è‡ªå‹•ç´¯åŠ 
        WhisperASR.counter += 1
        idx = WhisperASR.counter
        
        # å–å¾—éŸ³æª”é•·åº¦
        info = torchaudio.info(wav_path)
        duration_sec = info.num_frames / info.sample_rate
            
        # è¨ˆæ™‚ï¼šæ•´é«”é–‹å§‹
        start_all = time.perf_counter()
        
        # è¨ˆæ™‚ï¼šæ¨¡å‹æ¨ç†
        t0 = time.perf_counter()
        seg_gen, _ = self.model.transcribe(
            str(wav_path),
            word_timestamps=True,
            vad_filter=False,
            beam_size=self.beam,
            language=None if self.lang == "auto" else self.lang,
        )
        t1 = time.perf_counter()
        inference_time = t1 - t0
        logger.info(f"â± ASR æ¨ç†æ™‚é–“: {inference_time:.3f}s")
        
        # å¾Œè™•ç†
        segments = list(seg_gen)
        if not segments:
            return "", 0.0, []

        full_txt = "".join(s.text for s in segments).strip()
        words = [w for s in segments for w in (s.words or [])]
        
        # è‹¥ words ç‚ºç©ºï¼Œæ”¹ç”¨ segment-level average_logprob ç•¶ fallback
        if words:
            probs = [w.probability for w in words]
            avg_conf = float(sum(probs) / len(probs))
            word_info = [{
                "start": float(w.start),
                "end": float(w.end),
                "word": str(w.word),
                "probability": float(w.probability)
            } for w in words]
        else:
            avg_conf = float(sum(s.avg_logprob for s in segments) / len(segments))
            word_info = []
        
        # è¨ˆæ™‚ï¼šæ•´é«”çµæŸ
        end_all = time.perf_counter()
        total_time = end_all - start_all
        logger.info(f"âœ… transcribe() ç¸½è€—æ™‚: {total_time:.3f}s")
        
        
        # å°‡æœ¬æ¬¡çµæœå¯«å…¥CSV
        with open(CSV_PATH, mode="a", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([
                idx,
                f"{duration_sec:.3f}",
                f"{inference_time:.3f}",
                f"{total_time:.3f}",
                f"{avg_conf:.3f}"
            ])
        torch.cuda.empty_cache()
        return full_txt, avg_conf, word_info
