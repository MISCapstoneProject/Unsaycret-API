#!/usr/bin/env python3
"""
å°å…¥éŸ³æª”åˆ° AS-Norm Cohort è³‡æ–™åº«
==================================

å°‡åˆ†é›¢å¾Œçš„éŸ³æª”æ‰¹é‡å°å…¥åˆ° AS-Norm å°ˆç”¨çš„ cohort è³‡æ–™åº«ä¸­ï¼Œ
ç”¨æ–¼èªè€…è­˜åˆ¥ç³»çµ±çš„åˆ†æ•¸æ­£è¦åŒ–ã€‚

åŠŸèƒ½ç‰¹è‰²ï¼š
- ğŸ¯ æ‰¹é‡è™•ç†éŸ³æª”è³‡æ–™å¤¾
- ğŸ“Š å³æ™‚é€²åº¦é¡¯ç¤º
- ğŸ” é‡è¤‡æª”æ¡ˆæª¢æ¸¬
- ğŸ“ˆ è©³ç´°çµ±è¨ˆå ±å‘Š
- ğŸ’¾ åŒ¯å‡ºè™•ç†è¨˜éŒ„

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç¢ºä¿ Weaviate è³‡æ–™åº«å·²            import_record = {
                "file": str(audio_file),
                "source_dataset": source_dataset,
                "success": result_count > 0,
                "embeddings_count": result_count,
                "timestamp": get_taipei_time().isoformat()
            }æ”¹ä¸‹æ–¹çš„è¨­å®šåƒæ•¸
3. åŸ·è¡Œ: python examples/import_cohort_audio.py
"""

import os
import sys
import time
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from modules.database.cohort_manager import CohortDatabaseManager, get_taipei_time

# ==================== è¨­å®šå€åŸŸ ====================
# ğŸ‘‡ è«‹ä¿®æ”¹é€™è£¡çš„è¨­å®š

# éŸ³æª”è³‡æ–™å¤¾è¨­å®š
AUDIO_FOLDER = "dataset_separated_single_tcc300"  # éŸ³æª”æ ¹ç›®éŒ„
SOURCE_DATASET_PREFIX = "TCC-300"  # ä¾†æºè³‡æ–™é›†å‰ç¶´

# å…ƒæ•¸æ“šè¨­å®š
METADATA = {
    "gender": "mixed",           # æ€§åˆ¥ï¼šmixed, male, female
    "language": "zh-TW",         # èªè¨€ï¼šzh-TW, zh-CN, en, etc.
    "description": "TCC-300 åˆ†é›¢å¾Œçš„å–®èªè€…éŸ³æª”ç”¨æ–¼ AS-Norm cohort"
}

# è™•ç†è¨­å®š
AUDIO_EXTENSIONS = ['.wav', '.WAV', '.mp3', '.MP3', '.flac', '.FLAC']
ENABLE_PROGRESS_DISPLAY = True   # æ˜¯å¦é¡¯ç¤ºè©³ç´°é€²åº¦
SAVE_IMPORT_LOG = True          # æ˜¯å¦ä¿å­˜å°å…¥è¨˜éŒ„
BATCH_SIZE = 10                 # æ‰¹æ¬¡è™•ç†å¤§å°ï¼ˆæ¯Nå€‹æª”æ¡ˆé¡¯ç¤ºä¸€æ¬¡é€²åº¦ï¼‰

# å®‰å…¨è¨­å®š
CHECK_EXISTING = True           # æ˜¯å¦æª¢æŸ¥é‡è¤‡æª”æ¡ˆ
RESET_BEFORE_IMPORT = False     # æ˜¯å¦åœ¨å°å…¥å‰é‡ç½® cohort è³‡æ–™åº«
# ==================================================

class CohortImportProgress:
    """é€²åº¦é¡¯ç¤ºå™¨"""
    
    def __init__(self, total_files: int):
        self.total_files = total_files
        self.processed_files = 0
        self.success_files = 0
        self.failed_files = 0
        self.start_time = time.time()
        self.last_update = time.time()
    
    def update(self, success: bool = True):
        """æ›´æ–°é€²åº¦"""
        self.processed_files += 1
        if success:
            self.success_files += 1
        else:
            self.failed_files += 1
        
        # æ¯æ‰¹æ¬¡æˆ–æœ€å¾Œä¸€å€‹æª”æ¡ˆé¡¯ç¤ºé€²åº¦
        if (self.processed_files % BATCH_SIZE == 0 or 
            self.processed_files == self.total_files):
            self.display_progress()
    
    def display_progress(self):
        """é¡¯ç¤ºé€²åº¦è³‡è¨Š"""
        if not ENABLE_PROGRESS_DISPLAY:
            return
        
        current_time = time.time()
        elapsed = current_time - self.start_time
        
        # è¨ˆç®—é€²åº¦ç™¾åˆ†æ¯”
        progress_pct = (self.processed_files / self.total_files) * 100
        
        # è¨ˆç®—é ä¼°å‰©é¤˜æ™‚é–“
        if self.processed_files > 0:
            avg_time_per_file = elapsed / self.processed_files
            remaining_files = self.total_files - self.processed_files
            eta_seconds = avg_time_per_file * remaining_files
            eta_minutes = eta_seconds / 60
        else:
            eta_minutes = 0
        
        print(f"\nğŸ“Š é€²åº¦å ±å‘Š ({self.processed_files}/{self.total_files}, {progress_pct:.1f}%)")
        print(f"   âœ… æˆåŠŸ: {self.success_files}")
        print(f"   âŒ å¤±æ•—: {self.failed_files}")
        print(f"   â±ï¸  å·²è€—æ™‚: {elapsed/60:.1f} åˆ†é˜")
        print(f"   ğŸ• é ä¼°å‰©é¤˜: {eta_minutes:.1f} åˆ†é˜")
        
        self.last_update = current_time

def check_audio_folder(folder_path: str) -> Dict[str, Any]:
    """
    æª¢æŸ¥éŸ³æª”è³‡æ–™å¤¾ä¸¦æ”¶é›†çµ±è¨ˆè³‡è¨Š
    
    Args:
        folder_path: éŸ³æª”è³‡æ–™å¤¾è·¯å¾‘
        
    Returns:
        Dict[str, Any]: è³‡æ–™å¤¾çµ±è¨ˆè³‡è¨Š
    """
    folder = Path(folder_path)
    if not folder.exists():
        return {
            "exists": False,
            "error": f"è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}"
        }
    
    print(f"ğŸ” æƒæéŸ³æª”è³‡æ–™å¤¾: {folder_path}")
    
    # çµ±è¨ˆéŸ³æª”
    audio_files = []
    speaker_folders = {}
    total_size = 0
    
    for ext in AUDIO_EXTENSIONS:
        audio_files.extend(folder.rglob(f"*{ext}"))
    
    # åˆ†ææª”æ¡ˆ
    for file_path in audio_files:
        # è¨ˆç®—æª”æ¡ˆå¤§å°
        try:
            size = file_path.stat().st_size
            total_size += size
        except:
            size = 0
        
        # åˆ†æèªè€…è³‡æ–™å¤¾
        relative_path = file_path.relative_to(folder)
        speaker_folder = relative_path.parts[0] if relative_path.parts else "unknown"
        
        if speaker_folder not in speaker_folders:
            speaker_folders[speaker_folder] = 0
        speaker_folders[speaker_folder] += 1
    
    return {
        "exists": True,
        "total_files": len(audio_files),
        "total_size_mb": total_size / (1024 * 1024),
        "speaker_folders": len(speaker_folders),
        "speaker_distribution": speaker_folders,
        "audio_files": audio_files
    }

def check_existing_cohort(manager: CohortDatabaseManager) -> Dict[str, Any]:
    """
    æª¢æŸ¥ç¾æœ‰çš„ cohort è³‡æ–™åº«ç‹€æ…‹
    
    Args:
        manager: Cohort è³‡æ–™åº«ç®¡ç†å™¨
        
    Returns:
        Dict[str, Any]: ç¾æœ‰è³‡æ–™åº«ç‹€æ…‹
    """
    print("ğŸ” æª¢æŸ¥ç¾æœ‰ cohort è³‡æ–™åº«...")
    
    stats = manager.get_cohort_statistics()
    if stats.get("exists", False):
        print(f"ğŸ“Š ç¾æœ‰ cohort çµ±è¨ˆ:")
        print(f"   - ç¸½è²ç´‹æ•¸: {stats.get('total_count', 0)}")
        print(f"   - è³‡æ–™é›†æ•¸: {len(stats.get('source_datasets', {}))}")
        
        if stats.get('source_datasets'):
            print(f"   - ä¾†æºåˆ†å¸ƒ:")
            for dataset, count in stats.get('source_datasets', {}).items():
                print(f"     â€¢ {dataset}: {count}")
    else:
        print("ğŸ“ cohort è³‡æ–™åº«ç‚ºç©ºæˆ–ä¸å­˜åœ¨")
    
    return stats

def import_audio_files(manager: CohortDatabaseManager, audio_files: List[Path], 
                      folder_path: str) -> Dict[str, Any]:
    """
    æ‰¹é‡å°å…¥éŸ³æª”
    
    Args:
        manager: Cohort è³‡æ–™åº«ç®¡ç†å™¨
        audio_files: éŸ³æª”è·¯å¾‘åˆ—è¡¨
        folder_path: éŸ³æª”æ ¹ç›®éŒ„
        
    Returns:
        Dict[str, Any]: å°å…¥çµæœ
    """
    print(f"\nğŸš€ é–‹å§‹æ‰¹é‡å°å…¥ {len(audio_files)} å€‹éŸ³æª”...")
    
    # åˆå§‹åŒ–é€²åº¦è¿½è¹¤
    progress = CohortImportProgress(len(audio_files))
    import_log = []
    
    success_count = 0
    failed_files = []
    
    for i, audio_file in enumerate(audio_files, 1):
        try:
            # æº–å‚™æª”æ¡ˆå°ˆå±¬å…ƒæ•¸æ“š
            file_metadata = METADATA.copy()
            file_metadata.update({
                "original_file": audio_file.name,
                "file_path": str(audio_file.relative_to(folder_path)),
                "import_timestamp": get_taipei_time().isoformat()
            })
            
            # æ±ºå®š source_dataset åç¨±
            if SOURCE_DATASET_PREFIX:
                source_dataset = f"{SOURCE_DATASET_PREFIX}_{audio_file.stem}"
            else:
                source_dataset = audio_file.stem
            
            # å°å…¥å–®å€‹æª”æ¡ˆ
            result_count = manager.import_audio_file(
                str(audio_file), 
                source_dataset, 
                file_metadata
            )
            
            # è¨˜éŒ„çµæœ
            log_entry = {
                "file": str(audio_file),
                "source_dataset": source_dataset,
                "success": result_count > 0,
                "embeddings_count": result_count,
                "timestamp": datetime.now().isoformat()
            }
            
            if result_count > 0:
                success_count += 1
                progress.update(success=True)
                if ENABLE_PROGRESS_DISPLAY and i <= 5:  # åªé¡¯ç¤ºå‰5å€‹è©³ç´°è¨Šæ¯
                    print(f"   âœ… {audio_file.name} -> {source_dataset}")
            else:
                failed_files.append(str(audio_file))
                log_entry["error"] = "ç„¡æ³•æå–è²ç´‹"
                progress.update(success=False)
                print(f"   âŒ {audio_file.name} - ç„¡æ³•æå–è²ç´‹")
            
            import_log.append(log_entry)
            
        except Exception as e:
            failed_files.append(str(audio_file))
            log_entry = {
                "file": str(audio_file),
                "success": False,
                "error": str(e),
                "timestamp": get_taipei_time().isoformat()
            }
            import_log.append(log_entry)
            progress.update(success=False)
            print(f"   âŒ {audio_file.name} - {e}")
    
    # æœ€çµ‚é€²åº¦é¡¯ç¤º
    progress.display_progress()
    
    return {
        "total_files": len(audio_files),
        "success_files": success_count,
        "failed_files": len(failed_files),
        "success_rate": (success_count / len(audio_files)) * 100 if audio_files else 0,
        "failed_file_list": failed_files,
        "import_log": import_log,
        "total_time": time.time() - progress.start_time
    }

def save_import_log(results: Dict[str, Any]) -> str:
    """ä¿å­˜å°å…¥è¨˜éŒ„"""
    if not SAVE_IMPORT_LOG:
        return ""
    
    timestamp = get_taipei_time().strftime("%Y%m%d_%H%M%S")
    log_file = f"cohort_import_log_{timestamp}.json"
    
    try:
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ’¾ å°å…¥è¨˜éŒ„å·²ä¿å­˜: {log_file}")
        return log_file
        
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜å°å…¥è¨˜éŒ„å¤±æ•—: {e}")
        return ""

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸµ AS-Norm Cohort è³‡æ–™åº«éŸ³æª”å°å…¥å·¥å…·")
    print("=" * 80)
    print(f"ğŸ“‚ éŸ³æª”è³‡æ–™å¤¾: {AUDIO_FOLDER}")
    print(f"ğŸ·ï¸  è³‡æ–™é›†å‰ç¶´: {SOURCE_DATASET_PREFIX}")
    print(f"ğŸ”§ æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"ğŸ›¡ï¸  é‡ç½®è³‡æ–™åº«: {'æ˜¯' if RESET_BEFORE_IMPORT else 'å¦'}")
    print(f"ğŸ“Š é€²åº¦é¡¯ç¤º: {'é–‹å•Ÿ' if ENABLE_PROGRESS_DISPLAY else 'é—œé–‰'}")
    print(f"ğŸ’¾ ä¿å­˜è¨˜éŒ„: {'é–‹å•Ÿ' if SAVE_IMPORT_LOG else 'é—œé–‰'}")
    print()
    
    try:
        # æ­¥é©Ÿ1: æª¢æŸ¥éŸ³æª”è³‡æ–™å¤¾
        folder_info = check_audio_folder(AUDIO_FOLDER)
        if not folder_info["exists"]:
            print(f"âŒ {folder_info['error']}")
            return
        
        print(f"ğŸ“Š è³‡æ–™å¤¾çµ±è¨ˆ:")
        print(f"   - éŸ³æª”æ•¸é‡: {folder_info['total_files']}")
        print(f"   - ç¸½å¤§å°: {folder_info['total_size_mb']:.2f} MB")
        print(f"   - èªè€…è³‡æ–™å¤¾: {folder_info['speaker_folders']}")
        
        if folder_info['total_files'] == 0:
            print("âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•éŸ³æª”")
            return
        
        # æ­¥é©Ÿ2: åˆå§‹åŒ– cohort ç®¡ç†å™¨ï¼ˆä½¿ç”¨ pyannote æ¨¡å‹ï¼‰
        print(f"\nğŸ”§ åˆå§‹åŒ– cohort è³‡æ–™åº«ç®¡ç†å™¨...")
        manager = CohortDatabaseManager(model_type="pyannote")
        
        # æ­¥é©Ÿ3: æª¢æŸ¥ç¾æœ‰è³‡æ–™åº«
        existing_stats = check_existing_cohort(manager)
        
        # æ­¥é©Ÿ4: é‡ç½®è³‡æ–™åº«ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if RESET_BEFORE_IMPORT:
            print(f"\nğŸ—‘ï¸  é‡ç½® cohort è³‡æ–™åº«...")
            if manager.reset_cohort_collection():
                print("âœ… è³‡æ–™åº«é‡ç½®æˆåŠŸ")
            else:
                print("âŒ è³‡æ–™åº«é‡ç½®å¤±æ•—")
                return
        
        # æ­¥é©Ÿ5: ç¢ºèªå°å…¥
        print(f"\nâš ï¸  å³å°‡å°å…¥ {folder_info['total_files']} å€‹éŸ³æª”åˆ° cohort è³‡æ–™åº«")
        print(f"ä¾†æº: {AUDIO_FOLDER}")
        print(f"å‰ç¶´: {SOURCE_DATASET_PREFIX}")
        
        # åœ¨å¯¦éš›ç’°å¢ƒä¸­å¯ä»¥åŠ å…¥ç¢ºèªæç¤º
        # confirm = input("ç¢ºå®šè¦ç¹¼çºŒå—ï¼Ÿ(y/N): ")
        # if confirm.lower() != 'y':
        #     print("å–æ¶ˆå°å…¥")
        #     return
        
        # æ­¥é©Ÿ6: åŸ·è¡Œå°å…¥
        start_time = time.time()
        results = import_audio_files(manager, folder_info['audio_files'], AUDIO_FOLDER)
        
        # æ­¥é©Ÿ7: é¡¯ç¤ºçµæœ
        print(f"\n" + "=" * 80)
        print("ğŸ“ˆ å°å…¥å®Œæˆï¼")
        print("=" * 80)
        print(f"ç¸½æª”æ¡ˆæ•¸: {results['total_files']}")
        print(f"æˆåŠŸå°å…¥: {results['success_files']}")
        print(f"å¤±æ•—æª”æ¡ˆ: {results['failed_files']}")
        print(f"æˆåŠŸç‡: {results['success_rate']:.1f}%")
        print(f"ç¸½è€—æ™‚: {results['total_time']:.2f} ç§’")
        
        if results['failed_files'] > 0:
            print(f"\nâŒ å¤±æ•—æª”æ¡ˆåˆ—è¡¨ (å‰10å€‹):")
            for failed_file in results['failed_file_list'][:10]:
                print(f"   - {failed_file}")
            if len(results['failed_file_list']) > 10:
                print(f"   ... é‚„æœ‰ {len(results['failed_file_list']) - 10} å€‹")
        
        # æ­¥é©Ÿ8: æª¢æŸ¥æœ€çµ‚çµ±è¨ˆ
        final_stats = manager.get_cohort_statistics()
        print(f"\nğŸ“Š æ›´æ–°å¾Œçš„ cohort çµ±è¨ˆ:")
        print(f"   - ç¸½è²ç´‹æ•¸: {final_stats.get('total_count', 0)}")
        print(f"   - è³‡æ–™é›†æ•¸: {len(final_stats.get('source_datasets', {}))}")
        
        # æ­¥é©Ÿ9: ä¿å­˜è¨˜éŒ„
        log_file = save_import_log(results)
        
        # æ­¥é©Ÿ10: æ¸…ç†
        manager.close()
        print(f"\nâœ… å°å…¥ç¨‹åºå®Œæˆ")
        
    except Exception as e:
        print(f"\nâŒ å°å…¥éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
