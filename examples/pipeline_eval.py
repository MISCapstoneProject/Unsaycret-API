import argparse
import csv
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple
import time
import json
import gc

# import numpy as np
import torch
import torchaudio
import tempfile

from pipelines.orchestrator import init_pipeline_modules,run_pipeline_file
from modules.separation.separator import AudioSeparator
from modules.asr.text_utils import compute_cer, normalize_zh
# from modules.identification.VID_identify_v5 import SpeakerIdentifier
# from modules.asr.whisper_asr import WhisperASR


@dataclass
class SourceInfo:
    path: Path
    transcript: str | None
    mix_sdr: float | None = None
    sep_sdr: float | None = None
    delta_sdr: float | None = None
    clean_wave: torch.Tensor | None = None
    
    
def load_truth_map(path: Path) -> Dict[str, str]:
    mapping: Dict[str, str] = {}
    with path.open("r", encoding="utf-8") as f:
        next(f)  # skip header
        for line in f:
            line = line.strip()
            if not line:
                continue
            fname, txt = line.split(",", 1)
            mapping[fname] = txt
    return mapping


def load_mixture_map(path: Path) -> List[Tuple[str, str, str, str]]:
    rows: List[Tuple[str, str, str, str]] = []
    with path.open("r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            rows.append((row["mix_id"], row["mix_file"], row["src1"], row["src2"]))
    return rows

#è¨ˆç®—SI-SDR å¯åŒæ™‚è¨ˆç®—åˆ†é›¢å‰å’Œåˆ†é›¢å¾Œçš„SDR
def si_sdr(est: torch.Tensor, ref: torch.Tensor) -> float:
    """Scale-Invariant SDR for single-channel signals."""
    min_len = min(len(est), len(ref))
    est = est[:min_len]
    ref = ref[:min_len]

    est = est - est.mean()
    ref = ref - ref.mean()
    s_target = torch.dot(est, ref) * ref / torch.dot(ref, ref)
    e_noise = est - s_target
    return 10 * torch.log10((s_target.pow(2).sum()) / (e_noise.pow(2).sum())).item()
#å–æª”æ¡ˆä¸¦çµ±è¨ˆSI-SDR
def compute_baseline_sisdr(
    mix_path: Path,
    src1_path: Path,
    src2_path: Path,
    separator: AudioSeparator,
    sep_paths: List[Path] | None = None,
) -> Dict[str, float]:
    """
    è¨ˆç®— baseline èˆ‡åˆ†é›¢å¾Œçš„ SI-SDRï¼Œä»¥åŠ Î”SI-SDRã€‚

    mix_path  : æ··éŸ³æª” (.wav)
    src1_path : ä¾†æº 1 (ä¹¾æ·¨)
    src2_path : ä¾†æº 2 (ä¹¾æ·¨)
    separator : ä½ åˆå§‹åŒ–å¥½çš„ AudioSeparator å¯¦ä¾‹
    sep_paths : ã€å¯é¸ã€‘å·²å­˜åœ¨çš„åˆ†é›¢å¾Œ wav è·¯å¾‘æ¸…å–®
                è‹¥ Noneï¼Œå‡½å¼æœƒè‡¨æ™‚å†è·‘ä¸€æ¬¡ separator å–å¾—åˆ†é›¢éŸ³
    return    : dictï¼Œå« 4 å€‹æ¬„ä½
    """
    # --- è®€å– waveforms --------------------------------------------------
    def _load(wav: Path) -> torch.Tensor:
        wav_tensor, _ = torchaudio.load(wav)
        return wav_tensor.squeeze(0)          # [1, T] -> [T]

    mix_wave  = _load(mix_path)
    src1_wave = _load(src1_path)
    src2_wave = _load(src2_path)

    # --- baselineï¼šæ··éŸ³ vs å…©å€‹ä¹¾æ·¨æº -----------------------------------
    sdr_mix_src1 = si_sdr(mix_wave, src1_wave)
    sdr_mix_src2 = si_sdr(mix_wave, src2_wave)

    # --- å–å¾—åˆ†é›¢å¾ŒéŸ³æª” ---------------------------------------------------
    if sep_paths is None:
        # å¦‚æœå‘¼å«ç«¯æ²’çµ¦ï¼Œå°±è‡¨æ™‚å†åˆ†ä¸€æ¬¡ï¼ˆçœäº‹ä½†è¼ƒè€—æ™‚ï¼‰
        tmp_dir = Path(tempfile.mkdtemp(prefix="eval_sep_"))
        # æ³¨æ„ï¼šseparator éœ€è¦ tensor åœ¨æ­£ç¢º device
        mix_wave_device = mix_wave.to(separator.device).unsqueeze(0)  # [T] â†’ [1, T]
        sep_paths = [
            Path(p) for p, *_ in
            separator.separate_and_save(mix_wave_device, tmp_dir.as_posix(), segment_index=0)
        ]

    # --- åˆ†é›¢å¾Œ vs ä¹¾æ·¨æºï¼šå–ã€Œæœ€ä½³å°æ‡‰ã€å³å¯ -----------------------------
    def _best_sdr(ref_wave: torch.Tensor) -> float:
        best = -1e9
        for p in sep_paths:
            est_wave = _load(p)
            best = max(best, si_sdr(est_wave, ref_wave))
        return best

    sdr_sep_src1 = _best_sdr(src1_wave)
    sdr_sep_src2 = _best_sdr(src2_wave)

    # --- Î”SI-SDR ---------------------------------------------------------
    delta1 = sdr_sep_src1 - sdr_mix_src1
    delta2 = sdr_sep_src2 - sdr_mix_src2

    return {
        "si_sdr_src1":       sdr_sep_src1,
        "si_sdr_src2":       sdr_sep_src2,
        "delta_si_sdr_src1": delta1,
        "delta_si_sdr_src2": delta2,
    }
#spkID
def compute_accuracy(pred_speakers: List[str], true_speakers: List[str]) -> float:
    """
    pred_speakers: pipeline åˆ†é›¢å¾Œæ‰€æœ‰æ®µè½çš„é æ¸¬ speaker id (e.g. ["spk3","spk10"])
    true_speakers: mixture_map å®šç¾©çš„å…©ä½åŸå§‹ speaker id (e.g. ["spk10","spk1"])
    å›å‚³å€¼: æ­£ç¢ºæ•¸ / 2 -> 0.0, 0.5, or 1.0
    """
    matched = len(set(pred_speakers) & set(true_speakers))
    return matched / len(true_speakers)

NUM_MAP = {'0':'é›¶','1':'ä¸€','2':'äºŒ','3':'ä¸‰','4':'å››',
           '5':'äº”','6':'å…­','7':'ä¸ƒ','8':'å…«','9':'ä¹'}

def normalize_numbers_to_zh(text: str) -> str:
    return "".join(NUM_MAP.get(ch, ch) for ch in text)

def load_config_and_data() -> Tuple[argparse.Namespace, Path, Path, Dict[str, str], List[Tuple[str, str, str, str]]]:
    parser = argparse.ArgumentParser(description="Run speech pipeline and evaluate")
    parser.add_argument("--mix-dir", default="data/mix", help="mixè·¯å¾‘")
    parser.add_argument("--clean-dir", default="data/clean", help="cleanè·¯å¾‘")
    parser.add_argument("--truth-map", default="data/truth_map.csv")
    parser.add_argument("--test-list",  default="data/mix/mixture_map.csv",  help="batch æ¸¬è©¦æ¸…å–® CSV (mix_id,mix_file,src1,src2)")
    parser.add_argument("--out", default="work_output/pipeline_results.csv")
    args = parser.parse_args()

    mix_dir = Path(args.mix_dir)
    clean_dir = Path(args.clean_dir)
    truth_map = load_truth_map(Path(args.truth_map))
    mixture_rows = load_mixture_map(Path(args.test_list))
    Path(args.out).parent.mkdir(parents=True, exist_ok=True)

    return args, mix_dir, clean_dir, truth_map, mixture_rows

def prepare_results_structure() -> tuple[list[str], list[dict]]:
    columns = [
        "mix_id", "mix_file",
        "sep_time", "sid_time", "asr_time", "total_time",
        "si_sdr_src1", "si_sdr_src2",
        "delta_si_sdr_src1", "delta_si_sdr_src2",
        "accuracy",
        "cer1", "cer2", "avg_conf",
        "ref_text1", "pred_text1", "ref_text2", "pred_text2",
    ]
    return columns, []

def process_one_mixture(
    mix_path: str,
    mix_id: str = None,
    sep=None, spk=None, asr=None,
    clean_dir: Path = None,
    mixture_rows: List[Tuple[str, str, str, str]] = None,
    truth_map: Dict[str, str] = None,
) -> dict:
    """
    è™•ç†ä¸€çµ„æ··éŸ³éŸ³æª”ï¼Œè·‘å®Œæ•´çš„ pipelineï¼Œä¸¦å›å‚³æ‰€æœ‰å¯å–å¾—çš„æŒ‡æ¨™ã€‚
    
    mix_path: æ··éŸ³éŸ³æª”å®Œæ•´è·¯å¾‘
    mix_id: é¸å¡«çš„æª”æ¡ˆåç¨±ï¼ˆä¸å«å‰¯æª”åï¼‰ï¼Œé è¨­ç”¨æª”å
    return: ä¸€å€‹ dictï¼ŒåŒ…å« pipeline çš„æ‰€æœ‰å¯è§€å¯Ÿæ•¸æ“š
    """
    # ä½¿ç”¨ç›®å‰æ™‚é–“è¨ˆç®—ç¸½è€—æ™‚
    overall_start = time.perf_counter()
    mix_wav = Path(mix_path)
    
    if mix_id is None:
        mix_id = Path(mix_path).stem  # å–æª”åç•¶ä½œ id

    # ğŸŒ€ å‘¼å«ä¸»æµç¨‹è·‘å®Œæ•´ pipeline
    try:
        bundle, _ , stats = run_pipeline_file(mix_path,3, sep=sep, spk=spk, asr=asr)
    except Exception as e:
        print(f"[ERROR] è™•ç†æª”æ¡ˆ {mix_path} æ™‚å‡ºéŒ¯ï¼š{e}")
        return {
            "mix_id": mix_id,
            "mix_file": mix_path,
            "error": str(e)
        }

    # ğŸ“Š çµ±è¨ˆèˆ‡æ•´ç†å„éšæ®µè³‡è¨Š
    recog_texts = [s.get("text", "") for s in bundle if s.get("text")]
    confidences = [s.get("confidence", 0.0) for s in bundle if s.get("text")]

    full_text = " ".join(recog_texts)
    avg_conf = sum(confidences) / len(confidences) if confidences else 0.0

    result = {
        "mix_id": mix_id,
        "mix_file": mix_path,
        "seg_count": len(bundle),
        "sep_time": round(stats.get("separate", 0.0), 3),
        "sid_time": round(stats.get("speaker", 0.0), 3),
        "asr_time": round(stats.get("asr", 0.0), 3),
        "total_time": round(stats.get("total", 0.0), 3),
        "pipeline_time": round(stats.get("pipeline_total", 0.0), 3),
        "avg_conf": round(avg_conf, 4),
        "predicted_text": full_text,
        "segments": bundle,
        "overall_time": round(time.perf_counter() - overall_start, 3),
    }
    
    # â‘¢ åŠ ä¸Š baseline SI-SDR è¨ˆç®—    
    # è§£æ src1 / src2 æ¸…éŸ³è·¯å¾‘
    if clean_dir and mixture_rows:
        row = next((r for r in mixture_rows if r[0] == mix_id), None)
        if row:
            src1 = clean_dir / row[2]
            src2 = clean_dir / row[3]
            sep_paths = [Path(s["path"]) for s in bundle if "path" in s]
            sisdr_metrics = compute_baseline_sisdr(mix_wav, src1, src2, sep, sep_paths)
            result.update(sisdr_metrics)
            
            # --- å–å‡º true speaker IDs from mixture_map row ---
            # row[2] = "speaker10/â€¦", row[3] = "speaker1/â€¦"
            # row[2] = "speaker10/speaker10_17.wav"
            # Path(row[2]).parent.name â†’ "speaker10"
            # .replace("speaker", "spk") â†’ "spk10"
            
            true_spk1 = Path(row[2]).parent.name.replace("speaker", "spk")
            true_spk2 = Path(row[3]).parent.name.replace("speaker", "spk")
            true_speakers = [true_spk1, true_spk2]
            # print(f"ğŸ” çœŸå¯¦èªè€…ï¼š{true_speakers}")
            
            # --- å–å‡º pipeline é æ¸¬çš„æ‰€æœ‰ speaker IDs ---
            pred_speakers = [seg.get("speaker") for seg in bundle]
            # print(f"ğŸ” é æ¸¬èªè€…ï¼š{pred_speakers}")
            # --- è¨ˆç®— accuracy ---
            acc = compute_accuracy(pred_speakers, true_speakers)
            # print(f"ğŸ” èªè€…è¾¨è­˜æº–ç¢ºç‡ï¼š{acc:.2f}")
            result["accuracy"] = acc
            
                        # === CER & ref/pred text for each speaker === #
            # 1) åœ°å–æ¯å€‹ source çš„æ­£ç¢ºæ–‡å­—
            ref_fname1 = Path(src1).name                         # e.g. "speaker10_17.wav"
            ref_fname2 = Path(src2).name
            raw_ref1 = truth_map.get(ref_fname1, "")
            raw_ref2 = truth_map.get(ref_fname2, "")

            # 2) Normalize (å»æ¨™é»ã€ç©ºæ ¼ã€çµ±ä¸€ç¹é«”)
            ref_norm1 = normalize_zh(raw_ref1)
            ref_norm2 = normalize_zh(raw_ref2)
            # print(f"ğŸ” æ­£è¦åŒ–æ–‡å­—1ï¼š{ref_norm1}"
            #         f" æ­£è¦åŒ–æ–‡å­—2ï¼š{ref_norm2}")

            # 3) å¾ bundle ä¸­æ‰¾å‡ºå°æ‡‰ true speaker çš„é æ¸¬æ–‡å­—
            pred_text1 = ""
            pred_text2 = ""
            for seg in bundle:
                if seg.get("speaker") == true_spk1:
                    pred_text1 = seg.get("text", "")
                elif seg.get("speaker") == true_spk2:
                    pred_text2 = seg.get("text", "")
            pred_norm1 = normalize_numbers_to_zh(normalize_zh(pred_text1))
            pred_norm2 = normalize_numbers_to_zh(normalize_zh(pred_text2))

            # print(f"ğŸ” é æ¸¬æ–‡å­—1ï¼š{pred_norm1}"
            #         f" é æ¸¬æ–‡å­—2ï¼š{pred_norm2}")
            # 4) è¨ˆç®— CER
            cer1 = compute_cer(ref_norm1, pred_norm1) if ref_norm1 else None
            cer2 = compute_cer(ref_norm2, pred_norm2) if ref_norm2 else None
            # print(f"ğŸ” CER1ï¼š{cer1:.4f} CER2ï¼š{cer2:.4f}")
            # 5) å¯«å…¥çµæœ
            result.update({
                "ref_text1": ref_norm1,
                "pred_text1": pred_norm1,
                "cer1": cer1,
                "ref_text2": ref_norm2,
                "pred_text2": pred_norm2,
                "cer2": cer2,
            })
            del asr
            torch.cuda.empty_cache()
            gc.collect()
        else:
            print(f"[WARN] mix_id {mix_id} not found in mixture_map")
        
            

    return result

def run_and_evaluate_pipeline(
    mixture_csv: Path,
    mix_dir: Path,
    clean_dir: Path,
    truth_map: Dict[str, str],
    sep, spk, asr,
    output_csv: Path,
):
    test_rows = load_mixture_map(mixture_csv)               # â‘  è®€å–æ¸…å–®
    cols, _ = prepare_results_structure()

    with output_csv.open("w", newline="", encoding="utf-8") as fout:
        writer = csv.DictWriter(fout, fieldnames=cols)
        writer.writeheader()

        for mix_id, mix_file, *_ in test_rows:              # â‘¡ é€ç­†è·‘
            mix_path = mix_dir / mix_file
            print(f"ğŸ‘‰ è™•ç† {mix_id} â†’ {mix_path}")

            res = process_one_mixture(
                str(mix_path), mix_id,
                sep=sep, spk=spk, asr=asr,
                clean_dir=clean_dir,
                mixture_rows=test_rows,
                truth_map=truth_map
            )

            # â‘¢ å¦‚æœ pipeline å‡ºéŒ¯å°±è·³éï¼Œä¸å¯«é€² CSV
            if "error" in res:
                print(f"ğŸš¨ è·³é {mix_id}ï¼ŒåŸå› ï¼š{res['error']}")
                continue

            # â‘£ åªç•™ä¸‹æŒ‡å®šæ¬„ä½
            row = {k: res.get(k, "") for k in cols}
            writer.writerow(row)

    print(f"âœ… å…¨éƒ¨å®Œæˆï¼çµæœå·²å¯«å…¥ {output_csv}")
    
def main():
    # 1ï¸âƒ£ æ¸…ç©º GPU å¿«å–
    torch.cuda.empty_cache()
    gc.collect()

    # 2ï¸âƒ£ è¼‰å…¥æ‰€æœ‰åƒæ•¸èˆ‡è³‡æ–™
    #    --mix-dirã€--clean-dirã€--truth-mapã€--test-listã€--out éƒ½å·²è¨­é è¨­
    args, mix_dir, clean_dir, truth_map, _ = load_config_and_data()

    # 3ï¸âƒ£ åˆå§‹åŒ–æ¨¡å‹
    sep, spk, asr, _ = init_pipeline_modules()

    run_and_evaluate_pipeline(
        mixture_csv=Path(args.test_list),
        mix_dir=mix_dir,
        clean_dir=clean_dir,
        truth_map=truth_map,
        sep=sep, spk=spk, asr=asr,
        output_csv=Path(args.out),
    )

    # # â‘£ æ¸¬è©¦ä¸€çµ„æ··éŸ³
    # test_mix_id = "m01"  # ä½ å¯ä»¥è‡ªè¨‚ä¸€å€‹ ID
    # test_mix_path = "data/mix/m01.wav"  # â† æ”¹æˆä½ å¯¦éš›æœ‰çš„éŸ³æª”è·¯å¾‘ï¼

    # print(f"ğŸ‘‰ è™•ç†æ¸¬è©¦éŸ³æª”ï¼š{test_mix_path}")
    # result = process_one_mixture(
    #     test_mix_path,
    #     test_mix_id,
    #     sep=sep,
    #     spk=spk,
    #     asr=asr,
    #     clean_dir=clean_dir,
    #     mixture_rows=mixture_rows,
    #     truth_map=truth_map
    # )
    # #  å¯«å…¥ JSON æª”
    # with open(f"{test_mix_id}_result.json", "w", encoding="utf-8") as f:
    #     json.dump(result, f, indent=2, ensure_ascii=False)
    # print(f"ğŸ’¾ å·²å„²å­˜ JSON æª”è‡³ï¼š{test_mix_id}_result.json")
    
    
if __name__ == "__main__":
    main()
